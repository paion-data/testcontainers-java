{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Disclaimer This is NOT the official Testcontainers documentation. This site is used as the team knowledge hub for Paion Data. The official Testcontainers for Java is at java.testcontainers.org Testcontainers for Java Not using Java? Here are other supported languages! Java Go .NET Node.js Python Rust Haskell Ruby About Testcontainers for Java Testcontainers for Java is a Java library that supports JUnit tests, providing lightweight, throwaway instances of common databases, Selenium web browsers, or anything else that can run in a Docker container. Testcontainers make the following kinds of tests easier: Data access layer integration tests : use a containerized instance of a MySQL, PostgreSQL or Oracle database to test your data access layer code for complete compatibility, but without requiring complex setup on developers' machines and safe in the knowledge that your tests will always start with a known DB state. Any other database type that can be containerized can also be used. Application integration tests : for running your application in a short-lived test mode with dependencies, such as databases, message queues or web servers. UI/Acceptance tests : use containerized web browsers , compatible with Selenium, for conducting automated UI tests. Each test can get a fresh instance of the browser, with no browser state, plugin variations or automated browser upgrades to worry about. And you get a video recording of each test session, or just each session where tests failed. Much more! Check out the various contributed modules or create your own custom container classes using GenericContainer as a base. Prerequisites Docker - please see General Docker requirements A supported JVM testing framework: JUnit 4 - See the JUnit 4 Quickstart Guide Jupiter/JUnit 5 Spock Or manually add code to control the container/test lifecycle (See hints for this approach ) Maven dependencies Testcontainers is distributed as separate JARs with a common version number: A core JAR file for core functionality, generic containers and docker-compose support A separate JAR file for each of the specialised modules. Each module's documentation describes the Maven/Gradle dependency to add to your project's build. For the core library, the latest Maven/Gradle dependency is as follows: Gradle Maven testImplementation \"org.testcontainers:testcontainers:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> You can also check the latest version available on Maven Central . Managing versions for multiple Testcontainers dependencies To avoid specifying the version of each dependency, you can use a BOM or Bill Of Materials . Using Maven you can add the following to dependencyManagement section in your pom.xml : Maven <dependencyManagement> <dependencies> <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers-bom </artifactId> <version> 1.20.6 </version> <type> pom </type> <scope> import </scope> </dependency> </dependencies> </dependencyManagement> and then use dependencies without specifying a version: Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> mysql </artifactId> <scope> test </scope> </dependency> Using Gradle 5.0 or higher, you can add the following to the dependencies section in your build.gradle : Gradle implementation platform ( 'org.testcontainers:testcontainers-bom:1.20.6' ) //import bom testImplementation ( 'org.testcontainers:mysql' ) //no version specified JitPack builds are available for pre-release versions. Shaded dependencies Testcontainers depends on other libraries (like docker-java) for it to work. Some of them (JUnit, docker-java-{api,transport} and its transitive dependencies, JNA, visible-assertions and others) are part of our public API. But there are also \"private\", implementation detail dependencies (e.g., docker-java-core, Guava, OkHttp, etc.) that are not exposed to public API but prone to conflicts with test code/application under test code. As such, these libraries are 'shaded' into the core Testcontainers JAR and relocated under org.testcontainers.shaded to prevent class conflicts. Sponsors A huge thank you to our sponsors: Bronze sponsors Cirrus CI Vivy jOOQ Backbase Elastic Donors Red Hat Spotify Backers Philip Riecks (@rieckpil) Karl Heinz Marbaise (@khmarbaise) Sascha Frinken (@sascha-frinken) Christoph Dreis (@dreis2211) Nikita Zhevnitskiy (@zhenik) Bas Stoker (@bastoker) Oleg Nenashev (@oleg-nenashev) Rik Glover (@rikglover) Amitosh Swain Mahapatra (@recrsn) Paris Apostolopoulos Who is using Testcontainers? ZeroTurnaround - Testing of the Java Agents, micro-services, Selenium browser automation Zipkin - MySQL and Cassandra testing Apache Gora - CouchDB testing Apache James - LDAP and Cassandra integration testing StreamSets - LDAP, MySQL Vault, MongoDB, Redis integration testing Playtika - Kafka, Couchbase, MariaDB, Redis, Neo4j, Aerospike, MemSQL JetBrains - Testing of the TeamCity plugin for HashiCorp Vault Plumbr - Integration testing of data processing pipeline micro-services Streamlio - Integration and Chaos Testing of our fast data platform based on Apache Pulsar, Apache BookKeeper and Apache Heron. Spring Session - Redis, PostgreSQL, MySQL and MariaDB integration testing Apache Camel - Testing Camel against native services such as Consul, Etcd and so on Infinispan - Testing the Infinispan Server as well as integration tests with databases, LDAP and KeyCloak Instana - Testing agents and stream processing backends eBay Marketing - Testing for MySQL, Cassandra, Redis, Couchbase, Kafka, etc. Skyscanner - Integration testing against HTTP service mocks and various data stores Neo4j-OGM - Testing with Neo4j Spring Data Neo4j - Testing imperative and reactive implementations with Neo4j Lightbend - Testing Alpakka Kafka and support in Alpakka Kafka Testkit Zalando SE - Testing core business services Europace AG - Integration testing for databases and micro services Micronaut Data - Testing of Micronaut Data JDBC, a database access toolkit Vert.x SQL Client - Testing with PostgreSQL, MySQL, MariaDB, SQL Server, etc. JHipster - Couchbase and Cassandra integration testing wescale - Integration testing against HTTP service mocks and various data stores Marquez - PostgreSQL integration testing Wise (formerly TransferWise) - Integration testing for different RDBMS, kafka and micro services XWiki - Testing XWiki under all supported configurations Apache SkyWalking - End-to-end testing of the Apache SkyWalking, and plugin tests of its subproject, Apache SkyWalking Python , and of its eco-system built by the community, like SkyAPM NodeJS Agent jOOQ - Integration testing all of jOOQ with a variety of RDBMS Trino (formerly Presto SQL) - Integration testing all Trino core & connectors, including tests of multi-node deployments and security configurations. Google - Various open source projects: OpenTelemetry , Universal Application Tool , CloudBowl Backbase - Unit, Integration and Acceptance testing for different the databases supported (Oracle, SQL Server, MySQL), the different messaging systems supported (Kafka, Rabbit, AMQ) and other microservices and HTTP mocks. CloudBees - Integration testing of products, including but not limited to database and AWS/Localstack integration testing. Jenkins - Integration testing of multiple plugins and the Trilead SSH2 fork maintained by the Jenkins community ( query ). Elastic - Integration testing of the Java APM agent Alkira - Testing of multiple micro-services using Kafka, PostgreSQL, Apache Zookeeper, Etcd and so on. Togglz - Feature Flags for the Java platform Byzer - Integration tests for Data and AI platforms are based on multiple versions of Byzer, Ray and Apache Spark. Apache SeaTunnel - Integration testing with different datasource. Bucket4j - Java rate-limiting library based on the token-bucket algorithm. Spark ClickHouse Connector - Integration tests for Apache Spark with both single node ClickHouse instance and multi-node ClickHouse cluster. Quarkus - Testcontainers is used extensively for Quarkus' DevServices feature. Apache Kyuubi - Integration testing with Trino as data source engine, Kafka, etc. Dash0 - Integration testing for OpenTelemetry Observability product. License See LICENSE . Attributions This project includes a modified class (ScriptUtils) taken from the Spring JDBC project, adapted under the terms of the Apache license. Copyright for that class remains with the original authors. This project was initially inspired by a gist by Moshe Eshel . Copyright Copyright (c) 2015-2021 Richard North and other authors. See AUTHORS for contributors.","title":"Home"},{"location":"#testcontainers-for-java","text":"Not using Java? Here are other supported languages! Java Go .NET Node.js Python Rust Haskell Ruby","title":"Testcontainers for Java"},{"location":"#about-testcontainers-for-java","text":"Testcontainers for Java is a Java library that supports JUnit tests, providing lightweight, throwaway instances of common databases, Selenium web browsers, or anything else that can run in a Docker container. Testcontainers make the following kinds of tests easier: Data access layer integration tests : use a containerized instance of a MySQL, PostgreSQL or Oracle database to test your data access layer code for complete compatibility, but without requiring complex setup on developers' machines and safe in the knowledge that your tests will always start with a known DB state. Any other database type that can be containerized can also be used. Application integration tests : for running your application in a short-lived test mode with dependencies, such as databases, message queues or web servers. UI/Acceptance tests : use containerized web browsers , compatible with Selenium, for conducting automated UI tests. Each test can get a fresh instance of the browser, with no browser state, plugin variations or automated browser upgrades to worry about. And you get a video recording of each test session, or just each session where tests failed. Much more! Check out the various contributed modules or create your own custom container classes using GenericContainer as a base.","title":"About Testcontainers for Java"},{"location":"#prerequisites","text":"Docker - please see General Docker requirements A supported JVM testing framework: JUnit 4 - See the JUnit 4 Quickstart Guide Jupiter/JUnit 5 Spock Or manually add code to control the container/test lifecycle (See hints for this approach )","title":"Prerequisites"},{"location":"#maven-dependencies","text":"Testcontainers is distributed as separate JARs with a common version number: A core JAR file for core functionality, generic containers and docker-compose support A separate JAR file for each of the specialised modules. Each module's documentation describes the Maven/Gradle dependency to add to your project's build. For the core library, the latest Maven/Gradle dependency is as follows: Gradle Maven testImplementation \"org.testcontainers:testcontainers:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> You can also check the latest version available on Maven Central .","title":"Maven dependencies"},{"location":"#managing-versions-for-multiple-testcontainers-dependencies","text":"To avoid specifying the version of each dependency, you can use a BOM or Bill Of Materials . Using Maven you can add the following to dependencyManagement section in your pom.xml : Maven <dependencyManagement> <dependencies> <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers-bom </artifactId> <version> 1.20.6 </version> <type> pom </type> <scope> import </scope> </dependency> </dependencies> </dependencyManagement> and then use dependencies without specifying a version: Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> mysql </artifactId> <scope> test </scope> </dependency> Using Gradle 5.0 or higher, you can add the following to the dependencies section in your build.gradle : Gradle implementation platform ( 'org.testcontainers:testcontainers-bom:1.20.6' ) //import bom testImplementation ( 'org.testcontainers:mysql' ) //no version specified JitPack builds are available for pre-release versions. Shaded dependencies Testcontainers depends on other libraries (like docker-java) for it to work. Some of them (JUnit, docker-java-{api,transport} and its transitive dependencies, JNA, visible-assertions and others) are part of our public API. But there are also \"private\", implementation detail dependencies (e.g., docker-java-core, Guava, OkHttp, etc.) that are not exposed to public API but prone to conflicts with test code/application under test code. As such, these libraries are 'shaded' into the core Testcontainers JAR and relocated under org.testcontainers.shaded to prevent class conflicts.","title":"Managing versions for multiple Testcontainers dependencies"},{"location":"#sponsors","text":"A huge thank you to our sponsors:","title":"Sponsors"},{"location":"#bronze-sponsors","text":"Cirrus CI Vivy jOOQ Backbase Elastic","title":"Bronze sponsors"},{"location":"#donors","text":"Red Hat Spotify","title":"Donors"},{"location":"#backers","text":"Philip Riecks (@rieckpil) Karl Heinz Marbaise (@khmarbaise) Sascha Frinken (@sascha-frinken) Christoph Dreis (@dreis2211) Nikita Zhevnitskiy (@zhenik) Bas Stoker (@bastoker) Oleg Nenashev (@oleg-nenashev) Rik Glover (@rikglover) Amitosh Swain Mahapatra (@recrsn) Paris Apostolopoulos","title":"Backers"},{"location":"#who-is-using-testcontainers","text":"ZeroTurnaround - Testing of the Java Agents, micro-services, Selenium browser automation Zipkin - MySQL and Cassandra testing Apache Gora - CouchDB testing Apache James - LDAP and Cassandra integration testing StreamSets - LDAP, MySQL Vault, MongoDB, Redis integration testing Playtika - Kafka, Couchbase, MariaDB, Redis, Neo4j, Aerospike, MemSQL JetBrains - Testing of the TeamCity plugin for HashiCorp Vault Plumbr - Integration testing of data processing pipeline micro-services Streamlio - Integration and Chaos Testing of our fast data platform based on Apache Pulsar, Apache BookKeeper and Apache Heron. Spring Session - Redis, PostgreSQL, MySQL and MariaDB integration testing Apache Camel - Testing Camel against native services such as Consul, Etcd and so on Infinispan - Testing the Infinispan Server as well as integration tests with databases, LDAP and KeyCloak Instana - Testing agents and stream processing backends eBay Marketing - Testing for MySQL, Cassandra, Redis, Couchbase, Kafka, etc. Skyscanner - Integration testing against HTTP service mocks and various data stores Neo4j-OGM - Testing with Neo4j Spring Data Neo4j - Testing imperative and reactive implementations with Neo4j Lightbend - Testing Alpakka Kafka and support in Alpakka Kafka Testkit Zalando SE - Testing core business services Europace AG - Integration testing for databases and micro services Micronaut Data - Testing of Micronaut Data JDBC, a database access toolkit Vert.x SQL Client - Testing with PostgreSQL, MySQL, MariaDB, SQL Server, etc. JHipster - Couchbase and Cassandra integration testing wescale - Integration testing against HTTP service mocks and various data stores Marquez - PostgreSQL integration testing Wise (formerly TransferWise) - Integration testing for different RDBMS, kafka and micro services XWiki - Testing XWiki under all supported configurations Apache SkyWalking - End-to-end testing of the Apache SkyWalking, and plugin tests of its subproject, Apache SkyWalking Python , and of its eco-system built by the community, like SkyAPM NodeJS Agent jOOQ - Integration testing all of jOOQ with a variety of RDBMS Trino (formerly Presto SQL) - Integration testing all Trino core & connectors, including tests of multi-node deployments and security configurations. Google - Various open source projects: OpenTelemetry , Universal Application Tool , CloudBowl Backbase - Unit, Integration and Acceptance testing for different the databases supported (Oracle, SQL Server, MySQL), the different messaging systems supported (Kafka, Rabbit, AMQ) and other microservices and HTTP mocks. CloudBees - Integration testing of products, including but not limited to database and AWS/Localstack integration testing. Jenkins - Integration testing of multiple plugins and the Trilead SSH2 fork maintained by the Jenkins community ( query ). Elastic - Integration testing of the Java APM agent Alkira - Testing of multiple micro-services using Kafka, PostgreSQL, Apache Zookeeper, Etcd and so on. Togglz - Feature Flags for the Java platform Byzer - Integration tests for Data and AI platforms are based on multiple versions of Byzer, Ray and Apache Spark. Apache SeaTunnel - Integration testing with different datasource. Bucket4j - Java rate-limiting library based on the token-bucket algorithm. Spark ClickHouse Connector - Integration tests for Apache Spark with both single node ClickHouse instance and multi-node ClickHouse cluster. Quarkus - Testcontainers is used extensively for Quarkus' DevServices feature. Apache Kyuubi - Integration testing with Trino as data source engine, Kafka, etc. Dash0 - Integration testing for OpenTelemetry Observability product.","title":"Who is using Testcontainers?"},{"location":"#license","text":"See LICENSE .","title":"License"},{"location":"#attributions","text":"This project includes a modified class (ScriptUtils) taken from the Spring JDBC project, adapted under the terms of the Apache license. Copyright for that class remains with the original authors. This project was initially inspired by a gist by Moshe Eshel .","title":"Attributions"},{"location":"#copyright","text":"Copyright (c) 2015-2021 Richard North and other authors. See AUTHORS for contributors.","title":"Copyright"},{"location":"bounty/","text":"Testcontainers issue bounty policy General We want to use issue bounties to encourage contributions in areas that are important to our sponsors, or tricky to solve. This includes bug fixes and new features. We hope that this will provide incentives to tackle issues, and gives sponsors a way to influence where development time is expended. We also want to reward our contributors, some of whom make huge efforts to improve Testcontainers and help their fellow developers! Note It's early days for our use of sponsorship, so we expect to evolve this policy over time, possibly without notice. In the event of any ambiguity or dispute, the Testcontainers org core maintainers have the final say. If you'd like to suggest an improvement to this policy, we'd be grateful for your input - please raise a pull request! For Sponsors Sponsors will be able to create a number of 'bounties' per month, varying according to sponsorship tier. As a sponsor, the process for creating a bounty is as follows: Raise an issue, or find an existing issue that describes the bug or feature. Start a discussion with the Testcontainers org core maintainers to agree that the issue is suitable for a bounty, and how much the reward amount should be. Once agreed, we will assign a label to the issue so that interested developers can find it. Sponsors can create up to 1 or 3 bounties (according to tier) per calendar month - i.e. the counter resets on the 1st of each month. If a sponsor does not use their full quota of bounty credits in a calendar month, they cannot be rolled over to the next month. Bounties will expire 90 days after creation - after this time, if they have not been resolved we will close them. For Contributors As a contributor, the process for working on an issue with a bounty attached is: Find an issue with a bounty attached to it and no assignee, clarify the requirements if necessary, and consider how you would approach working on it. Start a discussion with the Testcontainers org core maintainers and the bounty owner. To avoid unpleasant surprises at review time, we'll try to confirm that we're happy with your proposed solution. If we're happy with your proposed solution, we will assign the ticket to you. Once work is complete, we will go through the PR process as usual and merge the work when finished. To receive the bounty reward, raise an invoice on Open Collective, following the expenses policy on that page. Note that a 20% cut of the bounty amount will normally be assigned to project maintainers for PR review work. We believe this reflects that PR review can often be a significant amount of work for some issues - and also gives maintainers an incentive to complete the review and unlock the bounty reward! Some pull requests are so well done that very little review is necessary. If that happens, the maintainers may choose not to take a cut of the bounty, and instead release the full amount to the contributor. Organisation core maintainers The organisation core maintainers are: Richard North (@rnorth) Sergei Egorov (@bsideup) Kevin Wittek (@kiview)","title":"Testcontainers issue bounty policy"},{"location":"bounty/#testcontainers-issue-bounty-policy","text":"","title":"Testcontainers issue bounty policy"},{"location":"bounty/#general","text":"We want to use issue bounties to encourage contributions in areas that are important to our sponsors, or tricky to solve. This includes bug fixes and new features. We hope that this will provide incentives to tackle issues, and gives sponsors a way to influence where development time is expended. We also want to reward our contributors, some of whom make huge efforts to improve Testcontainers and help their fellow developers! Note It's early days for our use of sponsorship, so we expect to evolve this policy over time, possibly without notice. In the event of any ambiguity or dispute, the Testcontainers org core maintainers have the final say. If you'd like to suggest an improvement to this policy, we'd be grateful for your input - please raise a pull request!","title":"General"},{"location":"bounty/#for-sponsors","text":"Sponsors will be able to create a number of 'bounties' per month, varying according to sponsorship tier. As a sponsor, the process for creating a bounty is as follows: Raise an issue, or find an existing issue that describes the bug or feature. Start a discussion with the Testcontainers org core maintainers to agree that the issue is suitable for a bounty, and how much the reward amount should be. Once agreed, we will assign a label to the issue so that interested developers can find it. Sponsors can create up to 1 or 3 bounties (according to tier) per calendar month - i.e. the counter resets on the 1st of each month. If a sponsor does not use their full quota of bounty credits in a calendar month, they cannot be rolled over to the next month. Bounties will expire 90 days after creation - after this time, if they have not been resolved we will close them.","title":"For Sponsors"},{"location":"bounty/#for-contributors","text":"As a contributor, the process for working on an issue with a bounty attached is: Find an issue with a bounty attached to it and no assignee, clarify the requirements if necessary, and consider how you would approach working on it. Start a discussion with the Testcontainers org core maintainers and the bounty owner. To avoid unpleasant surprises at review time, we'll try to confirm that we're happy with your proposed solution. If we're happy with your proposed solution, we will assign the ticket to you. Once work is complete, we will go through the PR process as usual and merge the work when finished. To receive the bounty reward, raise an invoice on Open Collective, following the expenses policy on that page. Note that a 20% cut of the bounty amount will normally be assigned to project maintainers for PR review work. We believe this reflects that PR review can often be a significant amount of work for some issues - and also gives maintainers an incentive to complete the review and unlock the bounty reward! Some pull requests are so well done that very little review is necessary. If that happens, the maintainers may choose not to take a cut of the bounty, and instead release the full amount to the contributor.","title":"For Contributors"},{"location":"bounty/#organisation-core-maintainers","text":"The organisation core maintainers are: Richard North (@rnorth) Sergei Egorov (@bsideup) Kevin Wittek (@kiview)","title":"Organisation core maintainers"},{"location":"contributing/","text":"Contributing Star the project on GitHub and help spread the word :) Join our Slack workspace Start a discussion if you have an idea, find a possible bug or have a general question. Contribute improvements or fixes using a Pull Request . If you're going to contribute, thank you! Please just be sure to: discuss with the authors prior to doing anything big. follow the style, naming and structure conventions of the rest of the project. make commits atomic and easy to merge. when updating documentation, please see our guidance for documentation contributions . apply format running ./gradlew spotlessApply (this requires Node.js to be installed on your machine, one of the package managers might be handy) verify all tests are passing. Build the project with ./gradlew check to do this. N.B. Gradle's Build Cache is enabled by default, but you can add --no-build-cache flag to disable it. Contributing new modules We often receive proposals (or fully formed PRs) for new modules. We're very happy to have contributions, but new modules require specific extra care. We want to balance: Usefulness of the module. Our ability to support the module in the future, potentially after contributors have moved on. Contributors time, so that nobody puts in wasted effort. Does it need to be a module? N.B. this is not a perfect list - please always reach out to us before starting on a module contribution! Does the module enable use of Testcontainers with a popular or rapidly growing technology? Does the module 'add value' beyond a GenericContainer code snippet/example? e.g. does it neatly encapsulate a difficult problem of running the program in a container? does it add technology-specific wait strategies ? does it enable straightforward usage of client libraries? If the answers to the above are all yes, then a new module may be a good approach. Otherwise, it is entirely possible for you to: publish a code snippet contribute an example to the Testcontainers repo publish your own third party library In any case, please contact us to help validate your proposal! Checklist Suggestion: copy and paste this list into PRs for new modules. Every item on this list will require judgement by the Testcontainers core maintainers. Exceptions will sometimes be possible; items with should are more likely to be negotiable than those items with must . Default docker image [ ] Should be a Docker Hub official image, or published by a reputable source (ideally the company or organisation that officially supports the technology) [ ] Should have a verifiable open source Dockerfile and a way to view the history of changes [ ] MUST show general good practices regarding container image tagging - e.g. we do not use latest tags, and we do not use tags that may be mutated in the future [ ] MUST be legal for Testcontainers developers and Testcontainers users to pull and use. Mechanisms exist to allow EULA acceptance to be signalled, but images that can be used without a licence are greatly preferred. Module dependencies [ ] The module should use as few dependencies as possible, [ ] Regarding libraries, either: they should be compileOnly if they are likely to already be on the classpath for users' tests (e.g. client libraries or drivers) they can be implementation (and thus transitive dependencies) if they are very unlikely to conflict with users' dependencies. [ ] If client libraries are used to test or use the module, these MUST be legal for Testcontainers developers and Testcontainers users to download and use. API (e.g. MyModuleContainer class) [ ] Favour doing the right thing, and least surprising thing, by default [ ] Ensure that method and parameter names are easy to understand. Many users will ignore documentation, so IDE-based substitutes (autocompletion and Javadocs) should be intuitive. [ ] The module's public API should only handle standard JDK data types and MUST not expose data types that come from compileOnly dependencies. This is to reduce the risk of compatibility problems with future versions of third party libraries. Documentation [ ] Every module MUST have a dedicated documentation page containing: [ ] A high level overview [ ] A usage example [ ] If appropriate, basic API documentation or further usage guidelines [ ] Dependency information [ ] Acknowledgements, if appropriate [ ] Consider that many users will not read the documentation pages - even if the first person to add it to a project does, people reading/updating the code in the future may not. Try and avoid the need for critical knowledge that is only present in documentation. Incubating modules We have a policy of marking new modules as 'incubating' so that we can evaluate its maintainability and usability traits over a longer period of time. We currently believe 3 months is a fair period of time, but may change this. New modules should have the following warning at the top of their documentation pages: Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. We will evaluate incubating modules periodically, and remove the label when appropriate. Combining Dependabot PRs Since we generally get a lot of Dependabot PRs, we regularly combine them into single commits. For this, we are using the gh-combine-prs extension for GitHub CLI . The whole process is as follows: Check that all open Dependabot PRs did succeed their build. If they did not succeed, trigger a rerun if the cause were external factors or else document the reason if obvious. Run the extension from an up-to-date local main branch: gh combine-prs --query \"author:app/dependabot\" Merge conflicts might appear. Just ignore them, we will get those PRs in a future run. Once the build of the combined PR did succeed, temporarily enable merge commits and merge the PR using a merge commit through the GitHub UI. After the merge, disable merge commits again.","title":"Contributing"},{"location":"contributing/#contributing","text":"Star the project on GitHub and help spread the word :) Join our Slack workspace Start a discussion if you have an idea, find a possible bug or have a general question. Contribute improvements or fixes using a Pull Request . If you're going to contribute, thank you! Please just be sure to: discuss with the authors prior to doing anything big. follow the style, naming and structure conventions of the rest of the project. make commits atomic and easy to merge. when updating documentation, please see our guidance for documentation contributions . apply format running ./gradlew spotlessApply (this requires Node.js to be installed on your machine, one of the package managers might be handy) verify all tests are passing. Build the project with ./gradlew check to do this. N.B. Gradle's Build Cache is enabled by default, but you can add --no-build-cache flag to disable it.","title":"Contributing"},{"location":"contributing/#contributing-new-modules","text":"We often receive proposals (or fully formed PRs) for new modules. We're very happy to have contributions, but new modules require specific extra care. We want to balance: Usefulness of the module. Our ability to support the module in the future, potentially after contributors have moved on. Contributors time, so that nobody puts in wasted effort.","title":"Contributing new modules"},{"location":"contributing/#does-it-need-to-be-a-module","text":"N.B. this is not a perfect list - please always reach out to us before starting on a module contribution! Does the module enable use of Testcontainers with a popular or rapidly growing technology? Does the module 'add value' beyond a GenericContainer code snippet/example? e.g. does it neatly encapsulate a difficult problem of running the program in a container? does it add technology-specific wait strategies ? does it enable straightforward usage of client libraries? If the answers to the above are all yes, then a new module may be a good approach. Otherwise, it is entirely possible for you to: publish a code snippet contribute an example to the Testcontainers repo publish your own third party library In any case, please contact us to help validate your proposal!","title":"Does it need to be a module?"},{"location":"contributing/#checklist","text":"Suggestion: copy and paste this list into PRs for new modules. Every item on this list will require judgement by the Testcontainers core maintainers. Exceptions will sometimes be possible; items with should are more likely to be negotiable than those items with must .","title":"Checklist"},{"location":"contributing/#default-docker-image","text":"[ ] Should be a Docker Hub official image, or published by a reputable source (ideally the company or organisation that officially supports the technology) [ ] Should have a verifiable open source Dockerfile and a way to view the history of changes [ ] MUST show general good practices regarding container image tagging - e.g. we do not use latest tags, and we do not use tags that may be mutated in the future [ ] MUST be legal for Testcontainers developers and Testcontainers users to pull and use. Mechanisms exist to allow EULA acceptance to be signalled, but images that can be used without a licence are greatly preferred.","title":"Default docker image"},{"location":"contributing/#module-dependencies","text":"[ ] The module should use as few dependencies as possible, [ ] Regarding libraries, either: they should be compileOnly if they are likely to already be on the classpath for users' tests (e.g. client libraries or drivers) they can be implementation (and thus transitive dependencies) if they are very unlikely to conflict with users' dependencies. [ ] If client libraries are used to test or use the module, these MUST be legal for Testcontainers developers and Testcontainers users to download and use.","title":"Module dependencies"},{"location":"contributing/#api-eg-mymodulecontainer-class","text":"[ ] Favour doing the right thing, and least surprising thing, by default [ ] Ensure that method and parameter names are easy to understand. Many users will ignore documentation, so IDE-based substitutes (autocompletion and Javadocs) should be intuitive. [ ] The module's public API should only handle standard JDK data types and MUST not expose data types that come from compileOnly dependencies. This is to reduce the risk of compatibility problems with future versions of third party libraries.","title":"API (e.g. MyModuleContainer class)"},{"location":"contributing/#documentation","text":"[ ] Every module MUST have a dedicated documentation page containing: [ ] A high level overview [ ] A usage example [ ] If appropriate, basic API documentation or further usage guidelines [ ] Dependency information [ ] Acknowledgements, if appropriate [ ] Consider that many users will not read the documentation pages - even if the first person to add it to a project does, people reading/updating the code in the future may not. Try and avoid the need for critical knowledge that is only present in documentation.","title":"Documentation"},{"location":"contributing/#incubating-modules","text":"We have a policy of marking new modules as 'incubating' so that we can evaluate its maintainability and usability traits over a longer period of time. We currently believe 3 months is a fair period of time, but may change this. New modules should have the following warning at the top of their documentation pages: Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. We will evaluate incubating modules periodically, and remove the label when appropriate.","title":"Incubating modules"},{"location":"contributing/#combining-dependabot-prs","text":"Since we generally get a lot of Dependabot PRs, we regularly combine them into single commits. For this, we are using the gh-combine-prs extension for GitHub CLI . The whole process is as follows: Check that all open Dependabot PRs did succeed their build. If they did not succeed, trigger a rerun if the cause were external factors or else document the reason if obvious. Run the extension from an up-to-date local main branch: gh combine-prs --query \"author:app/dependabot\" Merge conflicts might appear. Just ignore them, we will get those PRs in a future run. Once the build of the combined PR did succeed, temporarily enable merge commits and merge the PR using a merge commit through the GitHub UI. After the merge, disable merge commits again.","title":"Combining Dependabot PRs"},{"location":"contributing_docs/","text":"Contributing to documentation The Testcontainers for Java documentation is a static site built with MkDocs . We use the Material for MkDocs theme, which offers a number of useful extensions to MkDocs. In addition we use a custom plugin for inclusion of code snippets. We publish our documentation using Netlify. Previewing rendered content Using Docker locally The root of the project contains a docker-compose.yml file. Simply run docker-compose up and then access the docs at http://localhost:8000 . Using Python locally Ensure that you have Python 3.8.0 or higher. Set up a virtualenv and run pip install -r requirements.txt in the testcontainers-java root directory. Once Python dependencies have been installed, run mkdocs serve to start a local auto-updating MkDocs server. PR Preview deployments Note that documentation for pull requests will automatically be published by Netlify as 'deploy previews'. These deployment previews can be accessed via the deploy/netlify check that appears for each pull request. Codeincludes The Gradle project under docs/examples is intended to hold compilable, runnable example code that can be included as snippets into the documentation at build-time. As a result, we can have more confidence that code samples shown in the documentation is valid. We use a custom plugin for MkDocs to include snippets into our docs. A codeinclude block will resemble a regular markdown link surrounded by a pair of XML comments, e.g.: <!--codeinclude--> [Human readable title for snippet](./relative_path_to_example_code.java) targeting_expression <!--/codeinclude--> Where targeting_expression could be: block:someString or inside_block:someString If these are provided, the macro will seek out any line containing the token someString and grab the next curly brace delimited block that it finds. block will grab the starting line and closing brace, whereas inside_block will omit these. e.g., given: public class FooService { public void doFoo () { foo . doSomething (); } ... If we use block:doFoo as our targeting expression, we will have the following content included into our page: public void doFoo () { foo . doSomething (); } Whereas using inside_block:doFoo we would just have the inner content of the method included: foo . doSomething (); Note that: Any code included will have its indentation reduced Every line in the source file will be searched for an instance of the token (e.g. doFoo ). If more than one line includes that token, then potentially more than one block could be targeted for inclusion. It is advisable to use a specific, unique token to avoid unexpected behaviour. When we wish to include a section of code that does not naturally appear within braces, we can simply insert our token, with matching braces, in a comment. While a little ugly, this has the benefit of working in any context and is easy to understand. For example: public class FooService { public void boringMethod () { doSomethingBoring (); // doFoo { doTheThingThatWeActuallyWantToShow (); // } }","title":"Contributing to documentation"},{"location":"contributing_docs/#contributing-to-documentation","text":"The Testcontainers for Java documentation is a static site built with MkDocs . We use the Material for MkDocs theme, which offers a number of useful extensions to MkDocs. In addition we use a custom plugin for inclusion of code snippets. We publish our documentation using Netlify.","title":"Contributing to documentation"},{"location":"contributing_docs/#previewing-rendered-content","text":"","title":"Previewing rendered content"},{"location":"contributing_docs/#using-docker-locally","text":"The root of the project contains a docker-compose.yml file. Simply run docker-compose up and then access the docs at http://localhost:8000 .","title":"Using Docker locally"},{"location":"contributing_docs/#using-python-locally","text":"Ensure that you have Python 3.8.0 or higher. Set up a virtualenv and run pip install -r requirements.txt in the testcontainers-java root directory. Once Python dependencies have been installed, run mkdocs serve to start a local auto-updating MkDocs server.","title":"Using Python locally"},{"location":"contributing_docs/#pr-preview-deployments","text":"Note that documentation for pull requests will automatically be published by Netlify as 'deploy previews'. These deployment previews can be accessed via the deploy/netlify check that appears for each pull request.","title":"PR Preview deployments"},{"location":"contributing_docs/#codeincludes","text":"The Gradle project under docs/examples is intended to hold compilable, runnable example code that can be included as snippets into the documentation at build-time. As a result, we can have more confidence that code samples shown in the documentation is valid. We use a custom plugin for MkDocs to include snippets into our docs. A codeinclude block will resemble a regular markdown link surrounded by a pair of XML comments, e.g.: <!--codeinclude--> [Human readable title for snippet](./relative_path_to_example_code.java) targeting_expression <!--/codeinclude--> Where targeting_expression could be: block:someString or inside_block:someString If these are provided, the macro will seek out any line containing the token someString and grab the next curly brace delimited block that it finds. block will grab the starting line and closing brace, whereas inside_block will omit these. e.g., given: public class FooService { public void doFoo () { foo . doSomething (); } ... If we use block:doFoo as our targeting expression, we will have the following content included into our page: public void doFoo () { foo . doSomething (); } Whereas using inside_block:doFoo we would just have the inner content of the method included: foo . doSomething (); Note that: Any code included will have its indentation reduced Every line in the source file will be searched for an instance of the token (e.g. doFoo ). If more than one line includes that token, then potentially more than one block could be targeted for inclusion. It is advisable to use a specific, unique token to avoid unexpected behaviour. When we wish to include a section of code that does not naturally appear within braces, we can simply insert our token, with matching braces, in a comment. While a little ugly, this has the benefit of working in any context and is easy to understand. For example: public class FooService { public void boringMethod () { doSomethingBoring (); // doFoo { doTheThingThatWeActuallyWantToShow (); // } }","title":"Codeincludes"},{"location":"error_missing_container_runtime_environment/","text":"Fixing Issues with Discovering A Supported Container Runtime Environment If you ended up on this page, it seems that either Testcontainers was not able to find a supported container runtime in your environment, or you found this page while searching for information to deal with errors regarding the environment discovery mechanism of Testcontainers. Testcontainers requires a supported container runtime environment to be present in order to manage and run containers. Here is a list of supported container runtime environments: Docker Desktop Docker Engine on Linux Testcontainers Cloud For more extensive information on supported container runtime environments, as well as known limitations of alternative container runtime environments, please refer to this page in our documentation.","title":"Fixing Issues with Discovering A Supported Container Runtime Environment"},{"location":"error_missing_container_runtime_environment/#fixing-issues-with-discovering-a-supported-container-runtime-environment","text":"If you ended up on this page, it seems that either Testcontainers was not able to find a supported container runtime in your environment, or you found this page while searching for information to deal with errors regarding the environment discovery mechanism of Testcontainers. Testcontainers requires a supported container runtime environment to be present in order to manage and run containers. Here is a list of supported container runtime environments: Docker Desktop Docker Engine on Linux Testcontainers Cloud For more extensive information on supported container runtime environments, as well as known limitations of alternative container runtime environments, please refer to this page in our documentation.","title":"Fixing Issues with Discovering A Supported Container Runtime Environment"},{"location":"examples/","text":"Examples Examples of different use cases provided by Testcontainers can be found below: Hazelcast Kafka Cluster with multiple brokers Neo4j Redis Selenium Selenium Module with Cucumber Singleton Container Pattern Solr Spring Boot Spring Boot with Kotlin TestNG ImmuDb Zookeeper NATS SFTP","title":"Examples"},{"location":"examples/#examples","text":"Examples of different use cases provided by Testcontainers can be found below: Hazelcast Kafka Cluster with multiple brokers Neo4j Redis Selenium Selenium Module with Cucumber Singleton Container Pattern Solr Spring Boot Spring Boot with Kotlin TestNG ImmuDb Zookeeper NATS SFTP","title":"Examples"},{"location":"getting_help/","text":"Getting help We hope that you find Testcontainers intuitive to use and reliable. However, sometimes things don't go the way we'd expect, and we'd like to try and help out if we can. To contact the Testcontainers team and other users you can: Join our Slack team Search our issues tracker , or raise a new issue if you find any bugs or have suggested improvements Search Stack Overflow , especially among posts tagged with testcontainers","title":"Getting help"},{"location":"getting_help/#getting-help","text":"We hope that you find Testcontainers intuitive to use and reliable. However, sometimes things don't go the way we'd expect, and we'd like to try and help out if we can. To contact the Testcontainers team and other users you can: Join our Slack team Search our issues tracker , or raise a new issue if you find any bugs or have suggested improvements Search Stack Overflow , especially among posts tagged with testcontainers","title":"Getting help"},{"location":"jitpack_dependencies/","text":"JitPack (unreleased versions) If you like to live on the bleeding edge, jitpack.io can be used to obtain SNAPSHOT versions. Use the following dependency description instead: Gradle Maven testImplementation \"com.github.testcontainers.testcontainers-java:--artifact name--:main-SNAPSHOT\" <dependency> <groupId> com.github.testcontainers.testcontainers-java </groupId> <artifactId> --artifact name-- </artifactId> <version> main-SNAPSHOT </version> </dependency> A specific git revision (such as 02782d9 ) can be used as a fixed version instead: Gradle Maven testImplementation \"com.github.testcontainers.testcontainers-java:--artifact name--:02782d9\" <dependency> <groupId> com.github.testcontainers.testcontainers-java </groupId> <artifactId> --artifact name-- </artifactId> <version> 02782d9 </version> </dependency> The JitPack maven repository must also be declared, e.g.: Gradle Maven repositories { maven { url \"https://jitpack.io\" } } <repositories> <repository> <id> jitpack.io </id> <url> https://jitpack.io </url> </repository> </repositories>","title":"JitPack (unreleased versions)"},{"location":"jitpack_dependencies/#jitpack-unreleased-versions","text":"If you like to live on the bleeding edge, jitpack.io can be used to obtain SNAPSHOT versions. Use the following dependency description instead: Gradle Maven testImplementation \"com.github.testcontainers.testcontainers-java:--artifact name--:main-SNAPSHOT\" <dependency> <groupId> com.github.testcontainers.testcontainers-java </groupId> <artifactId> --artifact name-- </artifactId> <version> main-SNAPSHOT </version> </dependency> A specific git revision (such as 02782d9 ) can be used as a fixed version instead: Gradle Maven testImplementation \"com.github.testcontainers.testcontainers-java:--artifact name--:02782d9\" <dependency> <groupId> com.github.testcontainers.testcontainers-java </groupId> <artifactId> --artifact name-- </artifactId> <version> 02782d9 </version> </dependency> The JitPack maven repository must also be declared, e.g.: Gradle Maven repositories { maven { url \"https://jitpack.io\" } } <repositories> <repository> <id> jitpack.io </id> <url> https://jitpack.io </url> </repository> </repositories>","title":"JitPack (unreleased versions)"},{"location":"features/advanced_options/","text":"Advanced options Container labels To add a custom label to the container, use withLabel : Adding a single label public GenericContainer containerWithLabel = new GenericContainer ( DockerImageName . parse ( \"alpine:3.17\" )) . withLabel ( \"key\" , \"value\" ); Additionally, multiple labels may be applied together from a map: Adding multiple labels private Map < String , String > mapOfLabels = new HashMap <> (); // populate map, e.g. mapOfLabels.put(\"key1\", \"value1\"); public GenericContainer containerWithMultipleLabels = new GenericContainer ( DockerImageName . parse ( \"alpine:3.17\" )) . withLabels ( mapOfLabels ); Image Pull Policy By default, the container image is retrieved from the local Docker images cache. This works well when running against a specific version, but for images with a static tag (i.e. 'latest') this may lead to a newer version not being pulled. It is possible to specify an Image Pull Policy to determine at runtime whether an image should be pulled or not: Setting image pull policy GenericContainer <?> container = new GenericContainer <> ( imageName ) . withImagePullPolicy ( PullPolicy . alwaysPull ()) ... or providing a function: Custom image pull policy GenericContainer <?> container = new GenericContainer <> ( imageName ) . withImagePullPolicy ( new AbstractImagePullPolicy () { @Override protected boolean shouldPullCached ( DockerImageName imageName , ImageData localImageData ) { return System . getenv ( \"ALWAYS_PULL_IMAGE\" ) != null ; } } ) You can also configure Testcontainers to use your custom implementation by using pull.policy src/test/resources/testcontainers.properties pull.policy=com.mycompany.testcontainers.ExampleImagePullPolicy Please see the documentation on configuration mechanisms for more information. Customizing the container Using docker-java It is possible to use the docker-java API directly to customize containers before creation. This is useful if there is a need to use advanced Docker features that are not exposed by the Testcontainers API. Any customizations you make using withCreateContainerCmdModifier will be applied on top of the container definition that Testcontainers creates, but before it is created. For example, this can be used to change the container hostname: Using modifier to change hostname @Rule public GenericContainer theCache = new GenericContainer <> ( DockerImageName . parse ( \"redis:6-alpine\" )) . withCreateContainerCmdModifier ( cmd -> cmd . withHostName ( \"the-cache\" )); ... or modify container memory (see this if it does not appear to work): Using modifier to change memory limits private long memoryInBytes = 32l * 1024l * 1024l ; private long memorySwapInBytes = 64l * 1024l * 1024l ; @Rule public GenericContainer memoryLimitedRedis = new GenericContainer <> ( DockerImageName . parse ( \"redis:6-alpine\" )) . withCreateContainerCmdModifier ( cmd -> { cmd . getHostConfig () . withMemory ( memoryInBytes ) . withMemorySwap ( memorySwapInBytes ); }); Note It is recommended to use this sparingly, and follow changes to the docker-java API if you choose to use this. It is typically quite stable, though. For what is possible, consult the docker-java CreateContainerCmd source code . Using CreateContainerCmdModifier Testcontainers provides a CreateContainerCmdModifier to customize docker-java CreateContainerCmd via Service Provider Interface (SPI) mechanism. CreateContainerCmd example implementation package org.testcontainers.custom ; import com.github.dockerjava.api.command.CreateContainerCmd ; import org.testcontainers.core.CreateContainerCmdModifier ; import java.util.HashMap ; import java.util.Map ; public class TestCreateContainerCmdModifier implements CreateContainerCmdModifier { @Override public CreateContainerCmd modify ( CreateContainerCmd createContainerCmd ) { Map < String , String > labels = new HashMap <> (); labels . put ( \"project\" , \"testcontainers-java\" ); labels . put ( \"scope\" , \"global\" ); createContainerCmd . getLabels (). putAll ( labels ); return createContainerCmd ; } } The previous implementation should be registered in META-INF/services/org.testcontainers.core.CreateContainerCmdModifier file. Warning CreateContainerCmdModifier implementation will apply to all containers created by Testcontainers. Parallel Container Startup Usually, containers are started sequentially when more than one container is used. Using Startables.deepStart(container1, container2, ...).join() will start all containers in parallel. This can be advantageous to reduce the impact of the container startup overhead.","title":"Advanced options"},{"location":"features/advanced_options/#advanced-options","text":"","title":"Advanced options"},{"location":"features/advanced_options/#container-labels","text":"To add a custom label to the container, use withLabel : Adding a single label public GenericContainer containerWithLabel = new GenericContainer ( DockerImageName . parse ( \"alpine:3.17\" )) . withLabel ( \"key\" , \"value\" ); Additionally, multiple labels may be applied together from a map: Adding multiple labels private Map < String , String > mapOfLabels = new HashMap <> (); // populate map, e.g. mapOfLabels.put(\"key1\", \"value1\"); public GenericContainer containerWithMultipleLabels = new GenericContainer ( DockerImageName . parse ( \"alpine:3.17\" )) . withLabels ( mapOfLabels );","title":"Container labels"},{"location":"features/advanced_options/#image-pull-policy","text":"By default, the container image is retrieved from the local Docker images cache. This works well when running against a specific version, but for images with a static tag (i.e. 'latest') this may lead to a newer version not being pulled. It is possible to specify an Image Pull Policy to determine at runtime whether an image should be pulled or not: Setting image pull policy GenericContainer <?> container = new GenericContainer <> ( imageName ) . withImagePullPolicy ( PullPolicy . alwaysPull ()) ... or providing a function: Custom image pull policy GenericContainer <?> container = new GenericContainer <> ( imageName ) . withImagePullPolicy ( new AbstractImagePullPolicy () { @Override protected boolean shouldPullCached ( DockerImageName imageName , ImageData localImageData ) { return System . getenv ( \"ALWAYS_PULL_IMAGE\" ) != null ; } } ) You can also configure Testcontainers to use your custom implementation by using pull.policy src/test/resources/testcontainers.properties pull.policy=com.mycompany.testcontainers.ExampleImagePullPolicy Please see the documentation on configuration mechanisms for more information.","title":"Image Pull Policy"},{"location":"features/advanced_options/#customizing-the-container","text":"","title":"Customizing the container"},{"location":"features/advanced_options/#using-docker-java","text":"It is possible to use the docker-java API directly to customize containers before creation. This is useful if there is a need to use advanced Docker features that are not exposed by the Testcontainers API. Any customizations you make using withCreateContainerCmdModifier will be applied on top of the container definition that Testcontainers creates, but before it is created. For example, this can be used to change the container hostname: Using modifier to change hostname @Rule public GenericContainer theCache = new GenericContainer <> ( DockerImageName . parse ( \"redis:6-alpine\" )) . withCreateContainerCmdModifier ( cmd -> cmd . withHostName ( \"the-cache\" )); ... or modify container memory (see this if it does not appear to work): Using modifier to change memory limits private long memoryInBytes = 32l * 1024l * 1024l ; private long memorySwapInBytes = 64l * 1024l * 1024l ; @Rule public GenericContainer memoryLimitedRedis = new GenericContainer <> ( DockerImageName . parse ( \"redis:6-alpine\" )) . withCreateContainerCmdModifier ( cmd -> { cmd . getHostConfig () . withMemory ( memoryInBytes ) . withMemorySwap ( memorySwapInBytes ); }); Note It is recommended to use this sparingly, and follow changes to the docker-java API if you choose to use this. It is typically quite stable, though. For what is possible, consult the docker-java CreateContainerCmd source code .","title":"Using docker-java"},{"location":"features/advanced_options/#using-createcontainercmdmodifier","text":"Testcontainers provides a CreateContainerCmdModifier to customize docker-java CreateContainerCmd via Service Provider Interface (SPI) mechanism. CreateContainerCmd example implementation package org.testcontainers.custom ; import com.github.dockerjava.api.command.CreateContainerCmd ; import org.testcontainers.core.CreateContainerCmdModifier ; import java.util.HashMap ; import java.util.Map ; public class TestCreateContainerCmdModifier implements CreateContainerCmdModifier { @Override public CreateContainerCmd modify ( CreateContainerCmd createContainerCmd ) { Map < String , String > labels = new HashMap <> (); labels . put ( \"project\" , \"testcontainers-java\" ); labels . put ( \"scope\" , \"global\" ); createContainerCmd . getLabels (). putAll ( labels ); return createContainerCmd ; } } The previous implementation should be registered in META-INF/services/org.testcontainers.core.CreateContainerCmdModifier file. Warning CreateContainerCmdModifier implementation will apply to all containers created by Testcontainers.","title":"Using CreateContainerCmdModifier"},{"location":"features/advanced_options/#parallel-container-startup","text":"Usually, containers are started sequentially when more than one container is used. Using Startables.deepStart(container1, container2, ...).join() will start all containers in parallel. This can be advantageous to reduce the impact of the container startup overhead.","title":"Parallel Container Startup"},{"location":"features/commands/","text":"Executing commands Container startup command By default the container will execute whatever command is specified in the image's Dockerfile. To override this, and specify a different command, use withCommand . For example: Specifying a startup command public GenericContainer redisWithCustomPort = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withCommand ( \"redis-server --port 7777\" ) Executing a command Your test can execute a command inside a running container, similar to a docker exec call: Executing a command inside a running container container . execInContainer ( \"touch\" , \"/somefile.txt\" ); This can be useful for software that has a command line administration tool. You can also get the output (stdout/stderr) and exit code from the command - for example: Executing a command inside a running container and reading the result Container . ExecResult lsResult = container . execInContainer ( \"ls\" , \"-al\" , \"/\" ); String stdout = lsResult . getStdout (); int exitCode = lsResult . getExitCode (); assertThat ( stdout ). contains ( \"somefile.txt\" ); assertThat ( exitCode ). isZero (); Environment variables To add environment variables to the container, use withEnv : new GenericContainer (...) . withEnv ( \"API_TOKEN\" , \"foo\" )","title":"Executing commands"},{"location":"features/commands/#executing-commands","text":"","title":"Executing commands"},{"location":"features/commands/#container-startup-command","text":"By default the container will execute whatever command is specified in the image's Dockerfile. To override this, and specify a different command, use withCommand . For example: Specifying a startup command public GenericContainer redisWithCustomPort = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withCommand ( \"redis-server --port 7777\" )","title":"Container startup command"},{"location":"features/commands/#executing-a-command","text":"Your test can execute a command inside a running container, similar to a docker exec call: Executing a command inside a running container container . execInContainer ( \"touch\" , \"/somefile.txt\" ); This can be useful for software that has a command line administration tool. You can also get the output (stdout/stderr) and exit code from the command - for example: Executing a command inside a running container and reading the result Container . ExecResult lsResult = container . execInContainer ( \"ls\" , \"-al\" , \"/\" ); String stdout = lsResult . getStdout (); int exitCode = lsResult . getExitCode (); assertThat ( stdout ). contains ( \"somefile.txt\" ); assertThat ( exitCode ). isZero ();","title":"Executing a command"},{"location":"features/commands/#environment-variables","text":"To add environment variables to the container, use withEnv : new GenericContainer (...) . withEnv ( \"API_TOKEN\" , \"foo\" )","title":"Environment variables"},{"location":"features/configuration/","text":"Custom configuration You can override some default properties if your environment requires that. Configuration locations The configuration will be loaded from multiple locations. Properties are considered in the following order: Environment variables .testcontainers.properties in user's home folder. Example locations: Linux: /home/myuser/.testcontainers.properties Windows: C:/Users/myuser/.testcontainers.properties macOS: /Users/myuser/.testcontainers.properties testcontainers.properties on the classpath. Note that when using environment variables, configuration property names should be set in upper case with underscore separators, preceded by TESTCONTAINERS_ - e.g. checks.disable becomes TESTCONTAINERS_CHECKS_DISABLE . The classpath testcontainers.properties file may exist within the local codebase (e.g. within the src/test/resources directory) or within library dependencies that you may have. Any such configuration files will have their contents merged. If any keys conflict, the value will be taken on the basis of the first value found in: 'local' classpath (i.e. where the URL of the file on the classpath begins with file: ), then other classpath locations (i.e. JAR files) - considered in alphabetical order of path to provide deterministic ordering. Disabling the startup checks checks.disable = [true|false] Before running any containers Testcontainers will perform a set of startup checks to ensure that your environment is configured correctly. Usually they look like this: \u2139\ufe0e Checking the system... \u2714 Docker version should be at least 1.6.0 \u2714 File should be mountable \u2714 A port exposed by a docker container should be accessible It takes a couple of seconds, but if you want to speed up your tests, you can disable the checks once you have everything configured. Add checks.disable=true to your $HOME/.testcontainers.properties to completely disable them. Customizing images Note This approach is discouraged and deprecated, but is documented for completeness. Overriding individual image names via configuration may be removed in 2021. See Image Name Substitution for other strategies for substituting image names to pull from other registries. Testcontainers uses public Docker images to perform different actions like startup checks, VNC recording and others. Some companies disallow the usage of Docker Hub, but you can override *.image properties with your own images from your private registry to workaround that. ryuk.container.image = testcontainers/ryuk:0.3.3 Performs fail-safe cleanup of containers, and always required (unless Ryuk is disabled ) tinyimage.container.image = alpine:3.17 Used to check whether images can be pulled at startup, and always required (unless startup checks are disabled ) sshd.container.image = testcontainers/sshd:1.1.0 Required if exposing host ports to containers vncrecorder.container.image = testcontainers/vnc-recorder:1.3.0 Used by VNC recorder in Testcontainers' Selenium integration socat.container.image = alpine/socat compose.container.image = docker/compose:1.8.0 Required if using Docker Compose kafka.container.image = confluentinc/cp-kafka Used by KafkaContainer localstack.container.image = localstack/localstack Used by LocalStack pulsar.container.image = apachepulsar/pulsar:2.2.0 Used by Apache Pulsar Customizing Ryuk resource reaper ryuk.container.image = testcontainers/ryuk:0.3.3 The resource reaper is responsible for container removal and automatic cleanup of dead containers at JVM shutdown ryuk.container.privileged = true In some environments ryuk must be started in privileged mode to work properly (--privileged flag) Disabling Ryuk Ryuk must be started as a privileged container. If your environment already implements automatic cleanup of containers after the execution, but does not allow starting privileged containers, you can turn off the Ryuk container by setting TESTCONTAINERS_RYUK_DISABLED environment variable to true . Tip Note that Testcontainers will continue doing the cleanup at JVM's shutdown, unless you kill -9 your JVM process. Customizing image pull behaviour pull.timeout = 120 By default Testcontainers will timeout if pull takes more than this duration (in seconds) pull.pause.timeout = 30 By default Testcontainers will abort the pull of an image if the pull appears stalled (no data transferred) for longer than this duration (in seconds). Customizing client ping behaviour client.ping.timeout = 10 Specifies for how long Testcontainers will try to connect to the Docker client to obtain valid info about the client before giving up and trying next strategy, if applicable (in seconds). Customizing Docker host detection Testcontainers will attempt to detect the Docker environment and configure everything to work automatically. However, sometimes customization is required. Testcontainers will respect the following environment variables : DOCKER_HOST = unix:///var/run/docker.sock See Docker environment variables TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE Path to Docker's socket. Used by Ryuk, Docker Compose, and a few other containers that need to perform Docker actions. Example: /var/run/docker-alt.sock TESTCONTAINERS_HOST_OVERRIDE Docker's host on which ports are exposed. Example: docker.svc.local For advanced users, the Docker host connection can be configured via configuration in ~/.testcontainers.properties . Note that these settings require use of the EnvironmentAndSystemPropertyClientProviderStrategy . The example below illustrates usage: docker.client.strategy = org.testcontainers.dockerclient.EnvironmentAndSystemPropertyClientProviderStrategy docker.host = tcp \\: //my.docker.host \\: 1234 # Equivalent to the DOCKER_HOST environment variable. Colons should be escaped. docker.tls.verify = 1 # Equivalent to the DOCKER_TLS_VERIFY environment variable docker.cert.path = /some/path # Equivalent to the DOCKER_CERT_PATH environment variable In addition, you can deactivate this behaviour by specifying: dockerconfig.source = autoIgnoringUserProperties # 'auto' by default","title":"Custom configuration"},{"location":"features/configuration/#custom-configuration","text":"You can override some default properties if your environment requires that.","title":"Custom configuration"},{"location":"features/configuration/#configuration-locations","text":"The configuration will be loaded from multiple locations. Properties are considered in the following order: Environment variables .testcontainers.properties in user's home folder. Example locations: Linux: /home/myuser/.testcontainers.properties Windows: C:/Users/myuser/.testcontainers.properties macOS: /Users/myuser/.testcontainers.properties testcontainers.properties on the classpath. Note that when using environment variables, configuration property names should be set in upper case with underscore separators, preceded by TESTCONTAINERS_ - e.g. checks.disable becomes TESTCONTAINERS_CHECKS_DISABLE . The classpath testcontainers.properties file may exist within the local codebase (e.g. within the src/test/resources directory) or within library dependencies that you may have. Any such configuration files will have their contents merged. If any keys conflict, the value will be taken on the basis of the first value found in: 'local' classpath (i.e. where the URL of the file on the classpath begins with file: ), then other classpath locations (i.e. JAR files) - considered in alphabetical order of path to provide deterministic ordering.","title":"Configuration locations"},{"location":"features/configuration/#disabling-the-startup-checks","text":"checks.disable = [true|false] Before running any containers Testcontainers will perform a set of startup checks to ensure that your environment is configured correctly. Usually they look like this: \u2139\ufe0e Checking the system... \u2714 Docker version should be at least 1.6.0 \u2714 File should be mountable \u2714 A port exposed by a docker container should be accessible It takes a couple of seconds, but if you want to speed up your tests, you can disable the checks once you have everything configured. Add checks.disable=true to your $HOME/.testcontainers.properties to completely disable them.","title":"Disabling the startup checks"},{"location":"features/configuration/#customizing-images","text":"Note This approach is discouraged and deprecated, but is documented for completeness. Overriding individual image names via configuration may be removed in 2021. See Image Name Substitution for other strategies for substituting image names to pull from other registries. Testcontainers uses public Docker images to perform different actions like startup checks, VNC recording and others. Some companies disallow the usage of Docker Hub, but you can override *.image properties with your own images from your private registry to workaround that. ryuk.container.image = testcontainers/ryuk:0.3.3 Performs fail-safe cleanup of containers, and always required (unless Ryuk is disabled ) tinyimage.container.image = alpine:3.17 Used to check whether images can be pulled at startup, and always required (unless startup checks are disabled ) sshd.container.image = testcontainers/sshd:1.1.0 Required if exposing host ports to containers vncrecorder.container.image = testcontainers/vnc-recorder:1.3.0 Used by VNC recorder in Testcontainers' Selenium integration socat.container.image = alpine/socat compose.container.image = docker/compose:1.8.0 Required if using Docker Compose kafka.container.image = confluentinc/cp-kafka Used by KafkaContainer localstack.container.image = localstack/localstack Used by LocalStack pulsar.container.image = apachepulsar/pulsar:2.2.0 Used by Apache Pulsar","title":"Customizing images"},{"location":"features/configuration/#customizing-ryuk-resource-reaper","text":"ryuk.container.image = testcontainers/ryuk:0.3.3 The resource reaper is responsible for container removal and automatic cleanup of dead containers at JVM shutdown ryuk.container.privileged = true In some environments ryuk must be started in privileged mode to work properly (--privileged flag)","title":"Customizing Ryuk resource reaper"},{"location":"features/configuration/#disabling-ryuk","text":"Ryuk must be started as a privileged container. If your environment already implements automatic cleanup of containers after the execution, but does not allow starting privileged containers, you can turn off the Ryuk container by setting TESTCONTAINERS_RYUK_DISABLED environment variable to true . Tip Note that Testcontainers will continue doing the cleanup at JVM's shutdown, unless you kill -9 your JVM process.","title":"Disabling Ryuk"},{"location":"features/configuration/#customizing-image-pull-behaviour","text":"pull.timeout = 120 By default Testcontainers will timeout if pull takes more than this duration (in seconds) pull.pause.timeout = 30 By default Testcontainers will abort the pull of an image if the pull appears stalled (no data transferred) for longer than this duration (in seconds).","title":"Customizing image pull behaviour"},{"location":"features/configuration/#customizing-client-ping-behaviour","text":"client.ping.timeout = 10 Specifies for how long Testcontainers will try to connect to the Docker client to obtain valid info about the client before giving up and trying next strategy, if applicable (in seconds).","title":"Customizing client ping behaviour"},{"location":"features/configuration/#customizing-docker-host-detection","text":"Testcontainers will attempt to detect the Docker environment and configure everything to work automatically. However, sometimes customization is required. Testcontainers will respect the following environment variables : DOCKER_HOST = unix:///var/run/docker.sock See Docker environment variables TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE Path to Docker's socket. Used by Ryuk, Docker Compose, and a few other containers that need to perform Docker actions. Example: /var/run/docker-alt.sock TESTCONTAINERS_HOST_OVERRIDE Docker's host on which ports are exposed. Example: docker.svc.local For advanced users, the Docker host connection can be configured via configuration in ~/.testcontainers.properties . Note that these settings require use of the EnvironmentAndSystemPropertyClientProviderStrategy . The example below illustrates usage: docker.client.strategy = org.testcontainers.dockerclient.EnvironmentAndSystemPropertyClientProviderStrategy docker.host = tcp \\: //my.docker.host \\: 1234 # Equivalent to the DOCKER_HOST environment variable. Colons should be escaped. docker.tls.verify = 1 # Equivalent to the DOCKER_TLS_VERIFY environment variable docker.cert.path = /some/path # Equivalent to the DOCKER_CERT_PATH environment variable In addition, you can deactivate this behaviour by specifying: dockerconfig.source = autoIgnoringUserProperties # 'auto' by default","title":"Customizing Docker host detection"},{"location":"features/container_logs/","text":"Accessing container logs It is possible to capture container output using: the getLogs() method, which simply returns a String snapshot of a container's entire log output the followOutput() method. This method accepts a Consumer and (optionally) a varargs list stating which of STDOUT, STDERR, or both, should be followed. If not specified, both will be followed. At present, container output will always begin from the time of container creation. Reading all logs (from startup time to present) getLogs() is the simplest mechanism for accessing container logs, and can be used as follows: Accessing all output (stdout and stderr) final String logs = container . getLogs (); Accessing just stdout final String logs = container . getLogs ( OutputFrame . OutputType . STDOUT ); Accessing just stderr final String logs = container . getLogs ( OutputFrame . OutputType . STDERR ); Streaming logs Testcontainers includes some out-of-the-box Consumer implementations that can be used with the streaming followOutput() model; examples follow. Streaming container output to an SLF4J logger Given an existing SLF4J logger instance named LOGGER: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ); container . followOutput ( logConsumer ); By default both standard out and standard error will both be emitted at INFO level. Standard error may be emitted at ERROR level, if desired: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ). withSeparateOutputStreams (); The Mapped Diagnostic Context (MDC) for emitted messages may be configured using the withMdc(...) option: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ). withMdc ( \"key\" , \"value\" ); or using an existing map of key-value pairs: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ). withMdc ( map ); Capturing container output as a String To stream logs live or customize the decoding, ToStringConsumer may be used: ToStringConsumer toStringConsumer = new ToStringConsumer (); container . followOutput ( toStringConsumer , OutputType . STDOUT ); String utf8String = toStringConsumer . toUtf8String (); // Or if the container output is not UTF-8 String otherString = toStringConsumer . toString ( CharSet . forName ( \"ISO-8859-1\" )); Waiting for container output to contain expected content WaitingConsumer will block until a frame of container output (usually a line) matches a provided predicate. A timeout may be specified, as shown in this example. WaitingConsumer consumer = new WaitingConsumer (); container . followOutput ( consumer , STDOUT ); consumer . waitUntil ( frame -> frame . getUtf8String (). contains ( \"STARTED\" ), 30 , TimeUnit . SECONDS ); Additionally, as the Java 8 Consumer functional interface is used, Consumers may be composed together. This is useful, for example, to capture all the container output but only when a matching string has been found. e.g.: WaitingConsumer waitingConsumer = new WaitingConsumer (); ToStringConsumer toStringConsumer = new ToStringConsumer (); Consumer < OutputFrame > composedConsumer = toStringConsumer . andThen ( waitingConsumer ); container . followOutput ( composedConsumer ); waitingConsumer . waitUntil ( frame -> frame . getUtf8String (). contains ( \"STARTED\" ), 30 , TimeUnit . SECONDS ); String utf8String = toStringConsumer . toUtf8String ();","title":"Accessing container logs"},{"location":"features/container_logs/#accessing-container-logs","text":"It is possible to capture container output using: the getLogs() method, which simply returns a String snapshot of a container's entire log output the followOutput() method. This method accepts a Consumer and (optionally) a varargs list stating which of STDOUT, STDERR, or both, should be followed. If not specified, both will be followed. At present, container output will always begin from the time of container creation.","title":"Accessing container logs"},{"location":"features/container_logs/#reading-all-logs-from-startup-time-to-present","text":"getLogs() is the simplest mechanism for accessing container logs, and can be used as follows: Accessing all output (stdout and stderr) final String logs = container . getLogs (); Accessing just stdout final String logs = container . getLogs ( OutputFrame . OutputType . STDOUT ); Accessing just stderr final String logs = container . getLogs ( OutputFrame . OutputType . STDERR );","title":"Reading all logs (from startup time to present)"},{"location":"features/container_logs/#streaming-logs","text":"Testcontainers includes some out-of-the-box Consumer implementations that can be used with the streaming followOutput() model; examples follow.","title":"Streaming logs"},{"location":"features/container_logs/#streaming-container-output-to-an-slf4j-logger","text":"Given an existing SLF4J logger instance named LOGGER: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ); container . followOutput ( logConsumer ); By default both standard out and standard error will both be emitted at INFO level. Standard error may be emitted at ERROR level, if desired: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ). withSeparateOutputStreams (); The Mapped Diagnostic Context (MDC) for emitted messages may be configured using the withMdc(...) option: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ). withMdc ( \"key\" , \"value\" ); or using an existing map of key-value pairs: Slf4jLogConsumer logConsumer = new Slf4jLogConsumer ( LOGGER ). withMdc ( map );","title":"Streaming container output to an SLF4J logger"},{"location":"features/container_logs/#capturing-container-output-as-a-string","text":"To stream logs live or customize the decoding, ToStringConsumer may be used: ToStringConsumer toStringConsumer = new ToStringConsumer (); container . followOutput ( toStringConsumer , OutputType . STDOUT ); String utf8String = toStringConsumer . toUtf8String (); // Or if the container output is not UTF-8 String otherString = toStringConsumer . toString ( CharSet . forName ( \"ISO-8859-1\" ));","title":"Capturing container output as a String"},{"location":"features/container_logs/#waiting-for-container-output-to-contain-expected-content","text":"WaitingConsumer will block until a frame of container output (usually a line) matches a provided predicate. A timeout may be specified, as shown in this example. WaitingConsumer consumer = new WaitingConsumer (); container . followOutput ( consumer , STDOUT ); consumer . waitUntil ( frame -> frame . getUtf8String (). contains ( \"STARTED\" ), 30 , TimeUnit . SECONDS ); Additionally, as the Java 8 Consumer functional interface is used, Consumers may be composed together. This is useful, for example, to capture all the container output but only when a matching string has been found. e.g.: WaitingConsumer waitingConsumer = new WaitingConsumer (); ToStringConsumer toStringConsumer = new ToStringConsumer (); Consumer < OutputFrame > composedConsumer = toStringConsumer . andThen ( waitingConsumer ); container . followOutput ( composedConsumer ); waitingConsumer . waitUntil ( frame -> frame . getUtf8String (). contains ( \"STARTED\" ), 30 , TimeUnit . SECONDS ); String utf8String = toStringConsumer . toUtf8String ();","title":"Waiting for container output to contain expected content"},{"location":"features/creating_container/","text":"Creating a container Creating a generic container based on an image Testcontainers' generic container support offers the most flexibility, and makes it easy to use virtually any container images as temporary test dependencies. For example, if you might use it to test interactions with: NoSQL databases or other data stores (e.g. redis, elasticsearch, mongo) Web servers/proxies (e.g. nginx, apache) Log services (e.g. logstash, kibana) Other services developed by your team/organization which are already dockerized With a generic container, you set the container image using a parameter to the rule constructor, e.g.: new GenericContainer ( DockerImageName . parse ( \"jboss/wildfly:9.0.1.Final\" )) Specifying an image Many Container classes in Testcontainers have historically supported: a no-args constructor - for example new GenericContainer() and new ElasticsearchContainer() . With these constructors, Testcontainers has traditionally used a default image name (including a fixed image tag/version). This has caused a conflict between the need to keep the defaults sane (i.e. up to date) and the need to avoid silently upgrading these dependencies along with new versions of Testcontainers. a single string-argument constructor, which has taken either a version or an image name as a String. This has caused some ambiguity and confusion. Since v1.15.0, both of these constructor types have been deprecated, for the reasons given above. Instead, it is highly recommended that all containers be constructed using a constructor that accepts a DockerImageName object. The DockerImageName class is an unambiguous reference to a docker image. It is suggested that developers treat DockerImageName s as you would any other potentially-constant value - consider defining a constant in your test codebase that matches the production version of the dependency you are using. Examples A generic container rule can be used with any public docker image; for example: Creating a Redis container (JUnit 4) public static final DockerImageName REDIS_IMAGE = DockerImageName . parse ( \"redis:6-alpine\" ); @ClassRule public static GenericContainer <?> redis = new GenericContainer <> ( REDIS_IMAGE ) . withExposedPorts ( 6379 ); Further options may be specified: Creating a container with more options (JUnit 4) // Set up a plain OS container and customize environment, // command and exposed ports. This just listens on port 80 // and always returns '42' @ClassRule public static GenericContainer <?> alpine = new GenericContainer <> ( ALPINE_IMAGE ) . withExposedPorts ( 80 ) . withEnv ( \"MAGIC_NUMBER\" , \"42\" ) . withCommand ( \"/bin/sh\" , \"-c\" , \"while true; do echo \\\"$MAGIC_NUMBER\\\" | nc -l -p 80; done\" ); These containers, as @ClassRule s, will be started before any tests in the class run, and will be destroyed after all tests have run.","title":"Creating a container"},{"location":"features/creating_container/#creating-a-container","text":"","title":"Creating a container"},{"location":"features/creating_container/#creating-a-generic-container-based-on-an-image","text":"Testcontainers' generic container support offers the most flexibility, and makes it easy to use virtually any container images as temporary test dependencies. For example, if you might use it to test interactions with: NoSQL databases or other data stores (e.g. redis, elasticsearch, mongo) Web servers/proxies (e.g. nginx, apache) Log services (e.g. logstash, kibana) Other services developed by your team/organization which are already dockerized With a generic container, you set the container image using a parameter to the rule constructor, e.g.: new GenericContainer ( DockerImageName . parse ( \"jboss/wildfly:9.0.1.Final\" ))","title":"Creating a generic container based on an image"},{"location":"features/creating_container/#specifying-an-image","text":"Many Container classes in Testcontainers have historically supported: a no-args constructor - for example new GenericContainer() and new ElasticsearchContainer() . With these constructors, Testcontainers has traditionally used a default image name (including a fixed image tag/version). This has caused a conflict between the need to keep the defaults sane (i.e. up to date) and the need to avoid silently upgrading these dependencies along with new versions of Testcontainers. a single string-argument constructor, which has taken either a version or an image name as a String. This has caused some ambiguity and confusion. Since v1.15.0, both of these constructor types have been deprecated, for the reasons given above. Instead, it is highly recommended that all containers be constructed using a constructor that accepts a DockerImageName object. The DockerImageName class is an unambiguous reference to a docker image. It is suggested that developers treat DockerImageName s as you would any other potentially-constant value - consider defining a constant in your test codebase that matches the production version of the dependency you are using.","title":"Specifying an image"},{"location":"features/creating_container/#examples","text":"A generic container rule can be used with any public docker image; for example: Creating a Redis container (JUnit 4) public static final DockerImageName REDIS_IMAGE = DockerImageName . parse ( \"redis:6-alpine\" ); @ClassRule public static GenericContainer <?> redis = new GenericContainer <> ( REDIS_IMAGE ) . withExposedPorts ( 6379 ); Further options may be specified: Creating a container with more options (JUnit 4) // Set up a plain OS container and customize environment, // command and exposed ports. This just listens on port 80 // and always returns '42' @ClassRule public static GenericContainer <?> alpine = new GenericContainer <> ( ALPINE_IMAGE ) . withExposedPorts ( 80 ) . withEnv ( \"MAGIC_NUMBER\" , \"42\" ) . withCommand ( \"/bin/sh\" , \"-c\" , \"while true; do echo \\\"$MAGIC_NUMBER\\\" | nc -l -p 80; done\" ); These containers, as @ClassRule s, will be started before any tests in the class run, and will be destroyed after all tests have run.","title":"Examples"},{"location":"features/creating_images/","text":"Creating images on-the-fly Overview In situations where there is no pre-existing Docker image, Testcontainers can create a new temporary image on-the-fly from a Dockerfile. For example, when the component under test is the Docker image itself, or when an existing base image needs to be customized for specific test(s). Simply pass a configured instance of ImageFromDockerfile as a constructor parameter to GenericContainer . Testcontainers will docker build a temporary container image, and will use it when creating the container. Dockerfile from String, file or classpath resource ImageFromDockerfile accepts arbitrary files, strings or classpath resources to be used as files in the build context. At least one of these needs to be a Dockerfile . @Rule public GenericContainer dslContainer = new GenericContainer ( new ImageFromDockerfile () . withFileFromString ( \"folder/someFile.txt\" , \"hello\" ) . withFileFromClasspath ( \"test.txt\" , \"mappable-resource/test-resource.txt\" ) . withFileFromClasspath ( \"Dockerfile\" , \"mappable-dockerfile/Dockerfile\" )) The following methods may be used to provide the Dockerfile and any other required build context files: withFileFromString(buildContextPath, content) withFileFromClasspath(buildContextPath, classpathPath) withFileFromPath(buildContextPath, filesystemPath) withFileFromFile(buildContextPath, filesystemFile) Info In older versions of Testcontainers (before 1.3.0) it was necessary to explicitly declare each file that needed to be present in the Docker build context. This can be replaced with the following syntax: Passing an entire directory of files to the Dockerfile build context new ImageFromDockerfile () . withFileFromPath ( \".\" , RESOURCE_PATH ), Where RESOURCE_PATH is the path to a directory containing a Dockerfile and any files that it needs to refer to. Doing this is equivalent to docker build RESOURCE_PATH on the command line. To mimic docker build . , RESOURCE_PATH would simply be set to . as well. Dockerfile DSL If a static Dockerfile is not sufficient (e.g. your test needs to cover many variations that are best generated programmatically), there is a DSL available to allow Dockerfiles to be defined in code. e.g.: new GenericContainer ( new ImageFromDockerfile () . withDockerfileFromBuilder ( builder -> builder . from ( \"alpine:3.17\" ) . run ( \"apk add --update nginx\" ) . cmd ( \"nginx\" , \"-g\" , \"daemon off;\" ) . build ())) . withExposedPorts ( 80 ); See ParameterizedDockerfileContainerTest for a very basic example of using this in conjunction with JUnit parameterized testing. Automatic deletion Temporary container images will be automatically removed when the test JVM shuts down. If this is not desired and the image should be retained between tests, pass a stable image name and false flag to the ImageFromDockerfile constructor. Retaining the image between tests will use Docker's image cache to accelerate subsequent test runs. By default the no-args constructor will use an image name of the form testcontainers/ + random string: public ImageFromDockerfile() public ImageFromDockerfile(String dockerImageName) public ImageFromDockerfile(String dockerImageName, boolean deleteOnExit) Alternative Dockerfiles Normally Docker will automatically build an image from any /Dockerfile that it finds in the root of the build context. To override this behaviour, use .withDockerfilePath(\"./Name-Of-Other-Dockerfile\") . Build Args Build Args may be used to allow lightweight parameterization. To specify build args, use .withBuildArg(\"varname\", \"value\") or provide a Map of args using .withBuildArgs(map) .","title":"Creating images on-the-fly"},{"location":"features/creating_images/#creating-images-on-the-fly","text":"","title":"Creating images on-the-fly"},{"location":"features/creating_images/#overview","text":"In situations where there is no pre-existing Docker image, Testcontainers can create a new temporary image on-the-fly from a Dockerfile. For example, when the component under test is the Docker image itself, or when an existing base image needs to be customized for specific test(s). Simply pass a configured instance of ImageFromDockerfile as a constructor parameter to GenericContainer . Testcontainers will docker build a temporary container image, and will use it when creating the container.","title":"Overview"},{"location":"features/creating_images/#dockerfile-from-string-file-or-classpath-resource","text":"ImageFromDockerfile accepts arbitrary files, strings or classpath resources to be used as files in the build context. At least one of these needs to be a Dockerfile . @Rule public GenericContainer dslContainer = new GenericContainer ( new ImageFromDockerfile () . withFileFromString ( \"folder/someFile.txt\" , \"hello\" ) . withFileFromClasspath ( \"test.txt\" , \"mappable-resource/test-resource.txt\" ) . withFileFromClasspath ( \"Dockerfile\" , \"mappable-dockerfile/Dockerfile\" )) The following methods may be used to provide the Dockerfile and any other required build context files: withFileFromString(buildContextPath, content) withFileFromClasspath(buildContextPath, classpathPath) withFileFromPath(buildContextPath, filesystemPath) withFileFromFile(buildContextPath, filesystemFile) Info In older versions of Testcontainers (before 1.3.0) it was necessary to explicitly declare each file that needed to be present in the Docker build context. This can be replaced with the following syntax: Passing an entire directory of files to the Dockerfile build context new ImageFromDockerfile () . withFileFromPath ( \".\" , RESOURCE_PATH ), Where RESOURCE_PATH is the path to a directory containing a Dockerfile and any files that it needs to refer to. Doing this is equivalent to docker build RESOURCE_PATH on the command line. To mimic docker build . , RESOURCE_PATH would simply be set to . as well.","title":"Dockerfile from String, file or classpath resource"},{"location":"features/creating_images/#dockerfile-dsl","text":"If a static Dockerfile is not sufficient (e.g. your test needs to cover many variations that are best generated programmatically), there is a DSL available to allow Dockerfiles to be defined in code. e.g.: new GenericContainer ( new ImageFromDockerfile () . withDockerfileFromBuilder ( builder -> builder . from ( \"alpine:3.17\" ) . run ( \"apk add --update nginx\" ) . cmd ( \"nginx\" , \"-g\" , \"daemon off;\" ) . build ())) . withExposedPorts ( 80 ); See ParameterizedDockerfileContainerTest for a very basic example of using this in conjunction with JUnit parameterized testing.","title":"Dockerfile DSL"},{"location":"features/creating_images/#automatic-deletion","text":"Temporary container images will be automatically removed when the test JVM shuts down. If this is not desired and the image should be retained between tests, pass a stable image name and false flag to the ImageFromDockerfile constructor. Retaining the image between tests will use Docker's image cache to accelerate subsequent test runs. By default the no-args constructor will use an image name of the form testcontainers/ + random string: public ImageFromDockerfile() public ImageFromDockerfile(String dockerImageName) public ImageFromDockerfile(String dockerImageName, boolean deleteOnExit)","title":"Automatic deletion"},{"location":"features/creating_images/#alternative-dockerfiles","text":"Normally Docker will automatically build an image from any /Dockerfile that it finds in the root of the build context. To override this behaviour, use .withDockerfilePath(\"./Name-Of-Other-Dockerfile\") .","title":"Alternative Dockerfiles"},{"location":"features/creating_images/#build-args","text":"Build Args may be used to allow lightweight parameterization. To specify build args, use .withBuildArg(\"varname\", \"value\") or provide a Map of args using .withBuildArgs(map) .","title":"Build Args"},{"location":"features/files/","text":"Files and volumes Copying files Files can be copied into the container before startup, or can be copied from the container after the container has started. Note This is the recommended approach for portability cross-docker environments. Copying to a container before startup Copying files using MountableFile GenericContainer <?> container = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withCommand ( \"sleep\" , \"3000\" ) . withCopyFileToContainer ( MountableFile . forClasspathResource ( \"/mappable-resource/\" ), directoryInContainer ) Using Transferable , file content will be placed in the specified location. Copying files using Transferable GenericContainer <?> container = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withStartupCheckStrategy ( new NoopStartupCheckStrategy ()) . withCopyToContainer ( Transferable . of ( \"test\" ), \"/tmp/test\" ) . waitingFor ( new WaitForExitedState ( state -> state . getExitCodeLong () > 0 )) . withCommand ( \"sh\" , \"-c\" , \"grep -q test /tmp/test && exit 100\" ) Setting file mode is also possible. Copying files using Transferable with file mode GenericContainer <?> container = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withStartupCheckStrategy ( new NoopStartupCheckStrategy ()) . withCopyToContainer ( Transferable . of ( \"test\" , 0777 ), \"/tmp/test\" ) . waitingFor ( new WaitForExitedState ( state -> state . getExitCodeLong () > 0 )) . withCommand ( \"sh\" , \"-c\" , \"ls -ll /tmp | grep '\\\\-rwxrwxrwx\\\\|test' && exit 100\" ) Copying a file from a running container Copying files from a container container . copyFileFromContainer ( directoryInContainer + fileName , destinationOnHost );","title":"Files and volumes"},{"location":"features/files/#files-and-volumes","text":"","title":"Files and volumes"},{"location":"features/files/#copying-files","text":"Files can be copied into the container before startup, or can be copied from the container after the container has started. Note This is the recommended approach for portability cross-docker environments.","title":"Copying files"},{"location":"features/files/#copying-to-a-container-before-startup","text":"Copying files using MountableFile GenericContainer <?> container = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withCommand ( \"sleep\" , \"3000\" ) . withCopyFileToContainer ( MountableFile . forClasspathResource ( \"/mappable-resource/\" ), directoryInContainer ) Using Transferable , file content will be placed in the specified location. Copying files using Transferable GenericContainer <?> container = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withStartupCheckStrategy ( new NoopStartupCheckStrategy ()) . withCopyToContainer ( Transferable . of ( \"test\" ), \"/tmp/test\" ) . waitingFor ( new WaitForExitedState ( state -> state . getExitCodeLong () > 0 )) . withCommand ( \"sh\" , \"-c\" , \"grep -q test /tmp/test && exit 100\" ) Setting file mode is also possible. Copying files using Transferable with file mode GenericContainer <?> container = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withStartupCheckStrategy ( new NoopStartupCheckStrategy ()) . withCopyToContainer ( Transferable . of ( \"test\" , 0777 ), \"/tmp/test\" ) . waitingFor ( new WaitForExitedState ( state -> state . getExitCodeLong () > 0 )) . withCommand ( \"sh\" , \"-c\" , \"ls -ll /tmp | grep '\\\\-rwxrwxrwx\\\\|test' && exit 100\" )","title":"Copying to a container before startup"},{"location":"features/files/#copying-a-file-from-a-running-container","text":"Copying files from a container container . copyFileFromContainer ( directoryInContainer + fileName , destinationOnHost );","title":"Copying a file from a running container"},{"location":"features/image_name_substitution/","text":"Image name substitution Testcontainers supports automatic substitution of Docker image names. This allows replacement of an image name specified in test code with an alternative name - for example, to replace the name of a Docker Hub image dependency with an alternative hosted on a private image registry. This is advisable to avoid Docker Hub rate limiting , and some companies will prefer this for policy reasons. This page describes four approaches for image name substitution: Manual substitution - not relying upon an automated approach Using an Image Name Substitutor: Developing a custom function for transforming image names on the fly Overriding image names individually in configuration It is assumed that you have already set up a private registry hosting all the Docker images your build requires . Manual substitution Consider this if: You use only a few images and updating code is not a chore All developers and CI machines in your organisation have access to a common registry server You also use one of the automated mechanisms to substitute the images that Testcontainers itself requires This approach simply entails modifying test code manually, e.g. changing: For example, you may have a test that uses the mysql container image from Docker Hub: Direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing to: Private registry image name // Referring directly to an image on a private registry - image name will vary final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"registry.mycompany.com/mirror/mysql:8.0.36\" ) . asCompatibleSubstituteFor ( \"mysql\" ) ) // start the container and use it for testing Automatically modifying Docker Hub image names Testcontainers can be configured to modify Docker Hub image names on the fly to apply a prefix string. Consider this if: Developers and CI machines need to use different image names. For example, developers are able to pull images from Docker Hub, but CI machines need to pull from a private registry Your private registry has copies of images from Docker Hub where the names are predictable, and just adding a prefix is enough. For example, registry.mycompany.com/mirror/mysql:8.0.36 can be derived from the original Docker Hub image name ( mysql:8.0.36 ) with a consistent prefix string: registry.mycompany.com/mirror/ In this case, image name references in code are unchanged . i.e. you would leave as-is: Unchanged direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing You can then configure Testcontainers to apply the prefix registry.mycompany.com/mirror/ to every image that it tries to pull from Docker Hub. This can be done in one of two ways: Setting environment variables TESTCONTAINERS_HUB_IMAGE_NAME_PREFIX=registry.mycompany.com/mirror/ Via config file, setting hub.image.name.prefix in either: the ~/.testcontainers.properties file in your user home directory, or a file named testcontainers.properties on the classpath Testcontainers will automatically apply the prefix to every image that it pulls from Docker Hub - please verify that all the required images exist in your registry. Testcontainers will not apply the prefix to: non-Hub image names (e.g. where another registry is set) Docker Hub image names where the hub registry is explicitly part of the name (i.e. anything with a docker.io or registry.hub.docker.com host part) Developing a custom function for transforming image names on the fly Consider this if: You have complex rules about which private registry images should be used as substitutes, e.g.: non-deterministic mapping of names meaning that a name prefix cannot be used rules depending upon developer identity or location or you wish to add audit logging of images used in the build or you wish to prevent accidental usage of images that are not on an approved list In this case, image name references in code are unchanged . i.e. you would leave as-is: Unchanged direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing You can implement a custom image name substitutor by: subclassing org.testcontainers.utility.ImageNameSubstitutor configuring Testcontainers to use your custom implementation The following is an example image substitutor implementation: Example Image Substitutor public class ExampleImageNameSubstitutor extends ImageNameSubstitutor { @Override public DockerImageName apply ( DockerImageName original ) { // convert the original name to something appropriate for // our build environment return DockerImageName . parse ( // your code goes here - silly example of capitalising // the original name is shown original . asCanonicalNameString (). toUpperCase () ); } @Override protected String getDescription () { // used in logs return \"example image name substitutor\" ; } } Testcontainers can be configured to find it at runtime via configuration. To do this, create or modify a file on the classpath named testcontainers.properties . For example: src/test/resources/testcontainers.properties image.substitutor=com.mycompany.testcontainers.ExampleImageNameSubstitutor Note that it is also possible to provide this same configuration property: in a testcontainers.properties file at the root of a library JAR file (useful if you wish to distribute a drop-in image substitutor JAR within an organization) in a properties file in the user's home directory ( ~/.testcontainers.properties ; note the leading . ) or as an environment variable (e.g. TESTCONTAINERS_IMAGE_SUBSTITUTOR=com.mycompany.testcontainers.ExampleImageNameSubstitutor ). Please see the documentation on configuration mechanisms for more information. Also, you can use the ServiceLoader mechanism to provide the fully qualified class name of the ImageNameSubstitutor implementation: src/test/resources/META-INF/services/org.testcontainers.utility.ImageNameSubstitutor com.mycompany.testcontainers.ExampleImageNameSubstitutor Overriding image names individually in configuration Note This approach is discouraged and deprecated, but is documented for completeness. Please consider one of the other approaches outlined in this page instead. Overriding individual image names via configuration may be removed in the future. Consider this if: You have many references to image names in code and changing them is impractical, and None of the other options are practical for you In this case, image name references in code are left unchanged . i.e. you would leave as-is: Unchanged direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing You can force Testcontainers to substitute in a different image using a configuration file , which allows some (but not all) container names to be substituted.","title":"Image name substitution"},{"location":"features/image_name_substitution/#image-name-substitution","text":"Testcontainers supports automatic substitution of Docker image names. This allows replacement of an image name specified in test code with an alternative name - for example, to replace the name of a Docker Hub image dependency with an alternative hosted on a private image registry. This is advisable to avoid Docker Hub rate limiting , and some companies will prefer this for policy reasons. This page describes four approaches for image name substitution: Manual substitution - not relying upon an automated approach Using an Image Name Substitutor: Developing a custom function for transforming image names on the fly Overriding image names individually in configuration It is assumed that you have already set up a private registry hosting all the Docker images your build requires .","title":"Image name substitution"},{"location":"features/image_name_substitution/#manual-substitution","text":"Consider this if: You use only a few images and updating code is not a chore All developers and CI machines in your organisation have access to a common registry server You also use one of the automated mechanisms to substitute the images that Testcontainers itself requires This approach simply entails modifying test code manually, e.g. changing: For example, you may have a test that uses the mysql container image from Docker Hub: Direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing to: Private registry image name // Referring directly to an image on a private registry - image name will vary final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"registry.mycompany.com/mirror/mysql:8.0.36\" ) . asCompatibleSubstituteFor ( \"mysql\" ) ) // start the container and use it for testing","title":"Manual substitution"},{"location":"features/image_name_substitution/#automatically-modifying-docker-hub-image-names","text":"Testcontainers can be configured to modify Docker Hub image names on the fly to apply a prefix string. Consider this if: Developers and CI machines need to use different image names. For example, developers are able to pull images from Docker Hub, but CI machines need to pull from a private registry Your private registry has copies of images from Docker Hub where the names are predictable, and just adding a prefix is enough. For example, registry.mycompany.com/mirror/mysql:8.0.36 can be derived from the original Docker Hub image name ( mysql:8.0.36 ) with a consistent prefix string: registry.mycompany.com/mirror/ In this case, image name references in code are unchanged . i.e. you would leave as-is: Unchanged direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing You can then configure Testcontainers to apply the prefix registry.mycompany.com/mirror/ to every image that it tries to pull from Docker Hub. This can be done in one of two ways: Setting environment variables TESTCONTAINERS_HUB_IMAGE_NAME_PREFIX=registry.mycompany.com/mirror/ Via config file, setting hub.image.name.prefix in either: the ~/.testcontainers.properties file in your user home directory, or a file named testcontainers.properties on the classpath Testcontainers will automatically apply the prefix to every image that it pulls from Docker Hub - please verify that all the required images exist in your registry. Testcontainers will not apply the prefix to: non-Hub image names (e.g. where another registry is set) Docker Hub image names where the hub registry is explicitly part of the name (i.e. anything with a docker.io or registry.hub.docker.com host part)","title":"Automatically modifying Docker Hub image names"},{"location":"features/image_name_substitution/#developing-a-custom-function-for-transforming-image-names-on-the-fly","text":"Consider this if: You have complex rules about which private registry images should be used as substitutes, e.g.: non-deterministic mapping of names meaning that a name prefix cannot be used rules depending upon developer identity or location or you wish to add audit logging of images used in the build or you wish to prevent accidental usage of images that are not on an approved list In this case, image name references in code are unchanged . i.e. you would leave as-is: Unchanged direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing You can implement a custom image name substitutor by: subclassing org.testcontainers.utility.ImageNameSubstitutor configuring Testcontainers to use your custom implementation The following is an example image substitutor implementation: Example Image Substitutor public class ExampleImageNameSubstitutor extends ImageNameSubstitutor { @Override public DockerImageName apply ( DockerImageName original ) { // convert the original name to something appropriate for // our build environment return DockerImageName . parse ( // your code goes here - silly example of capitalising // the original name is shown original . asCanonicalNameString (). toUpperCase () ); } @Override protected String getDescription () { // used in logs return \"example image name substitutor\" ; } } Testcontainers can be configured to find it at runtime via configuration. To do this, create or modify a file on the classpath named testcontainers.properties . For example: src/test/resources/testcontainers.properties image.substitutor=com.mycompany.testcontainers.ExampleImageNameSubstitutor Note that it is also possible to provide this same configuration property: in a testcontainers.properties file at the root of a library JAR file (useful if you wish to distribute a drop-in image substitutor JAR within an organization) in a properties file in the user's home directory ( ~/.testcontainers.properties ; note the leading . ) or as an environment variable (e.g. TESTCONTAINERS_IMAGE_SUBSTITUTOR=com.mycompany.testcontainers.ExampleImageNameSubstitutor ). Please see the documentation on configuration mechanisms for more information. Also, you can use the ServiceLoader mechanism to provide the fully qualified class name of the ImageNameSubstitutor implementation: src/test/resources/META-INF/services/org.testcontainers.utility.ImageNameSubstitutor com.mycompany.testcontainers.ExampleImageNameSubstitutor","title":"Developing a custom function for transforming image names on the fly"},{"location":"features/image_name_substitution/#overriding-image-names-individually-in-configuration","text":"Note This approach is discouraged and deprecated, but is documented for completeness. Please consider one of the other approaches outlined in this page instead. Overriding individual image names via configuration may be removed in the future. Consider this if: You have many references to image names in code and changing them is impractical, and None of the other options are practical for you In this case, image name references in code are left unchanged . i.e. you would leave as-is: Unchanged direct Docker Hub image name // Referring directly to an image on Docker Hub (mysql:8.0.36) final MySQLContainer <?> mysql = new MySQLContainer <> ( DockerImageName . parse ( \"mysql:8.0.36\" ) ) // start the container and use it for testing You can force Testcontainers to substitute in a different image using a configuration file , which allows some (but not all) container names to be substituted.","title":"Overriding image names individually in configuration"},{"location":"features/jib/","text":"Using Jib Jib is a library for building Docker images. You can use it as an alternative to Testcontainers default DockerfileBuilder . GenericContainer with JibImage GenericContainer <?> busybox = new GenericContainer <> ( new JibImage ( \"busybox:1.35\" , jibContainerBuilder -> { return jibContainerBuilder . setEntrypoint ( \"echo\" , \"Hello World\" ); } ) ) . withStartupCheckStrategy ( new OneShotStartupCheckStrategy (). withTimeout ( Duration . ofSeconds ( 3 ))) Hint The Testcontainers library JAR will not automatically add a jib-core JAR to your project. Minimum version required is com.google.cloud.tools:jib-core:0.22.0 .","title":"Using Jib"},{"location":"features/jib/#using-jib","text":"Jib is a library for building Docker images. You can use it as an alternative to Testcontainers default DockerfileBuilder . GenericContainer with JibImage GenericContainer <?> busybox = new GenericContainer <> ( new JibImage ( \"busybox:1.35\" , jibContainerBuilder -> { return jibContainerBuilder . setEntrypoint ( \"echo\" , \"Hello World\" ); } ) ) . withStartupCheckStrategy ( new OneShotStartupCheckStrategy (). withTimeout ( Duration . ofSeconds ( 3 ))) Hint The Testcontainers library JAR will not automatically add a jib-core JAR to your project. Minimum version required is com.google.cloud.tools:jib-core:0.22.0 .","title":"Using Jib"},{"location":"features/networking/","text":"Networking and communicating with containers Exposing container ports to the host It is common to want to connect to a container from your test process, running on the test 'host' machine. For example, you may be testing a class that needs to connect to a backend or data store container. Generally, each required port needs to be explicitly exposed. For example, we can specify one or more ports as follows: Exposing ports public GenericContainer <?> container = new GenericContainer <> ( DockerImageName . parse ( \"testcontainers/helloworld:1.1.0\" ) ) . withExposedPorts ( 8080 , 8081 ) . withLogConsumer ( new Slf4jLogConsumer ( log )); Note that this exposed port number is from the perspective of the container . From the host's perspective Testcontainers actually exposes this on a random free port. This is by design, to avoid port collisions that may arise with locally running software or in between parallel test runs. Because there is this layer of indirection, it is necessary to ask Testcontainers for the actual mapped port at runtime. This can be done using the getMappedPort method, which takes the original (container) port as an argument: Retrieving actual ports at runtime Integer firstMappedPort = container . getMappedPort ( 8080 ); Integer secondMappedPort = container . getMappedPort ( 8081 ); Warning Because the randomised port mapping happens during container startup, the container must be running at the time getMappedPort is called. You may need to ensure that the startup order of components in your tests caters for this. There is also a getFirstMappedPort method for convenience, for the fairly common scenario of a container that only exposes one port: Retrieving the first mapped port Integer firstMappedPort = container . getFirstMappedPort (); Getting the container host When running with a local Docker daemon, exposed ports will usually be reachable on localhost . However, in some CI environments they may instead be reachable on a different host. As such, Testcontainers provides a convenience method to obtain an address on which the container should be reachable from the host machine. Getting the container host String ipAddress = container . getHost (); It is normally advisable to use getHost and getMappedPort together when constructing addresses - for example: Getting the container host and mapped port String address = container . getHost () + \":\" + container . getMappedPort ( 8080 ); Tip getHost() is a replacement for getContainerIpAddress() and returns the same result. getContainerIpAddress() is believed to be confusingly named, and will eventually be deprecated. Exposing host ports to the container In some cases it is necessary to make a network connection from a container to a socket that is listening on the host machine. Natively, Docker has limited support for this model across platforms. Testcontainers, however, makes this possible. In this example, assume that localServerPort is a port on our test host machine where a server (e.g. a web application) is running. We need to tell Testcontainers to prepare to expose this port to containers: Exposing the host port Testcontainers . exposeHostPorts ( localServerPort ); Warning Note that the above command should be invoked before containers are started, but after the server on the host was started. Alternatively, use container.withAccessToHost(true) to force the host access mechanism (you still need to call exposeHostPorts to make the port available). Having done so, we can now access this port from any containers that are launched. From a container's perspective, the hostname will be host.testcontainers.internal and the port will be the same value as localServerPort . For example, here we construct an HTTP URL for our local web application and tell a Selenium container to get a page from it: Accessing the exposed host port from a container final String rootUrl = String . format ( \"http://host.testcontainers.internal:%d/\" , localServerPort ); final RemoteWebDriver webDriver = new RemoteWebDriver ( this . browser . getSeleniumAddress (), new ChromeOptions ()); webDriver . get ( rootUrl ); Advanced networking Docker provides the ability for you to create custom networks and place containers on one or more networks. Then, communication can occur between networked containers without the need of exposing ports through the host. With Testcontainers, you can do this as well. Warning Note that Testcontainers currently only allows a container to be on a single network. Creating custom networks try ( Network network = Network . newNetwork (); GenericContainer <?> foo = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withNetwork ( network ) . withNetworkAliases ( \"foo\" ) . withCommand ( \"/bin/sh\" , \"-c\" , \"while true ; do printf 'HTTP/1.1 200 OK\\\\n\\\\nyay' | nc -l -p 8080; done\" ); GenericContainer <?> bar = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withNetwork ( network ) . withCommand ( \"top\" ) ) { foo . start (); bar . start (); String response = bar . execInContainer ( \"wget\" , \"-O\" , \"-\" , \"http://foo:8080\" ). getStdout (); assertThat ( response ). as ( \"received response\" ). isEqualTo ( \"yay\" ); }","title":"Networking and communicating with containers"},{"location":"features/networking/#networking-and-communicating-with-containers","text":"","title":"Networking and communicating with containers"},{"location":"features/networking/#exposing-container-ports-to-the-host","text":"It is common to want to connect to a container from your test process, running on the test 'host' machine. For example, you may be testing a class that needs to connect to a backend or data store container. Generally, each required port needs to be explicitly exposed. For example, we can specify one or more ports as follows: Exposing ports public GenericContainer <?> container = new GenericContainer <> ( DockerImageName . parse ( \"testcontainers/helloworld:1.1.0\" ) ) . withExposedPorts ( 8080 , 8081 ) . withLogConsumer ( new Slf4jLogConsumer ( log )); Note that this exposed port number is from the perspective of the container . From the host's perspective Testcontainers actually exposes this on a random free port. This is by design, to avoid port collisions that may arise with locally running software or in between parallel test runs. Because there is this layer of indirection, it is necessary to ask Testcontainers for the actual mapped port at runtime. This can be done using the getMappedPort method, which takes the original (container) port as an argument: Retrieving actual ports at runtime Integer firstMappedPort = container . getMappedPort ( 8080 ); Integer secondMappedPort = container . getMappedPort ( 8081 ); Warning Because the randomised port mapping happens during container startup, the container must be running at the time getMappedPort is called. You may need to ensure that the startup order of components in your tests caters for this. There is also a getFirstMappedPort method for convenience, for the fairly common scenario of a container that only exposes one port: Retrieving the first mapped port Integer firstMappedPort = container . getFirstMappedPort ();","title":"Exposing container ports to the host"},{"location":"features/networking/#getting-the-container-host","text":"When running with a local Docker daemon, exposed ports will usually be reachable on localhost . However, in some CI environments they may instead be reachable on a different host. As such, Testcontainers provides a convenience method to obtain an address on which the container should be reachable from the host machine. Getting the container host String ipAddress = container . getHost (); It is normally advisable to use getHost and getMappedPort together when constructing addresses - for example: Getting the container host and mapped port String address = container . getHost () + \":\" + container . getMappedPort ( 8080 ); Tip getHost() is a replacement for getContainerIpAddress() and returns the same result. getContainerIpAddress() is believed to be confusingly named, and will eventually be deprecated.","title":"Getting the container host"},{"location":"features/networking/#exposing-host-ports-to-the-container","text":"In some cases it is necessary to make a network connection from a container to a socket that is listening on the host machine. Natively, Docker has limited support for this model across platforms. Testcontainers, however, makes this possible. In this example, assume that localServerPort is a port on our test host machine where a server (e.g. a web application) is running. We need to tell Testcontainers to prepare to expose this port to containers: Exposing the host port Testcontainers . exposeHostPorts ( localServerPort ); Warning Note that the above command should be invoked before containers are started, but after the server on the host was started. Alternatively, use container.withAccessToHost(true) to force the host access mechanism (you still need to call exposeHostPorts to make the port available). Having done so, we can now access this port from any containers that are launched. From a container's perspective, the hostname will be host.testcontainers.internal and the port will be the same value as localServerPort . For example, here we construct an HTTP URL for our local web application and tell a Selenium container to get a page from it: Accessing the exposed host port from a container final String rootUrl = String . format ( \"http://host.testcontainers.internal:%d/\" , localServerPort ); final RemoteWebDriver webDriver = new RemoteWebDriver ( this . browser . getSeleniumAddress (), new ChromeOptions ()); webDriver . get ( rootUrl );","title":"Exposing host ports to the container"},{"location":"features/networking/#advanced-networking","text":"Docker provides the ability for you to create custom networks and place containers on one or more networks. Then, communication can occur between networked containers without the need of exposing ports through the host. With Testcontainers, you can do this as well. Warning Note that Testcontainers currently only allows a container to be on a single network. Creating custom networks try ( Network network = Network . newNetwork (); GenericContainer <?> foo = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withNetwork ( network ) . withNetworkAliases ( \"foo\" ) . withCommand ( \"/bin/sh\" , \"-c\" , \"while true ; do printf 'HTTP/1.1 200 OK\\\\n\\\\nyay' | nc -l -p 8080; done\" ); GenericContainer <?> bar = new GenericContainer <> ( TestImages . TINY_IMAGE ) . withNetwork ( network ) . withCommand ( \"top\" ) ) { foo . start (); bar . start (); String response = bar . execInContainer ( \"wget\" , \"-O\" , \"-\" , \"http://foo:8080\" ). getStdout (); assertThat ( response ). as ( \"received response\" ). isEqualTo ( \"yay\" ); }","title":"Advanced networking"},{"location":"features/reuse/","text":"Reusable Containers (Experimental) Warning Reusable Containers is still an experimental feature and the behavior can change. Those containers won't stop after all tests are finished. The Reusable feature keeps the containers running and next executions with the same container configuration will reuse it. To use it, start the container manually by calling start() method, do not call stop() method directly or indirectly via try-with-resources or JUnit integration , and enable it manually through an opt-in mechanism per environment. To reuse a container, the container configuration must be the same . Note Reusable containers are not suited for CI usage and as an experimental feature not all Testcontainers features are fully working (e.g., resource cleanup or networking). How to use it Enable Reusable Containers through environment variable TESTCONTAINERS_REUSE_ENABLE=true through user property file ~/.testcontainers.properties , by adding testcontainers.reuse.enable=true not through classpath properties file see this comment Define a container and subscribe to reuse the container using withReuse(true) GenericContainer container = new GenericContainer ( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) . withReuse ( true ) Start the container manually by using container.start() Reusable Container with Testcontainers JDBC URL If using the Testcontainers JDBC URL support the URL must follow the pattern of jdbc:tc:mysql:8.0.36:///databasename?TC_REUSABLE=true . TC_REUSABLE=true is set as a parameter of the JDBC URL.","title":"Reusable Containers (Experimental)"},{"location":"features/reuse/#reusable-containers-experimental","text":"Warning Reusable Containers is still an experimental feature and the behavior can change. Those containers won't stop after all tests are finished. The Reusable feature keeps the containers running and next executions with the same container configuration will reuse it. To use it, start the container manually by calling start() method, do not call stop() method directly or indirectly via try-with-resources or JUnit integration , and enable it manually through an opt-in mechanism per environment. To reuse a container, the container configuration must be the same . Note Reusable containers are not suited for CI usage and as an experimental feature not all Testcontainers features are fully working (e.g., resource cleanup or networking).","title":"Reusable Containers (Experimental)"},{"location":"features/reuse/#how-to-use-it","text":"Enable Reusable Containers through environment variable TESTCONTAINERS_REUSE_ENABLE=true through user property file ~/.testcontainers.properties , by adding testcontainers.reuse.enable=true not through classpath properties file see this comment Define a container and subscribe to reuse the container using withReuse(true) GenericContainer container = new GenericContainer ( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) . withReuse ( true ) Start the container manually by using container.start()","title":"How to use it"},{"location":"features/reuse/#reusable-container-with-testcontainers-jdbc-url","text":"If using the Testcontainers JDBC URL support the URL must follow the pattern of jdbc:tc:mysql:8.0.36:///databasename?TC_REUSABLE=true . TC_REUSABLE=true is set as a parameter of the JDBC URL.","title":"Reusable Container with Testcontainers JDBC URL"},{"location":"features/startup_and_waits/","text":"Waiting for containers to start or be ready Wait strategies vs Startup strategies Wait strategy: is the container in a state that is useful for testing. This is generally approximated as 'can we talk to this container over the network'. However, there are quite a few variations and nuances. Startup strategy: did a container reach the desired running state. Almost always this just means 'wait until the container is running' - for a daemon process in a container this is the goal. Sometimes we need to wait until the container reaches a running state and then exits - this is the 'one shot startup' strategy, only used for cases where we need to run a one off command in a container but not a daemon. Wait Strategies Ordinarily Testcontainers will wait for up to 60 seconds for the container's first mapped network port to start listening. This simple measure provides a basic check whether a container is ready for use. Waiting for the first exposed port to start listening public GenericContainer nginx = new GenericContainer ( DockerImageName . parse ( \"nginx:1.27.0-alpine3.19-slim\" )) // . withExposedPorts ( 80 ); If the default 60s timeout is not sufficient, it can be altered with the withStartupTimeout() method. If waiting for a listening TCP port is not sufficient to establish whether the container is ready, you can use the waitingFor() method with other WaitStrategy implementations as shown below. HTTP Wait strategy examples You can choose to wait for an HTTP(S) endpoint to return a particular status code. Waiting for 200 OK public GenericContainer nginxWithHttpWait = new GenericContainer ( DockerImageName . parse ( \"nginx:1.27.0-alpine3.19-slim\" ) ) . withExposedPorts ( 80 ) . waitingFor ( Wait . forHttp ( \"/\" )); Variations on the HTTP wait strategy are supported, including: Waiting for multiple possible status codes Wait . forHttp ( \"/\" ) . forStatusCode ( 200 ) . forStatusCode ( 301 ); Waiting for a status code that matches a predicate Waiting for a status code that matches a predicate Wait . forHttp ( \"/all\" ) . forStatusCodeMatching ( it -> it >= 200 && it < 300 || it == 401 ); Using TLS Wait . forHttp ( \"/all\" ) . usingTls (); Healthcheck Wait strategy examples If the used image supports Docker's Healthcheck feature, you can directly leverage the healthy state of the container as your wait condition: Wait . forHealthcheck (); Log output Wait Strategy In some situations a container's log output is a simple way to determine if it is ready or not. For example, we can wait for a `Ready' message in the container's logs as follows: public GenericContainer containerWithLogWait = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ) . waitingFor ( Wait . forLogMessage ( \".*Ready to accept connections.*\\\\n\" , 1 )); Other Wait Strategies For further options, check out the Wait convenience class, or the various subclasses of WaitStrategy . If none of these options meet your requirements, you can create your own subclass of AbstractWaitStrategy with an appropriate wait mechanism in waitUntilReady() . The GenericContainer.waitingFor() method accepts any valid WaitStrategy . Startup check Strategies Ordinarily Testcontainers will check that the container has reached the running state and has not exited. In order to do that inspect is executed against the container and state parameter is extracted. All logic is implemented in StartupCheckStrategy child classes. Running startup strategy example This is the strategy used by default. Testcontainers just checks if container is running. Implemented in IsRunningStartupCheckStrategy class. One shot startup strategy example This strategy is intended for use with containers that only run briefly and exit of their own accord. As such, success is deemed to be when the container has stopped with exit code 0. Using one shot startup strategy public GenericContainer <?> bboxWithOneShot = new GenericContainer <> ( DockerImageName . parse ( \"busybox:1.31.1\" )) . withCommand ( String . format ( \"echo %s\" , HELLO_TESTCONTAINERS )) . withStartupCheckStrategy ( new OneShotStartupCheckStrategy (). withTimeout ( Duration . ofSeconds ( 3 )) ); Indefinite one shot startup strategy example Variant of one shot strategy that does not impose a timeout. Intended for situation such as when a long running task forms part of container startup. It has to be assumed that the container will stop of its own accord, either with a success or failure exit code. Using indefinite one shot startup strategy public GenericContainer <?> bboxWithIndefiniteOneShot = new GenericContainer <> ( DockerImageName . parse ( \"busybox:1.31.1\" ) ) . withCommand ( \"sh\" , \"-c\" , String . format ( \"sleep 5 && echo \\\"%s\\\"\" , HELLO_TESTCONTAINERS )) . withStartupCheckStrategy ( new IndefiniteWaitOneShotStartupCheckStrategy () ); Minimum duration startup strategy example Checks that the container is running and has been running for a defined minimum period of time. Using minimum duration strategy public GenericContainer <?> bboxWithMinimumDuration = new GenericContainer <> ( DockerImageName . parse ( \"busybox:1.31.1\" ) ) . withCommand ( \"sh\" , \"-c\" , String . format ( \"sleep 5 && echo \\\"%s\\\"\" , HELLO_TESTCONTAINERS )) . withStartupCheckStrategy ( new MinimumDurationRunningStartupCheckStrategy ( Duration . ofSeconds ( 1 )) ); Other startup strategies If none of these options meet your requirements, you can create your own subclass of StartupCheckStrategy with an appropriate startup check mechanism in waitUntilStartupSuccessful() . Or you can leave it as is and just implement the checkStartupState(DockerClient dockerClient, String containerId) if you still want to check state periodically. Depending on another container Sometimes, a container relies on another container to be ready before it should start itself. An example of this might be a database that needs to be started before your application container can link to it. You can tell a container that it depends on another container by using the dependsOn method: Depending on another container public GenericContainer <?> redis = new GenericContainer <> ( \"redis:6-alpine\" ). withExposedPorts ( 6379 ); @Rule public GenericContainer <?> nginx = new GenericContainer <> ( \"nginx:1.27.0-alpine3.19-slim\" ) . dependsOn ( redis ) . withExposedPorts ( 80 );","title":"Waiting for containers to start or be ready"},{"location":"features/startup_and_waits/#waiting-for-containers-to-start-or-be-ready","text":"Wait strategies vs Startup strategies Wait strategy: is the container in a state that is useful for testing. This is generally approximated as 'can we talk to this container over the network'. However, there are quite a few variations and nuances. Startup strategy: did a container reach the desired running state. Almost always this just means 'wait until the container is running' - for a daemon process in a container this is the goal. Sometimes we need to wait until the container reaches a running state and then exits - this is the 'one shot startup' strategy, only used for cases where we need to run a one off command in a container but not a daemon.","title":"Waiting for containers to start or be ready"},{"location":"features/startup_and_waits/#wait-strategies","text":"Ordinarily Testcontainers will wait for up to 60 seconds for the container's first mapped network port to start listening. This simple measure provides a basic check whether a container is ready for use. Waiting for the first exposed port to start listening public GenericContainer nginx = new GenericContainer ( DockerImageName . parse ( \"nginx:1.27.0-alpine3.19-slim\" )) // . withExposedPorts ( 80 ); If the default 60s timeout is not sufficient, it can be altered with the withStartupTimeout() method. If waiting for a listening TCP port is not sufficient to establish whether the container is ready, you can use the waitingFor() method with other WaitStrategy implementations as shown below.","title":"Wait Strategies"},{"location":"features/startup_and_waits/#http-wait-strategy-examples","text":"You can choose to wait for an HTTP(S) endpoint to return a particular status code.","title":"HTTP Wait strategy examples"},{"location":"features/startup_and_waits/#waiting-for-200-ok","text":"public GenericContainer nginxWithHttpWait = new GenericContainer ( DockerImageName . parse ( \"nginx:1.27.0-alpine3.19-slim\" ) ) . withExposedPorts ( 80 ) . waitingFor ( Wait . forHttp ( \"/\" )); Variations on the HTTP wait strategy are supported, including:","title":"Waiting for 200 OK"},{"location":"features/startup_and_waits/#waiting-for-multiple-possible-status-codes","text":"Wait . forHttp ( \"/\" ) . forStatusCode ( 200 ) . forStatusCode ( 301 );","title":"Waiting for multiple possible status codes"},{"location":"features/startup_and_waits/#waiting-for-a-status-code-that-matches-a-predicate","text":"Waiting for a status code that matches a predicate Wait . forHttp ( \"/all\" ) . forStatusCodeMatching ( it -> it >= 200 && it < 300 || it == 401 );","title":"Waiting for a status code that matches a predicate"},{"location":"features/startup_and_waits/#using-tls","text":"Wait . forHttp ( \"/all\" ) . usingTls ();","title":"Using TLS"},{"location":"features/startup_and_waits/#healthcheck-wait-strategy-examples","text":"If the used image supports Docker's Healthcheck feature, you can directly leverage the healthy state of the container as your wait condition: Wait . forHealthcheck ();","title":"Healthcheck Wait strategy examples"},{"location":"features/startup_and_waits/#log-output-wait-strategy","text":"In some situations a container's log output is a simple way to determine if it is ready or not. For example, we can wait for a `Ready' message in the container's logs as follows: public GenericContainer containerWithLogWait = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ) . waitingFor ( Wait . forLogMessage ( \".*Ready to accept connections.*\\\\n\" , 1 ));","title":"Log output Wait Strategy"},{"location":"features/startup_and_waits/#other-wait-strategies","text":"For further options, check out the Wait convenience class, or the various subclasses of WaitStrategy . If none of these options meet your requirements, you can create your own subclass of AbstractWaitStrategy with an appropriate wait mechanism in waitUntilReady() . The GenericContainer.waitingFor() method accepts any valid WaitStrategy .","title":"Other Wait Strategies"},{"location":"features/startup_and_waits/#startup-check-strategies","text":"Ordinarily Testcontainers will check that the container has reached the running state and has not exited. In order to do that inspect is executed against the container and state parameter is extracted. All logic is implemented in StartupCheckStrategy child classes.","title":"Startup check Strategies"},{"location":"features/startup_and_waits/#running-startup-strategy-example","text":"This is the strategy used by default. Testcontainers just checks if container is running. Implemented in IsRunningStartupCheckStrategy class.","title":"Running startup strategy example"},{"location":"features/startup_and_waits/#one-shot-startup-strategy-example","text":"This strategy is intended for use with containers that only run briefly and exit of their own accord. As such, success is deemed to be when the container has stopped with exit code 0. Using one shot startup strategy public GenericContainer <?> bboxWithOneShot = new GenericContainer <> ( DockerImageName . parse ( \"busybox:1.31.1\" )) . withCommand ( String . format ( \"echo %s\" , HELLO_TESTCONTAINERS )) . withStartupCheckStrategy ( new OneShotStartupCheckStrategy (). withTimeout ( Duration . ofSeconds ( 3 )) );","title":"One shot startup strategy example"},{"location":"features/startup_and_waits/#indefinite-one-shot-startup-strategy-example","text":"Variant of one shot strategy that does not impose a timeout. Intended for situation such as when a long running task forms part of container startup. It has to be assumed that the container will stop of its own accord, either with a success or failure exit code. Using indefinite one shot startup strategy public GenericContainer <?> bboxWithIndefiniteOneShot = new GenericContainer <> ( DockerImageName . parse ( \"busybox:1.31.1\" ) ) . withCommand ( \"sh\" , \"-c\" , String . format ( \"sleep 5 && echo \\\"%s\\\"\" , HELLO_TESTCONTAINERS )) . withStartupCheckStrategy ( new IndefiniteWaitOneShotStartupCheckStrategy () );","title":"Indefinite one shot startup strategy example"},{"location":"features/startup_and_waits/#minimum-duration-startup-strategy-example","text":"Checks that the container is running and has been running for a defined minimum period of time. Using minimum duration strategy public GenericContainer <?> bboxWithMinimumDuration = new GenericContainer <> ( DockerImageName . parse ( \"busybox:1.31.1\" ) ) . withCommand ( \"sh\" , \"-c\" , String . format ( \"sleep 5 && echo \\\"%s\\\"\" , HELLO_TESTCONTAINERS )) . withStartupCheckStrategy ( new MinimumDurationRunningStartupCheckStrategy ( Duration . ofSeconds ( 1 )) );","title":"Minimum duration startup strategy example"},{"location":"features/startup_and_waits/#other-startup-strategies","text":"If none of these options meet your requirements, you can create your own subclass of StartupCheckStrategy with an appropriate startup check mechanism in waitUntilStartupSuccessful() . Or you can leave it as is and just implement the checkStartupState(DockerClient dockerClient, String containerId) if you still want to check state periodically.","title":"Other startup strategies"},{"location":"features/startup_and_waits/#depending-on-another-container","text":"Sometimes, a container relies on another container to be ready before it should start itself. An example of this might be a database that needs to be started before your application container can link to it. You can tell a container that it depends on another container by using the dependsOn method: Depending on another container public GenericContainer <?> redis = new GenericContainer <> ( \"redis:6-alpine\" ). withExposedPorts ( 6379 ); @Rule public GenericContainer <?> nginx = new GenericContainer <> ( \"nginx:1.27.0-alpine3.19-slim\" ) . dependsOn ( redis ) . withExposedPorts ( 80 );","title":"Depending on another container"},{"location":"modules/activemq/","text":"ActiveMQ Testcontainers module for ActiveMQ and Artemis . ActiveMQContainer's usage examples You can start an ActiveMQ Classic container instance from any Java application by using: Default ActiveMQ container ActiveMQContainer activemq = new ActiveMQContainer ( \"apache/activemq-classic:5.18.3\" ) With custom credentials: Setting custom credentials ActiveMQContainer activemq = new ActiveMQContainer ( \"apache/activemq-classic:5.18.3\" ) . withUser ( \"testcontainers\" ) . withPassword ( \"testcontainers\" ) ArtemisContainer's usage examples You can start an ActiveMQ Artemis container instance from any Java application by using: Default Artemis container ArtemisContainer artemis = new ArtemisContainer ( \"apache/activemq-artemis:2.30.0-alpine\" ) With custom credentials: Setting custom credentials ArtemisContainer artemis = new ArtemisContainer ( \"apache/activemq-artemis:2.30.0-alpine\" ) . withUser ( \"testcontainers\" ) . withPassword ( \"testcontainers\" ) With anonymous login: Allow anonymous login ArtemisContainer artemis = new ArtemisContainer ( \"apache/activemq-artemis:2.30.0-alpine\" ) . withEnv ( \"ANONYMOUS_LOGIN\" , \"true\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:activemq:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> activemq </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"ActiveMQ"},{"location":"modules/activemq/#activemq","text":"Testcontainers module for ActiveMQ and Artemis .","title":"ActiveMQ"},{"location":"modules/activemq/#activemqcontainers-usage-examples","text":"You can start an ActiveMQ Classic container instance from any Java application by using: Default ActiveMQ container ActiveMQContainer activemq = new ActiveMQContainer ( \"apache/activemq-classic:5.18.3\" ) With custom credentials: Setting custom credentials ActiveMQContainer activemq = new ActiveMQContainer ( \"apache/activemq-classic:5.18.3\" ) . withUser ( \"testcontainers\" ) . withPassword ( \"testcontainers\" )","title":"ActiveMQContainer's usage examples"},{"location":"modules/activemq/#artemiscontainers-usage-examples","text":"You can start an ActiveMQ Artemis container instance from any Java application by using: Default Artemis container ArtemisContainer artemis = new ArtemisContainer ( \"apache/activemq-artemis:2.30.0-alpine\" ) With custom credentials: Setting custom credentials ArtemisContainer artemis = new ArtemisContainer ( \"apache/activemq-artemis:2.30.0-alpine\" ) . withUser ( \"testcontainers\" ) . withPassword ( \"testcontainers\" ) With anonymous login: Allow anonymous login ArtemisContainer artemis = new ArtemisContainer ( \"apache/activemq-artemis:2.30.0-alpine\" ) . withEnv ( \"ANONYMOUS_LOGIN\" , \"true\" )","title":"ArtemisContainer's usage examples"},{"location":"modules/activemq/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:activemq:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> activemq </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/azure/","text":"Azure Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for the Microsoft Azure's SDK . Currently, the module supports Azurite , Azure Event Hubs , Azure Service Bus and CosmosDB emulators. In order to use them, you should use the following classes: Class Container Image AzuriteContainer mcr.microsoft.com/azure-storage/azurite EventHubsEmulatorContainer mcr.microsoft.com/azure-messaging/eventhubs-emulator ServiceBusEmulatorContainer mcr.microsoft.com/azure-messaging/servicebus-emulator CosmosDBEmulatorContainer mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator Usage example Azurite Storage Emulator Start Azurite Emulator during a test: Starting an Azurite container AzuriteContainer emulator = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) Note SSL configuration is possible using the withSsl(MountableFile, String) and withSsl(MountableFile, MountableFile) methods. If the tested application needs to use more than one set of credentials, the container can be configured to use custom credentials. Please see some examples below. Starting an Azurite Blob container with one account and two keys AzuriteContainer emulator = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) . withEnv ( \"AZURITE_ACCOUNTS\" , \"account1:key1:key2\" ) Starting an Azurite Blob container with more accounts and keys AzuriteContainer emulator = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) . withEnv ( \"AZURITE_ACCOUNTS\" , \"account1:key1;account2:key2\" ) Using with Blob Build Azure Blob client: Build Azure Blob Service client BlobServiceClient blobServiceClient = new BlobServiceClientBuilder () . connectionString ( container . getConnectionString ()) . buildClient (); In case the application needs to use custom credentials, we can obtain them with a different method: Obtain connection string with non-default credentials String connectionString1 = emulator . getConnectionString ( \"account1\" , \"key1\" ); // the second account will not have access to the same container String connectionString2 = emulator . getConnectionString ( \"account2\" , \"key2\" ); Using with Queue Build Azure Queue client: Build Azure Queue Service client QueueServiceClient queueServiceClient = new QueueServiceClientBuilder () . connectionString ( container . getConnectionString ()) . buildClient (); Note We can use custom credentials the same way as defined in the Blob section. Using with Table Build Azure Table client: Build Azure Table Service client TableServiceClient tableServiceClient = new TableServiceClientBuilder () . connectionString ( container . getConnectionString ()) . buildClient (); Note We can use custom credentials the same way as defined in the Blob section. Azure Event Hubs Emulator Configuring the Azure Event Hubs Emulator container { \"UserConfig\" : { \"NamespaceConfig\" : [ { \"Type\" : \"EventHub\" , \"Name\" : \"emulatorNs1\" , \"Entities\" : [ { \"Name\" : \"eh1\" , \"PartitionCount\" : \"1\" , \"ConsumerGroups\" : [ { \"Name\" : \"cg1\" } ] } ] } ], \"LoggingConfig\" : { \"Type\" : \"File\" } } } Start Azure Event Hubs Emulator during a test: Setting up a network public Network network = Network . newNetwork (); Starting an Azurite container as dependency public AzuriteContainer azuriteContainer = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) . withNetwork ( network ); Starting an Azure Event Hubs Emulator container public EventHubsEmulatorContainer emulator = new EventHubsEmulatorContainer ( \"mcr.microsoft.com/azure-messaging/eventhubs-emulator:2.0.1\" ) . acceptLicense () . withNetwork ( network ) . withConfig ( MountableFile . forClasspathResource ( \"/eventhubs_config.json\" )) . withAzuriteContainer ( azuriteContainer ); Using Azure Event Hubs clients Configure the consumer and the producer clients: Configuring the clients EventHubProducerClient producer = new EventHubClientBuilder () . connectionString ( emulator . getConnectionString ()) . fullyQualifiedNamespace ( \"emulatorNs1\" ) . eventHubName ( \"eh1\" ) . buildProducerClient (); EventHubConsumerClient consumer = new EventHubClientBuilder () . connectionString ( emulator . getConnectionString ()) . fullyQualifiedNamespace ( \"emulatorNs1\" ) . eventHubName ( \"eh1\" ) . consumerGroup ( \"cg1\" ) . buildConsumerClient () Azure Service Bus Emulator Configuring the Azure Service Bus Emulator container { \"UserConfig\" : { \"Namespaces\" : [ { \"Name\" : \"sbemulatorns\" , \"Queues\" : [ { \"Name\" : \"queue.1\" , \"Properties\" : { \"DeadLetteringOnMessageExpiration\" : false , \"DefaultMessageTimeToLive\" : \"PT1H\" , \"DuplicateDetectionHistoryTimeWindow\" : \"PT20S\" , \"ForwardDeadLetteredMessagesTo\" : \"\" , \"ForwardTo\" : \"\" , \"LockDuration\" : \"PT1M\" , \"MaxDeliveryCount\" : 3 , \"RequiresDuplicateDetection\" : false , \"RequiresSession\" : false } } ], \"Topics\" : [] } ], \"Logging\" : { \"Type\" : \"File\" } } } Start Azure Service Bus Emulator during a test: Setting up a network public Network network = Network . newNetwork (); Starting a SQL Server container as dependency public MSSQLServerContainer <?> mssqlServerContainer = new MSSQLServerContainer <> ( \"mcr.microsoft.com/mssql/server:2022-CU14-ubuntu-22.04\" ) . acceptLicense () . withPassword ( \"yourStrong(!)Password\" ) . withCreateContainerCmdModifier ( cmd -> { cmd . getHostConfig (). withCapAdd ( Capability . SYS_PTRACE ); }) . withNetwork ( network ); Starting a Service Bus Emulator container public ServiceBusEmulatorContainer emulator = new ServiceBusEmulatorContainer ( \"mcr.microsoft.com/azure-messaging/servicebus-emulator:1.0.1\" ) . acceptLicense () . withConfig ( MountableFile . forClasspathResource ( \"/service-bus-config.json\" )) . withNetwork ( network ) . withMsSqlServerContainer ( mssqlServerContainer ); Using Azure Service Bus clients Configure the sender and the processor clients: Configuring the sender client ServiceBusSenderClient senderClient = new ServiceBusClientBuilder () . connectionString ( emulator . getConnectionString ()) . sender () . queueName ( \"queue.1\" ) . buildClient (); Configuring the processor client ServiceBusProcessorClient processorClient = new ServiceBusClientBuilder () . connectionString ( emulator . getConnectionString ()) . processor () . queueName ( \"queue.1\" ) . processMessage ( messageConsumer ) . processError ( errorConsumer ) . buildProcessorClient (); CosmosDB Start Azure CosmosDB Emulator during a test: Starting an Azure CosmosDB Emulator container public CosmosDBEmulatorContainer emulator = new CosmosDBEmulatorContainer ( DockerImageName . parse ( \"mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator:latest\" ) ); Prepare KeyStore to use for SSL. Building KeyStore from certificate within container Path keyStoreFile = tempFolder . newFile ( \"azure-cosmos-emulator.keystore\" ). toPath (); KeyStore keyStore = emulator . buildNewKeyStore (); keyStore . store ( new FileOutputStream ( keyStoreFile . toFile ()), emulator . getEmulatorKey (). toCharArray ()); Set system trust-store parameters to use already built KeyStore: Set system trust-store parameters System . setProperty ( \"javax.net.ssl.trustStore\" , keyStoreFile . toString ()); System . setProperty ( \"javax.net.ssl.trustStorePassword\" , emulator . getEmulatorKey ()); System . setProperty ( \"javax.net.ssl.trustStoreType\" , \"PKCS12\" ); Build Azure CosmosDB client: Build Azure CosmosDB client CosmosAsyncClient client = new CosmosClientBuilder () . gatewayMode () . endpointDiscoveryEnabled ( false ) . endpoint ( emulator . getEmulatorEndpoint ()) . key ( emulator . getEmulatorKey ()) . buildAsyncClient (); Test against the Emulator: Testing against Azure CosmosDB Emulator container CosmosDatabaseResponse databaseResponse = client . createDatabaseIfNotExists ( \"Azure\" ). block (); assertThat ( databaseResponse . getStatusCode ()). isEqualTo ( 201 ); CosmosContainerResponse containerResponse = client . getDatabase ( \"Azure\" ) . createContainerIfNotExists ( \"ServiceContainer\" , \"/name\" ) . block (); assertThat ( containerResponse . getStatusCode ()). isEqualTo ( 201 ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:azure:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> azure </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Azure Module"},{"location":"modules/azure/#azure-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for the Microsoft Azure's SDK . Currently, the module supports Azurite , Azure Event Hubs , Azure Service Bus and CosmosDB emulators. In order to use them, you should use the following classes: Class Container Image AzuriteContainer mcr.microsoft.com/azure-storage/azurite EventHubsEmulatorContainer mcr.microsoft.com/azure-messaging/eventhubs-emulator ServiceBusEmulatorContainer mcr.microsoft.com/azure-messaging/servicebus-emulator CosmosDBEmulatorContainer mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator","title":"Azure Module"},{"location":"modules/azure/#usage-example","text":"","title":"Usage example"},{"location":"modules/azure/#azurite-storage-emulator","text":"Start Azurite Emulator during a test: Starting an Azurite container AzuriteContainer emulator = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) Note SSL configuration is possible using the withSsl(MountableFile, String) and withSsl(MountableFile, MountableFile) methods. If the tested application needs to use more than one set of credentials, the container can be configured to use custom credentials. Please see some examples below. Starting an Azurite Blob container with one account and two keys AzuriteContainer emulator = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) . withEnv ( \"AZURITE_ACCOUNTS\" , \"account1:key1:key2\" ) Starting an Azurite Blob container with more accounts and keys AzuriteContainer emulator = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) . withEnv ( \"AZURITE_ACCOUNTS\" , \"account1:key1;account2:key2\" )","title":"Azurite Storage Emulator"},{"location":"modules/azure/#using-with-blob","text":"Build Azure Blob client: Build Azure Blob Service client BlobServiceClient blobServiceClient = new BlobServiceClientBuilder () . connectionString ( container . getConnectionString ()) . buildClient (); In case the application needs to use custom credentials, we can obtain them with a different method: Obtain connection string with non-default credentials String connectionString1 = emulator . getConnectionString ( \"account1\" , \"key1\" ); // the second account will not have access to the same container String connectionString2 = emulator . getConnectionString ( \"account2\" , \"key2\" );","title":"Using with Blob"},{"location":"modules/azure/#using-with-queue","text":"Build Azure Queue client: Build Azure Queue Service client QueueServiceClient queueServiceClient = new QueueServiceClientBuilder () . connectionString ( container . getConnectionString ()) . buildClient (); Note We can use custom credentials the same way as defined in the Blob section.","title":"Using with Queue"},{"location":"modules/azure/#using-with-table","text":"Build Azure Table client: Build Azure Table Service client TableServiceClient tableServiceClient = new TableServiceClientBuilder () . connectionString ( container . getConnectionString ()) . buildClient (); Note We can use custom credentials the same way as defined in the Blob section.","title":"Using with Table"},{"location":"modules/azure/#azure-event-hubs-emulator","text":"Configuring the Azure Event Hubs Emulator container { \"UserConfig\" : { \"NamespaceConfig\" : [ { \"Type\" : \"EventHub\" , \"Name\" : \"emulatorNs1\" , \"Entities\" : [ { \"Name\" : \"eh1\" , \"PartitionCount\" : \"1\" , \"ConsumerGroups\" : [ { \"Name\" : \"cg1\" } ] } ] } ], \"LoggingConfig\" : { \"Type\" : \"File\" } } } Start Azure Event Hubs Emulator during a test: Setting up a network public Network network = Network . newNetwork (); Starting an Azurite container as dependency public AzuriteContainer azuriteContainer = new AzuriteContainer ( \"mcr.microsoft.com/azure-storage/azurite:3.33.0\" ) . withNetwork ( network ); Starting an Azure Event Hubs Emulator container public EventHubsEmulatorContainer emulator = new EventHubsEmulatorContainer ( \"mcr.microsoft.com/azure-messaging/eventhubs-emulator:2.0.1\" ) . acceptLicense () . withNetwork ( network ) . withConfig ( MountableFile . forClasspathResource ( \"/eventhubs_config.json\" )) . withAzuriteContainer ( azuriteContainer );","title":"Azure Event Hubs Emulator"},{"location":"modules/azure/#using-azure-event-hubs-clients","text":"Configure the consumer and the producer clients: Configuring the clients EventHubProducerClient producer = new EventHubClientBuilder () . connectionString ( emulator . getConnectionString ()) . fullyQualifiedNamespace ( \"emulatorNs1\" ) . eventHubName ( \"eh1\" ) . buildProducerClient (); EventHubConsumerClient consumer = new EventHubClientBuilder () . connectionString ( emulator . getConnectionString ()) . fullyQualifiedNamespace ( \"emulatorNs1\" ) . eventHubName ( \"eh1\" ) . consumerGroup ( \"cg1\" ) . buildConsumerClient ()","title":"Using Azure Event Hubs clients"},{"location":"modules/azure/#azure-service-bus-emulator","text":"Configuring the Azure Service Bus Emulator container { \"UserConfig\" : { \"Namespaces\" : [ { \"Name\" : \"sbemulatorns\" , \"Queues\" : [ { \"Name\" : \"queue.1\" , \"Properties\" : { \"DeadLetteringOnMessageExpiration\" : false , \"DefaultMessageTimeToLive\" : \"PT1H\" , \"DuplicateDetectionHistoryTimeWindow\" : \"PT20S\" , \"ForwardDeadLetteredMessagesTo\" : \"\" , \"ForwardTo\" : \"\" , \"LockDuration\" : \"PT1M\" , \"MaxDeliveryCount\" : 3 , \"RequiresDuplicateDetection\" : false , \"RequiresSession\" : false } } ], \"Topics\" : [] } ], \"Logging\" : { \"Type\" : \"File\" } } } Start Azure Service Bus Emulator during a test: Setting up a network public Network network = Network . newNetwork (); Starting a SQL Server container as dependency public MSSQLServerContainer <?> mssqlServerContainer = new MSSQLServerContainer <> ( \"mcr.microsoft.com/mssql/server:2022-CU14-ubuntu-22.04\" ) . acceptLicense () . withPassword ( \"yourStrong(!)Password\" ) . withCreateContainerCmdModifier ( cmd -> { cmd . getHostConfig (). withCapAdd ( Capability . SYS_PTRACE ); }) . withNetwork ( network ); Starting a Service Bus Emulator container public ServiceBusEmulatorContainer emulator = new ServiceBusEmulatorContainer ( \"mcr.microsoft.com/azure-messaging/servicebus-emulator:1.0.1\" ) . acceptLicense () . withConfig ( MountableFile . forClasspathResource ( \"/service-bus-config.json\" )) . withNetwork ( network ) . withMsSqlServerContainer ( mssqlServerContainer );","title":"Azure Service Bus Emulator"},{"location":"modules/azure/#using-azure-service-bus-clients","text":"Configure the sender and the processor clients: Configuring the sender client ServiceBusSenderClient senderClient = new ServiceBusClientBuilder () . connectionString ( emulator . getConnectionString ()) . sender () . queueName ( \"queue.1\" ) . buildClient (); Configuring the processor client ServiceBusProcessorClient processorClient = new ServiceBusClientBuilder () . connectionString ( emulator . getConnectionString ()) . processor () . queueName ( \"queue.1\" ) . processMessage ( messageConsumer ) . processError ( errorConsumer ) . buildProcessorClient ();","title":"Using Azure Service Bus clients"},{"location":"modules/azure/#cosmosdb","text":"Start Azure CosmosDB Emulator during a test: Starting an Azure CosmosDB Emulator container public CosmosDBEmulatorContainer emulator = new CosmosDBEmulatorContainer ( DockerImageName . parse ( \"mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator:latest\" ) ); Prepare KeyStore to use for SSL. Building KeyStore from certificate within container Path keyStoreFile = tempFolder . newFile ( \"azure-cosmos-emulator.keystore\" ). toPath (); KeyStore keyStore = emulator . buildNewKeyStore (); keyStore . store ( new FileOutputStream ( keyStoreFile . toFile ()), emulator . getEmulatorKey (). toCharArray ()); Set system trust-store parameters to use already built KeyStore: Set system trust-store parameters System . setProperty ( \"javax.net.ssl.trustStore\" , keyStoreFile . toString ()); System . setProperty ( \"javax.net.ssl.trustStorePassword\" , emulator . getEmulatorKey ()); System . setProperty ( \"javax.net.ssl.trustStoreType\" , \"PKCS12\" ); Build Azure CosmosDB client: Build Azure CosmosDB client CosmosAsyncClient client = new CosmosClientBuilder () . gatewayMode () . endpointDiscoveryEnabled ( false ) . endpoint ( emulator . getEmulatorEndpoint ()) . key ( emulator . getEmulatorKey ()) . buildAsyncClient (); Test against the Emulator: Testing against Azure CosmosDB Emulator container CosmosDatabaseResponse databaseResponse = client . createDatabaseIfNotExists ( \"Azure\" ). block (); assertThat ( databaseResponse . getStatusCode ()). isEqualTo ( 201 ); CosmosContainerResponse containerResponse = client . getDatabase ( \"Azure\" ) . createContainerIfNotExists ( \"ServiceContainer\" , \"/name\" ) . block (); assertThat ( containerResponse . getStatusCode ()). isEqualTo ( 201 );","title":"CosmosDB"},{"location":"modules/azure/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:azure:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> azure </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/chromadb/","text":"ChromaDB Testcontainers module for ChromaDB ChromaDB's usage examples You can start a ChromaDB container instance from any Java application by using: Default ChromaDB container ChromaDBContainer chroma = new ChromaDBContainer ( \"chromadb/chroma:0.4.23\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:chromadb:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> chromadb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"ChromaDB"},{"location":"modules/chromadb/#chromadb","text":"Testcontainers module for ChromaDB","title":"ChromaDB"},{"location":"modules/chromadb/#chromadbs-usage-examples","text":"You can start a ChromaDB container instance from any Java application by using: Default ChromaDB container ChromaDBContainer chroma = new ChromaDBContainer ( \"chromadb/chroma:0.4.23\" )","title":"ChromaDB's usage examples"},{"location":"modules/chromadb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:chromadb:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> chromadb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/consul/","text":"Hashicorp Consul Module Testcontainers module for Consul . Consul is a tool for managing key value properties. More information on Consul here . Usage example Running Consul in your Junit tests package org.testcontainers.consul ; import com.ecwid.consul.v1.ConsulClient ; import com.ecwid.consul.v1.Response ; import com.ecwid.consul.v1.kv.model.GetValue ; import io.restassured.RestAssured ; import org.junit.ClassRule ; import org.junit.Test ; import org.testcontainers.containers.GenericContainer ; import java.io.IOException ; import java.nio.charset.StandardCharsets ; import java.util.Base64 ; import java.util.HashMap ; import java.util.Map ; import static org.assertj.core.api.Assertions.assertThat ; /** * This test shows the pattern to use the ConsulContainer @ClassRule for a junit test. It also has tests that ensure * the properties were added correctly by reading from Consul with the CLI and over HTTP. */ public class ConsulContainerTest { @ClassRule public static ConsulContainer consulContainer = new ConsulContainer ( \"hashicorp/consul:1.15\" ) . withConsulCommand ( \"kv put config/testing1 value123\" ); @Test public void readFirstPropertyPathWithCli () throws IOException , InterruptedException { GenericContainer . ExecResult result = consulContainer . execInContainer ( \"consul\" , \"kv\" , \"get\" , \"config/testing1\" ); final String output = result . getStdout (). replaceAll ( \"\\\\r?\\\\n\" , \"\" ); assertThat ( output ). contains ( \"value123\" ); } @Test public void readFirstSecretPathOverHttpApi () { io . restassured . response . Response response = RestAssured . given () . when () . get ( \"http://\" + getHostAndPort () + \"/v1/kv/config/testing1\" ) . andReturn (); assertThat ( response . body (). jsonPath (). getString ( \"[0].Value\" )) . isEqualTo ( Base64 . getEncoder (). encodeToString ( \"value123\" . getBytes ( StandardCharsets . UTF_8 ))); } @Test public void writeAndReadMultipleValuesUsingClient () { final ConsulClient consulClient = new ConsulClient ( consulContainer . getHost (), consulContainer . getFirstMappedPort () ); final Map < String , String > properties = new HashMap <> (); properties . put ( \"value\" , \"world\" ); properties . put ( \"other_value\" , \"another world\" ); // Write operation properties . forEach (( key , value ) -> { Response < Boolean > writeResponse = consulClient . setKVValue ( key , value ); assertThat ( writeResponse . getValue ()). isTrue (); }); // Read operation properties . forEach (( key , value ) -> { Response < GetValue > readResponse = consulClient . getKVValue ( key ); assertThat ( readResponse . getValue (). getDecodedValue ()). isEqualTo ( value ); }); } private String getHostAndPort () { return consulContainer . getHost () + \":\" + consulContainer . getMappedPort ( 8500 ); } } Why Consul in Junit tests? With the increasing popularity of Consul and config externalization, applications are now needing to source properties from Consul. This can prove challenging in the development phase without a running Consul instance readily on hand. This library aims to solve your apps integration testing with Consul. You can also use it to test how your application behaves with Consul by writing different test scenarios in Junit. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:consul:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> consul </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Hashicorp Consul Module"},{"location":"modules/consul/#hashicorp-consul-module","text":"Testcontainers module for Consul . Consul is a tool for managing key value properties. More information on Consul here .","title":"Hashicorp Consul Module"},{"location":"modules/consul/#usage-example","text":"Running Consul in your Junit tests package org.testcontainers.consul ; import com.ecwid.consul.v1.ConsulClient ; import com.ecwid.consul.v1.Response ; import com.ecwid.consul.v1.kv.model.GetValue ; import io.restassured.RestAssured ; import org.junit.ClassRule ; import org.junit.Test ; import org.testcontainers.containers.GenericContainer ; import java.io.IOException ; import java.nio.charset.StandardCharsets ; import java.util.Base64 ; import java.util.HashMap ; import java.util.Map ; import static org.assertj.core.api.Assertions.assertThat ; /** * This test shows the pattern to use the ConsulContainer @ClassRule for a junit test. It also has tests that ensure * the properties were added correctly by reading from Consul with the CLI and over HTTP. */ public class ConsulContainerTest { @ClassRule public static ConsulContainer consulContainer = new ConsulContainer ( \"hashicorp/consul:1.15\" ) . withConsulCommand ( \"kv put config/testing1 value123\" ); @Test public void readFirstPropertyPathWithCli () throws IOException , InterruptedException { GenericContainer . ExecResult result = consulContainer . execInContainer ( \"consul\" , \"kv\" , \"get\" , \"config/testing1\" ); final String output = result . getStdout (). replaceAll ( \"\\\\r?\\\\n\" , \"\" ); assertThat ( output ). contains ( \"value123\" ); } @Test public void readFirstSecretPathOverHttpApi () { io . restassured . response . Response response = RestAssured . given () . when () . get ( \"http://\" + getHostAndPort () + \"/v1/kv/config/testing1\" ) . andReturn (); assertThat ( response . body (). jsonPath (). getString ( \"[0].Value\" )) . isEqualTo ( Base64 . getEncoder (). encodeToString ( \"value123\" . getBytes ( StandardCharsets . UTF_8 ))); } @Test public void writeAndReadMultipleValuesUsingClient () { final ConsulClient consulClient = new ConsulClient ( consulContainer . getHost (), consulContainer . getFirstMappedPort () ); final Map < String , String > properties = new HashMap <> (); properties . put ( \"value\" , \"world\" ); properties . put ( \"other_value\" , \"another world\" ); // Write operation properties . forEach (( key , value ) -> { Response < Boolean > writeResponse = consulClient . setKVValue ( key , value ); assertThat ( writeResponse . getValue ()). isTrue (); }); // Read operation properties . forEach (( key , value ) -> { Response < GetValue > readResponse = consulClient . getKVValue ( key ); assertThat ( readResponse . getValue (). getDecodedValue ()). isEqualTo ( value ); }); } private String getHostAndPort () { return consulContainer . getHost () + \":\" + consulContainer . getMappedPort ( 8500 ); } }","title":"Usage example"},{"location":"modules/consul/#why-consul-in-junit-tests","text":"With the increasing popularity of Consul and config externalization, applications are now needing to source properties from Consul. This can prove challenging in the development phase without a running Consul instance readily on hand. This library aims to solve your apps integration testing with Consul. You can also use it to test how your application behaves with Consul by writing different test scenarios in Junit.","title":"Why Consul in Junit tests?"},{"location":"modules/consul/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:consul:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> consul </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/docker_compose/","text":"Docker Compose Module Benefits Similar to generic container support, it's also possible to run a bespoke set of services specified in a docker-compose.yml file. This is especially useful for projects where Docker Compose is already used in development or other environments to define services that an application may be dependent upon. The ComposeContainer leverages Compose V2 , making it easy to use the same dependencies from the development environment within tests. Example A single class ComposeContainer , defined based on a docker-compose.yml file, should be sufficient to launch any number of services required by our tests: Create a ComposeContainer public ComposeContainer environment = new ComposeContainer ( new File ( \"src/test/resources/composev2/compose-test.yml\" ) ) . withExposedService ( \"redis-1\" , REDIS_PORT ) . withExposedService ( \"db-1\" , 3306 ); Note Make sure the service names use a - rather than _ as separator. In this example, Docker Compose file should have content such as: services : redis : image : redis db : image : mysql:8.0.36 Note that it is not necessary to define ports to be exposed in the YAML file, as this would inhibit the reuse/inclusion of the file in other contexts. Instead, Testcontainers will spin up a small ambassador container, which will proxy between the Compose-managed containers and ports that are accessible to our tests. ComposeContainer vs DockerComposeContainer So far, we discussed ComposeContainer , which supports docker compose version 2 . On the other hand, DockerComposeContainer utilizes Compose V1, which has been marked deprecated by Docker. The two APIs are quite similar, and most examples provided on this page can be applied to both of them. Accessing a Container ComposeContainer provides methods for discovering how your tests can interact with the containers: getServiceHost(serviceName, servicePort) returns the IP address where the container is listening (via an ambassador container) getServicePort(serviceName, servicePort) returns the Docker mapped port for a port that has been exposed (via an ambassador container) Let's use this API to create the URL that will enable our tests to access the Redis service: Access a Service's host and port String serviceHost = environment . getServiceHost ( \"redis-1\" , REDIS_PORT ); int serviceWithInstancePort = environment . getServicePort ( \"redis-1\" , REDIS_PORT ); Wait Strategies and Startup Timeouts Ordinarily Testcontainers will wait for up to 60 seconds for each exposed container's first mapped network port to start listening. This simple measure provides a basic check whether a container is ready for use. There are overloaded withExposedService methods that take a WaitStrategy where we can specify a timeout strategy per container. We can either use the fluent API to crate a custom strategy or use one of the already existing ones, accessible via the static factory methods from of the Wait class. For instance, we can wait for exposed port and set a custom timeout: Wait for the exposed port and use a custom timeout ComposeContainer compose = new ComposeContainer ( new File ( \"src/test/resources/composev2/compose-test.yml\" )) . withExposedService ( \"redis-1\" , REDIS_PORT , Wait . forListeningPort (). withStartupTimeout ( Duration . ofSeconds ( 30 )) ) Needless to say, we can define different strategies for each service in our Docker Compose setup. For example, our Redis container can wait for a successful redis-cli command, while our db service waits for a specific log message: Wait for a custom command and a log message ComposeContainer compose = new ComposeContainer ( new File ( \"src/test/resources/composev2/compose-test.yml\" )) . withExposedService ( \"redis-1\" , REDIS_PORT , Wait . forSuccessfulCommand ( \"redis-cli ping\" )) . withExposedService ( \"db-1\" , 3306 , Wait . forLogMessage ( \".*ready for connections.*\\\\n\" , 1 )) The 'Local Compose' Mode We can override Testcontainers' default behaviour and make it use a docker-compose binary installed on the local machine. This will generally yield an experience that is closer to running docker compose locally, with the caveat that Docker Compose needs to be present on dev and CI machines. Use ComposeContainer in 'Local Compose' mode ComposeContainer compose = new ComposeContainer ( COMPOSE_FILE ) . withLocalCompose ( true ) Build Working Directory We can select what files should be copied only via withCopyFilesInContainer : Use ComposeContainer in 'Local Compose' mode ComposeContainer environment = new ComposeContainer ( new File ( \"src/test/resources/compose-file-copy-inclusions/compose-test-only.yml\" ) ) . withExposedService ( \"app\" , 8080 ) . withCopyFilesInContainer ( \"Dockerfile\" , \"EnvVariableRestEndpoint.java\" , \"test\" ) In this example, only docker compose and env files are copied over into the container that will run the Docker Compose file. By default, all files in the same directory as the compose file are copied over. We can use file and directory references. They are always resolved relative to the directory where the compose file resides. Note This can be used with DockerComposeContainer and ComposeContainer , but only in the containerized Compose (not with Local Compose mode) . Using private repositories in Docker compose When Docker Compose is used in container mode (not local), it needs to be made aware of Docker settings for private repositories. By default, those setting are located in $HOME/.docker/config.json . There are 3 ways to specify location of the config.json for Docker Compose: Use DOCKER_CONFIG_FILE environment variable. export DOCKER_CONFIG_FILE=/some/location/config.json Use dockerConfigFile java property java -DdockerConfigFile=/some/location/config.json Don't specify anything. In this case default location $HOME/.docker/config.json , if present, will be used. Docker Compose and Credential Store / Credential Helpers Modern Docker tends to store credentials using the credential store/helper mechanism rather than storing credentials in Docker's configuration file. So, your config.json may look something like: { \"auths\" : { \"https://index.docker.io/v1/\" : { } }, \"credsStore\" : \"osxkeychain\" } When run inside a container, Docker Compose cannot access the Keychain, thus making the configuration useless. To work around this problem, there are two options: Putting auths in a config file Create a config.json in separate location with real authentication keys, like: { \"auths\" : { \"https://index.docker.io/v1/\" : { \"auth\" : \"QWEADSZXC...\" } }, \"credsStore\" : \"osxkeychain\" } and specify the location to Testcontainers using any of the two first methods from above. Using 'local compose' mode Local Compose mode , mentioned above, will allow compose to directly access the Docker auth system (to the same extent that running the docker-compose CLI manually works). Adding this module to your project dependencies Docker Compose support is part of the core Testcontainers library. Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:testcontainers:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Docker Compose Module"},{"location":"modules/docker_compose/#docker-compose-module","text":"","title":"Docker Compose Module"},{"location":"modules/docker_compose/#benefits","text":"Similar to generic container support, it's also possible to run a bespoke set of services specified in a docker-compose.yml file. This is especially useful for projects where Docker Compose is already used in development or other environments to define services that an application may be dependent upon. The ComposeContainer leverages Compose V2 , making it easy to use the same dependencies from the development environment within tests.","title":"Benefits"},{"location":"modules/docker_compose/#example","text":"A single class ComposeContainer , defined based on a docker-compose.yml file, should be sufficient to launch any number of services required by our tests: Create a ComposeContainer public ComposeContainer environment = new ComposeContainer ( new File ( \"src/test/resources/composev2/compose-test.yml\" ) ) . withExposedService ( \"redis-1\" , REDIS_PORT ) . withExposedService ( \"db-1\" , 3306 ); Note Make sure the service names use a - rather than _ as separator. In this example, Docker Compose file should have content such as: services : redis : image : redis db : image : mysql:8.0.36 Note that it is not necessary to define ports to be exposed in the YAML file, as this would inhibit the reuse/inclusion of the file in other contexts. Instead, Testcontainers will spin up a small ambassador container, which will proxy between the Compose-managed containers and ports that are accessible to our tests.","title":"Example"},{"location":"modules/docker_compose/#composecontainer-vs-dockercomposecontainer","text":"So far, we discussed ComposeContainer , which supports docker compose version 2 . On the other hand, DockerComposeContainer utilizes Compose V1, which has been marked deprecated by Docker. The two APIs are quite similar, and most examples provided on this page can be applied to both of them.","title":"ComposeContainer vs DockerComposeContainer"},{"location":"modules/docker_compose/#accessing-a-container","text":"ComposeContainer provides methods for discovering how your tests can interact with the containers: getServiceHost(serviceName, servicePort) returns the IP address where the container is listening (via an ambassador container) getServicePort(serviceName, servicePort) returns the Docker mapped port for a port that has been exposed (via an ambassador container) Let's use this API to create the URL that will enable our tests to access the Redis service: Access a Service's host and port String serviceHost = environment . getServiceHost ( \"redis-1\" , REDIS_PORT ); int serviceWithInstancePort = environment . getServicePort ( \"redis-1\" , REDIS_PORT );","title":"Accessing a Container"},{"location":"modules/docker_compose/#wait-strategies-and-startup-timeouts","text":"Ordinarily Testcontainers will wait for up to 60 seconds for each exposed container's first mapped network port to start listening. This simple measure provides a basic check whether a container is ready for use. There are overloaded withExposedService methods that take a WaitStrategy where we can specify a timeout strategy per container. We can either use the fluent API to crate a custom strategy or use one of the already existing ones, accessible via the static factory methods from of the Wait class. For instance, we can wait for exposed port and set a custom timeout: Wait for the exposed port and use a custom timeout ComposeContainer compose = new ComposeContainer ( new File ( \"src/test/resources/composev2/compose-test.yml\" )) . withExposedService ( \"redis-1\" , REDIS_PORT , Wait . forListeningPort (). withStartupTimeout ( Duration . ofSeconds ( 30 )) ) Needless to say, we can define different strategies for each service in our Docker Compose setup. For example, our Redis container can wait for a successful redis-cli command, while our db service waits for a specific log message: Wait for a custom command and a log message ComposeContainer compose = new ComposeContainer ( new File ( \"src/test/resources/composev2/compose-test.yml\" )) . withExposedService ( \"redis-1\" , REDIS_PORT , Wait . forSuccessfulCommand ( \"redis-cli ping\" )) . withExposedService ( \"db-1\" , 3306 , Wait . forLogMessage ( \".*ready for connections.*\\\\n\" , 1 ))","title":"Wait Strategies and Startup Timeouts"},{"location":"modules/docker_compose/#the-local-compose-mode","text":"We can override Testcontainers' default behaviour and make it use a docker-compose binary installed on the local machine. This will generally yield an experience that is closer to running docker compose locally, with the caveat that Docker Compose needs to be present on dev and CI machines. Use ComposeContainer in 'Local Compose' mode ComposeContainer compose = new ComposeContainer ( COMPOSE_FILE ) . withLocalCompose ( true )","title":"The 'Local Compose' Mode"},{"location":"modules/docker_compose/#build-working-directory","text":"We can select what files should be copied only via withCopyFilesInContainer : Use ComposeContainer in 'Local Compose' mode ComposeContainer environment = new ComposeContainer ( new File ( \"src/test/resources/compose-file-copy-inclusions/compose-test-only.yml\" ) ) . withExposedService ( \"app\" , 8080 ) . withCopyFilesInContainer ( \"Dockerfile\" , \"EnvVariableRestEndpoint.java\" , \"test\" ) In this example, only docker compose and env files are copied over into the container that will run the Docker Compose file. By default, all files in the same directory as the compose file are copied over. We can use file and directory references. They are always resolved relative to the directory where the compose file resides. Note This can be used with DockerComposeContainer and ComposeContainer , but only in the containerized Compose (not with Local Compose mode) .","title":"Build Working Directory"},{"location":"modules/docker_compose/#using-private-repositories-in-docker-compose","text":"When Docker Compose is used in container mode (not local), it needs to be made aware of Docker settings for private repositories. By default, those setting are located in $HOME/.docker/config.json . There are 3 ways to specify location of the config.json for Docker Compose: Use DOCKER_CONFIG_FILE environment variable. export DOCKER_CONFIG_FILE=/some/location/config.json Use dockerConfigFile java property java -DdockerConfigFile=/some/location/config.json Don't specify anything. In this case default location $HOME/.docker/config.json , if present, will be used. Docker Compose and Credential Store / Credential Helpers Modern Docker tends to store credentials using the credential store/helper mechanism rather than storing credentials in Docker's configuration file. So, your config.json may look something like: { \"auths\" : { \"https://index.docker.io/v1/\" : { } }, \"credsStore\" : \"osxkeychain\" } When run inside a container, Docker Compose cannot access the Keychain, thus making the configuration useless. To work around this problem, there are two options:","title":"Using private repositories in Docker compose"},{"location":"modules/docker_compose/#putting-auths-in-a-config-file","text":"Create a config.json in separate location with real authentication keys, like: { \"auths\" : { \"https://index.docker.io/v1/\" : { \"auth\" : \"QWEADSZXC...\" } }, \"credsStore\" : \"osxkeychain\" } and specify the location to Testcontainers using any of the two first methods from above.","title":"Putting auths in a config file"},{"location":"modules/docker_compose/#using-local-compose-mode","text":"Local Compose mode , mentioned above, will allow compose to directly access the Docker auth system (to the same extent that running the docker-compose CLI manually works).","title":"Using 'local compose' mode"},{"location":"modules/docker_compose/#adding-this-module-to-your-project-dependencies","text":"Docker Compose support is part of the core Testcontainers library. Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:testcontainers:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/elasticsearch/","text":"Elasticsearch container This module helps running elasticsearch using Testcontainers. Note that it's based on the official Docker image provided by elastic. Usage example You can start an elasticsearch container instance from any Java application by using: HttpClient // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( ELASTICSEARCH_IMAGE )) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the rest client ... final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient . builder ( HttpHost . create ( container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { return httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } HttpClient with Elasticsearch 8 // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( \"docker.elastic.co/elasticsearch/elasticsearch:8.1.2\" ) ) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the rest client ... final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient // use HTTPS for Elasticsearch 8 . builder ( HttpHost . create ( \"https://\" + container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); // SSL is activated by default in Elasticsearch 8 httpClientBuilder . setSSLContext ( container . createSslContextFromCa ()); return httpClientBuilder ; }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } HttpClient with Elasticsearch 8 and SSL disabled // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( \"docker.elastic.co/elasticsearch/elasticsearch:8.1.2\" ) // disable SSL . withEnv ( \"xpack.security.transport.ssl.enabled\" , \"false\" ) . withEnv ( \"xpack.security.http.ssl.enabled\" , \"false\" ) ) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the rest client ... final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient . builder ( HttpHost . create ( container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { return httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } TransportClient // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( ELASTICSEARCH_IMAGE )) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the transport client TransportAddress transportAddress = new TransportAddress ( container . getTcpHost ()); String expectedClusterName = \"docker-cluster\" ; Settings settings = Settings . builder (). put ( \"cluster.name\" , expectedClusterName ). build (); try ( TransportClient transportClient = new PreBuiltTransportClient ( settings ) . addTransportAddress ( transportAddress ) ) { ClusterHealthResponse healths = transportClient . admin (). cluster (). prepareHealth (). get (); String clusterName = healths . getClusterName (); \u22ef } } Note that if you are still using the TransportClient (not recommended as it is deprecated), the default cluster name is set to docker-cluster so you need to change cluster.name setting or set client.transport.ignore_cluster_name to true . Secure your Elasticsearch cluster The default distribution of Elasticsearch comes with the basic license which contains security feature. You can turn on security by providing a password: HttpClient // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( ELASTICSEARCH_IMAGE ) // With a password . withPassword ( ELASTICSEARCH_PASSWORD ) ) { // Start the container. This step might take some time... container . start (); // Create the secured client. final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient . builder ( HttpHost . create ( container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { return httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:elasticsearch:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> elasticsearch </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Elasticsearch container"},{"location":"modules/elasticsearch/#elasticsearch-container","text":"This module helps running elasticsearch using Testcontainers. Note that it's based on the official Docker image provided by elastic.","title":"Elasticsearch container"},{"location":"modules/elasticsearch/#usage-example","text":"You can start an elasticsearch container instance from any Java application by using: HttpClient // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( ELASTICSEARCH_IMAGE )) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the rest client ... final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient . builder ( HttpHost . create ( container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { return httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } HttpClient with Elasticsearch 8 // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( \"docker.elastic.co/elasticsearch/elasticsearch:8.1.2\" ) ) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the rest client ... final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient // use HTTPS for Elasticsearch 8 . builder ( HttpHost . create ( \"https://\" + container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); // SSL is activated by default in Elasticsearch 8 httpClientBuilder . setSSLContext ( container . createSslContextFromCa ()); return httpClientBuilder ; }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } HttpClient with Elasticsearch 8 and SSL disabled // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( \"docker.elastic.co/elasticsearch/elasticsearch:8.1.2\" ) // disable SSL . withEnv ( \"xpack.security.transport.ssl.enabled\" , \"false\" ) . withEnv ( \"xpack.security.http.ssl.enabled\" , \"false\" ) ) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the rest client ... final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient . builder ( HttpHost . create ( container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { return httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef } TransportClient // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( ELASTICSEARCH_IMAGE )) { // Start the container. This step might take some time... container . start (); // Do whatever you want with the transport client TransportAddress transportAddress = new TransportAddress ( container . getTcpHost ()); String expectedClusterName = \"docker-cluster\" ; Settings settings = Settings . builder (). put ( \"cluster.name\" , expectedClusterName ). build (); try ( TransportClient transportClient = new PreBuiltTransportClient ( settings ) . addTransportAddress ( transportAddress ) ) { ClusterHealthResponse healths = transportClient . admin (). cluster (). prepareHealth (). get (); String clusterName = healths . getClusterName (); \u22ef } } Note that if you are still using the TransportClient (not recommended as it is deprecated), the default cluster name is set to docker-cluster so you need to change cluster.name setting or set client.transport.ignore_cluster_name to true .","title":"Usage example"},{"location":"modules/elasticsearch/#secure-your-elasticsearch-cluster","text":"The default distribution of Elasticsearch comes with the basic license which contains security feature. You can turn on security by providing a password: HttpClient // Create the elasticsearch container. try ( ElasticsearchContainer container = new ElasticsearchContainer ( ELASTICSEARCH_IMAGE ) // With a password . withPassword ( ELASTICSEARCH_PASSWORD ) ) { // Start the container. This step might take some time... container . start (); // Create the secured client. final CredentialsProvider credentialsProvider = new BasicCredentialsProvider (); credentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( ELASTICSEARCH_USERNAME , ELASTICSEARCH_PASSWORD ) ); client = RestClient . builder ( HttpHost . create ( container . getHttpHostAddress ())) . setHttpClientConfigCallback ( httpClientBuilder -> { return httpClientBuilder . setDefaultCredentialsProvider ( credentialsProvider ); }) . build (); Response response = client . performRequest ( new Request ( \"GET\" , \"/_cluster/health\" )); \u22ef }","title":"Secure your Elasticsearch cluster"},{"location":"modules/elasticsearch/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:elasticsearch:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> elasticsearch </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/gcloud/","text":"GCloud Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for the Google Cloud Platform's Cloud SDK . Currently, the module supports BigQuery , Bigtable , Datastore , Firestore , Spanner , and Pub/Sub emulators. In order to use it, you should use the following classes: Class Container Image BigQueryEmulatorContainer ghcr.io/goccy/bigquery-emulator BigtableEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators DatastoreEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators FirestoreEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators SpannerEmulatorContainer gcr.io/cloud-spanner-emulator/emulator PubSubEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators Usage example BigQuery Start BigQuery Emulator during a test: Starting a BigQuery Emulator container BigQueryEmulatorContainer container = new BigQueryEmulatorContainer ( \"ghcr.io/goccy/bigquery-emulator:0.4.3\" ) Creating BigQuery Client String url = container . getEmulatorHttpEndpoint (); BigQueryOptions options = BigQueryOptions . newBuilder () . setProjectId ( container . getProjectId ()) . setHost ( url ) . setLocation ( url ) . setCredentials ( NoCredentials . getInstance ()) . build (); BigQuery bigQuery = options . getService (); Bigtable Start Bigtable Emulator during a test: Starting a Bigtable Emulator container public BigtableEmulatorContainer emulator = new BigtableEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); Create a test Bigtable table in the Emulator: Create a test table private void createTable ( TransportChannelProvider channelProvider , CredentialsProvider credentialsProvider , String tableName ) throws IOException { EnhancedBigtableTableAdminStub stub = EnhancedBigtableTableAdminStub . createEnhanced ( BigtableTableAdminStubSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build () ); try ( BigtableTableAdminClient client = BigtableTableAdminClient . create ( PROJECT_ID , INSTANCE_ID , stub )) { Table table = client . createTable ( CreateTableRequest . of ( tableName ). addFamily ( \"name\" )); } } Test against the Emulator: Testing with a Bigtable Emulator container public void testSimple () throws IOException { ManagedChannel channel = ManagedChannelBuilder . forTarget ( emulator . getEmulatorEndpoint ()). usePlaintext (). build (); TransportChannelProvider channelProvider = FixedTransportChannelProvider . create ( GrpcTransportChannel . create ( channel ) ); NoCredentialsProvider credentialsProvider = NoCredentialsProvider . create (); createTable ( channelProvider , credentialsProvider , \"test-table\" ); try ( BigtableDataClient client = BigtableDataClient . create ( BigtableDataSettings . newBuilderForEmulator ( emulator . getHost (), emulator . getEmulatorPort ()) . setProjectId ( PROJECT_ID ) . setInstanceId ( INSTANCE_ID ) . build () ) ) { client . mutateRow ( RowMutation . create ( TableId . of ( \"test-table\" ), \"1\" ). setCell ( \"name\" , \"firstName\" , \"Ray\" )); Row row = client . readRow ( TableId . of ( \"test-table\" ), \"1\" ); List < RowCell > cells = row . getCells ( \"name\" , \"firstName\" ); assertThat ( cells ). isNotNull (). hasSize ( 1 ); assertThat ( cells . get ( 0 ). getValue (). toStringUtf8 ()). isEqualTo ( \"Ray\" ); } finally { channel . shutdown (); } } Datastore Start Datastore Emulator during a test: Starting a Datastore Emulator container public DatastoreEmulatorContainer emulator = new DatastoreEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); And test against the Emulator: Testing with a Datastore Emulator container @Test public void testSimple () { DatastoreOptions options = DatastoreOptions . newBuilder () . setHost ( emulator . getEmulatorEndpoint ()) . setCredentials ( NoCredentials . getInstance ()) . setRetrySettings ( ServiceOptions . getNoRetrySettings ()) . setProjectId ( emulator . getProjectId ()) . build (); Datastore datastore = options . getService (); Key key = datastore . newKeyFactory (). setKind ( \"Task\" ). newKey ( \"sample\" ); Entity entity = Entity . newBuilder ( key ). set ( \"description\" , \"my description\" ). build (); datastore . put ( entity ); assertThat ( datastore . get ( key ). getString ( \"description\" )). isEqualTo ( \"my description\" ); } See more examples: Full sample code With Spring Boot Firestore Start Firestore Emulator during a test: Starting a Firestore Emulator container public FirestoreEmulatorContainer emulator = new FirestoreEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); And test against the Emulator: Testing with a Firestore Emulator container @Test public void testSimple () throws ExecutionException , InterruptedException { FirestoreOptions options = FirestoreOptions . getDefaultInstance () . toBuilder () . setHost ( emulator . getEmulatorEndpoint ()) . setCredentials ( NoCredentials . getInstance ()) . setProjectId ( \"test-project\" ) . build (); Firestore firestore = options . getService (); CollectionReference users = firestore . collection ( \"users\" ); DocumentReference docRef = users . document ( \"alovelace\" ); Map < String , Object > data = new HashMap <> (); data . put ( \"first\" , \"Ada\" ); data . put ( \"last\" , \"Lovelace\" ); ApiFuture < WriteResult > result = docRef . set ( data ); result . get (); ApiFuture < QuerySnapshot > query = users . get (); QuerySnapshot querySnapshot = query . get (); assertThat ( querySnapshot . getDocuments (). get ( 0 ). getData ()). containsEntry ( \"first\" , \"Ada\" ); } See more examples: Full sample code With Spring Boot Spanner Start Spanner Emulator during a test: Starting a Spanner Emulator container public SpannerEmulatorContainer emulator = new SpannerEmulatorContainer ( DockerImageName . parse ( \"gcr.io/cloud-spanner-emulator/emulator:1.4.0\" ) ); Create a test Spanner Instance in the Emulator: Create a test Spanner instance private InstanceId createInstance ( Spanner spanner ) throws InterruptedException , ExecutionException { InstanceConfigId instanceConfig = InstanceConfigId . of ( PROJECT_NAME , \"emulator-config\" ); InstanceId instanceId = InstanceId . of ( PROJECT_NAME , INSTANCE_NAME ); InstanceAdminClient insAdminClient = spanner . getInstanceAdminClient (); Instance instance = insAdminClient . createInstance ( InstanceInfo . newBuilder ( instanceId ) . setNodeCount ( 1 ) . setDisplayName ( \"Test instance\" ) . setInstanceConfigId ( instanceConfig ) . build () ) . get (); return instanceId ; } Create a test Database in the Emulator: Creating a test Spanner database private void createDatabase ( Spanner spanner ) throws InterruptedException , ExecutionException { DatabaseAdminClient dbAdminClient = spanner . getDatabaseAdminClient (); Database database = dbAdminClient . createDatabase ( INSTANCE_NAME , DATABASE_NAME , Arrays . asList ( \"CREATE TABLE TestTable (Key INT64, Value STRING(MAX)) PRIMARY KEY (Key)\" ) ) . get (); } And test against the Emulator: Testing with a Spanner Emulator container @Test public void testSimple () throws ExecutionException , InterruptedException { SpannerOptions options = SpannerOptions . newBuilder () . setEmulatorHost ( emulator . getEmulatorGrpcEndpoint ()) . setCredentials ( NoCredentials . getInstance ()) . setProjectId ( PROJECT_NAME ) . build (); Spanner spanner = options . getService (); InstanceId instanceId = createInstance ( spanner ); createDatabase ( spanner ); DatabaseId databaseId = DatabaseId . of ( instanceId , DATABASE_NAME ); DatabaseClient dbClient = spanner . getDatabaseClient ( databaseId ); dbClient . readWriteTransaction () . run ( tx -> { String sql1 = \"Delete from TestTable where 1=1\" ; tx . executeUpdate ( Statement . of ( sql1 )); String sql = \"INSERT INTO TestTable (Key, Value) VALUES (1, 'Java'), (2, 'Go')\" ; tx . executeUpdate ( Statement . of ( sql )); return null ; }); ResultSet resultSet = dbClient . readOnlyTransaction () . executeQuery ( Statement . of ( \"select * from TestTable order by Key\" )); resultSet . next (); assertThat ( resultSet . getLong ( 0 )). isEqualTo ( 1 ); assertThat ( resultSet . getString ( 1 )). isEqualTo ( \"Java\" ); } See more examples: Full sample code With Spring Boot Pub/Sub Start Pub/Sub Emulator during a test: Starting a Pub/Sub Emulator container public PubSubEmulatorContainer emulator = new PubSubEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); Create a test Pub/Sub topic in the Emulator: Create a test topic private void createTopic ( String topicId , TransportChannelProvider channelProvider , NoCredentialsProvider credentialsProvider ) throws IOException { TopicAdminSettings topicAdminSettings = TopicAdminSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); try ( TopicAdminClient topicAdminClient = TopicAdminClient . create ( topicAdminSettings )) { TopicName topicName = TopicName . of ( PROJECT_ID , topicId ); topicAdminClient . createTopic ( topicName ); } } Create a test Pub/Sub subscription in the Emulator: Create a test subscription private void createSubscription ( String subscriptionId , String topicId , TransportChannelProvider channelProvider , NoCredentialsProvider credentialsProvider ) throws IOException { SubscriptionAdminSettings subscriptionAdminSettings = SubscriptionAdminSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); SubscriptionAdminClient subscriptionAdminClient = SubscriptionAdminClient . create ( subscriptionAdminSettings ); SubscriptionName subscriptionName = SubscriptionName . of ( PROJECT_ID , subscriptionId ); subscriptionAdminClient . createSubscription ( subscriptionName , TopicName . of ( PROJECT_ID , topicId ), PushConfig . getDefaultInstance (), 10 ); } And test against the Emulator: Testing with a Pub/Sub Emulator container public void testSimple () throws IOException { String hostport = emulator . getEmulatorEndpoint (); ManagedChannel channel = ManagedChannelBuilder . forTarget ( hostport ). usePlaintext (). build (); try { TransportChannelProvider channelProvider = FixedTransportChannelProvider . create ( GrpcTransportChannel . create ( channel ) ); NoCredentialsProvider credentialsProvider = NoCredentialsProvider . create (); String topicId = \"my-topic-id\" ; createTopic ( topicId , channelProvider , credentialsProvider ); String subscriptionId = \"my-subscription-id\" ; createSubscription ( subscriptionId , topicId , channelProvider , credentialsProvider ); Publisher publisher = Publisher . newBuilder ( TopicName . of ( PROJECT_ID , topicId )) . setChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); PubsubMessage message = PubsubMessage . newBuilder (). setData ( ByteString . copyFromUtf8 ( \"test message\" )). build (); publisher . publish ( message ); SubscriberStubSettings subscriberStubSettings = SubscriberStubSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); try ( SubscriberStub subscriber = GrpcSubscriberStub . create ( subscriberStubSettings )) { PullRequest pullRequest = PullRequest . newBuilder () . setMaxMessages ( 1 ) . setSubscription ( ProjectSubscriptionName . format ( PROJECT_ID , subscriptionId )) . build (); PullResponse pullResponse = subscriber . pullCallable (). call ( pullRequest ); assertThat ( pullResponse . getReceivedMessagesList ()). hasSize ( 1 ); assertThat ( pullResponse . getReceivedMessages ( 0 ). getMessage (). getData (). toStringUtf8 ()) . isEqualTo ( \"test message\" ); } } finally { channel . shutdown (); } } See more examples: Full sample code With Spring Boot Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:gcloud:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> gcloud </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"GCloud Module"},{"location":"modules/gcloud/#gcloud-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for the Google Cloud Platform's Cloud SDK . Currently, the module supports BigQuery , Bigtable , Datastore , Firestore , Spanner , and Pub/Sub emulators. In order to use it, you should use the following classes: Class Container Image BigQueryEmulatorContainer ghcr.io/goccy/bigquery-emulator BigtableEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators DatastoreEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators FirestoreEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators SpannerEmulatorContainer gcr.io/cloud-spanner-emulator/emulator PubSubEmulatorContainer gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators","title":"GCloud Module"},{"location":"modules/gcloud/#usage-example","text":"","title":"Usage example"},{"location":"modules/gcloud/#bigquery","text":"Start BigQuery Emulator during a test: Starting a BigQuery Emulator container BigQueryEmulatorContainer container = new BigQueryEmulatorContainer ( \"ghcr.io/goccy/bigquery-emulator:0.4.3\" ) Creating BigQuery Client String url = container . getEmulatorHttpEndpoint (); BigQueryOptions options = BigQueryOptions . newBuilder () . setProjectId ( container . getProjectId ()) . setHost ( url ) . setLocation ( url ) . setCredentials ( NoCredentials . getInstance ()) . build (); BigQuery bigQuery = options . getService ();","title":"BigQuery"},{"location":"modules/gcloud/#bigtable","text":"Start Bigtable Emulator during a test: Starting a Bigtable Emulator container public BigtableEmulatorContainer emulator = new BigtableEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); Create a test Bigtable table in the Emulator: Create a test table private void createTable ( TransportChannelProvider channelProvider , CredentialsProvider credentialsProvider , String tableName ) throws IOException { EnhancedBigtableTableAdminStub stub = EnhancedBigtableTableAdminStub . createEnhanced ( BigtableTableAdminStubSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build () ); try ( BigtableTableAdminClient client = BigtableTableAdminClient . create ( PROJECT_ID , INSTANCE_ID , stub )) { Table table = client . createTable ( CreateTableRequest . of ( tableName ). addFamily ( \"name\" )); } } Test against the Emulator: Testing with a Bigtable Emulator container public void testSimple () throws IOException { ManagedChannel channel = ManagedChannelBuilder . forTarget ( emulator . getEmulatorEndpoint ()). usePlaintext (). build (); TransportChannelProvider channelProvider = FixedTransportChannelProvider . create ( GrpcTransportChannel . create ( channel ) ); NoCredentialsProvider credentialsProvider = NoCredentialsProvider . create (); createTable ( channelProvider , credentialsProvider , \"test-table\" ); try ( BigtableDataClient client = BigtableDataClient . create ( BigtableDataSettings . newBuilderForEmulator ( emulator . getHost (), emulator . getEmulatorPort ()) . setProjectId ( PROJECT_ID ) . setInstanceId ( INSTANCE_ID ) . build () ) ) { client . mutateRow ( RowMutation . create ( TableId . of ( \"test-table\" ), \"1\" ). setCell ( \"name\" , \"firstName\" , \"Ray\" )); Row row = client . readRow ( TableId . of ( \"test-table\" ), \"1\" ); List < RowCell > cells = row . getCells ( \"name\" , \"firstName\" ); assertThat ( cells ). isNotNull (). hasSize ( 1 ); assertThat ( cells . get ( 0 ). getValue (). toStringUtf8 ()). isEqualTo ( \"Ray\" ); } finally { channel . shutdown (); } }","title":"Bigtable"},{"location":"modules/gcloud/#datastore","text":"Start Datastore Emulator during a test: Starting a Datastore Emulator container public DatastoreEmulatorContainer emulator = new DatastoreEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); And test against the Emulator: Testing with a Datastore Emulator container @Test public void testSimple () { DatastoreOptions options = DatastoreOptions . newBuilder () . setHost ( emulator . getEmulatorEndpoint ()) . setCredentials ( NoCredentials . getInstance ()) . setRetrySettings ( ServiceOptions . getNoRetrySettings ()) . setProjectId ( emulator . getProjectId ()) . build (); Datastore datastore = options . getService (); Key key = datastore . newKeyFactory (). setKind ( \"Task\" ). newKey ( \"sample\" ); Entity entity = Entity . newBuilder ( key ). set ( \"description\" , \"my description\" ). build (); datastore . put ( entity ); assertThat ( datastore . get ( key ). getString ( \"description\" )). isEqualTo ( \"my description\" ); } See more examples: Full sample code With Spring Boot","title":"Datastore"},{"location":"modules/gcloud/#firestore","text":"Start Firestore Emulator during a test: Starting a Firestore Emulator container public FirestoreEmulatorContainer emulator = new FirestoreEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); And test against the Emulator: Testing with a Firestore Emulator container @Test public void testSimple () throws ExecutionException , InterruptedException { FirestoreOptions options = FirestoreOptions . getDefaultInstance () . toBuilder () . setHost ( emulator . getEmulatorEndpoint ()) . setCredentials ( NoCredentials . getInstance ()) . setProjectId ( \"test-project\" ) . build (); Firestore firestore = options . getService (); CollectionReference users = firestore . collection ( \"users\" ); DocumentReference docRef = users . document ( \"alovelace\" ); Map < String , Object > data = new HashMap <> (); data . put ( \"first\" , \"Ada\" ); data . put ( \"last\" , \"Lovelace\" ); ApiFuture < WriteResult > result = docRef . set ( data ); result . get (); ApiFuture < QuerySnapshot > query = users . get (); QuerySnapshot querySnapshot = query . get (); assertThat ( querySnapshot . getDocuments (). get ( 0 ). getData ()). containsEntry ( \"first\" , \"Ada\" ); } See more examples: Full sample code With Spring Boot","title":"Firestore"},{"location":"modules/gcloud/#spanner","text":"Start Spanner Emulator during a test: Starting a Spanner Emulator container public SpannerEmulatorContainer emulator = new SpannerEmulatorContainer ( DockerImageName . parse ( \"gcr.io/cloud-spanner-emulator/emulator:1.4.0\" ) ); Create a test Spanner Instance in the Emulator: Create a test Spanner instance private InstanceId createInstance ( Spanner spanner ) throws InterruptedException , ExecutionException { InstanceConfigId instanceConfig = InstanceConfigId . of ( PROJECT_NAME , \"emulator-config\" ); InstanceId instanceId = InstanceId . of ( PROJECT_NAME , INSTANCE_NAME ); InstanceAdminClient insAdminClient = spanner . getInstanceAdminClient (); Instance instance = insAdminClient . createInstance ( InstanceInfo . newBuilder ( instanceId ) . setNodeCount ( 1 ) . setDisplayName ( \"Test instance\" ) . setInstanceConfigId ( instanceConfig ) . build () ) . get (); return instanceId ; } Create a test Database in the Emulator: Creating a test Spanner database private void createDatabase ( Spanner spanner ) throws InterruptedException , ExecutionException { DatabaseAdminClient dbAdminClient = spanner . getDatabaseAdminClient (); Database database = dbAdminClient . createDatabase ( INSTANCE_NAME , DATABASE_NAME , Arrays . asList ( \"CREATE TABLE TestTable (Key INT64, Value STRING(MAX)) PRIMARY KEY (Key)\" ) ) . get (); } And test against the Emulator: Testing with a Spanner Emulator container @Test public void testSimple () throws ExecutionException , InterruptedException { SpannerOptions options = SpannerOptions . newBuilder () . setEmulatorHost ( emulator . getEmulatorGrpcEndpoint ()) . setCredentials ( NoCredentials . getInstance ()) . setProjectId ( PROJECT_NAME ) . build (); Spanner spanner = options . getService (); InstanceId instanceId = createInstance ( spanner ); createDatabase ( spanner ); DatabaseId databaseId = DatabaseId . of ( instanceId , DATABASE_NAME ); DatabaseClient dbClient = spanner . getDatabaseClient ( databaseId ); dbClient . readWriteTransaction () . run ( tx -> { String sql1 = \"Delete from TestTable where 1=1\" ; tx . executeUpdate ( Statement . of ( sql1 )); String sql = \"INSERT INTO TestTable (Key, Value) VALUES (1, 'Java'), (2, 'Go')\" ; tx . executeUpdate ( Statement . of ( sql )); return null ; }); ResultSet resultSet = dbClient . readOnlyTransaction () . executeQuery ( Statement . of ( \"select * from TestTable order by Key\" )); resultSet . next (); assertThat ( resultSet . getLong ( 0 )). isEqualTo ( 1 ); assertThat ( resultSet . getString ( 1 )). isEqualTo ( \"Java\" ); } See more examples: Full sample code With Spring Boot","title":"Spanner"},{"location":"modules/gcloud/#pubsub","text":"Start Pub/Sub Emulator during a test: Starting a Pub/Sub Emulator container public PubSubEmulatorContainer emulator = new PubSubEmulatorContainer ( DockerImageName . parse ( \"gcr.io/google.com/cloudsdktool/google-cloud-cli:441.0.0-emulators\" ) ); Create a test Pub/Sub topic in the Emulator: Create a test topic private void createTopic ( String topicId , TransportChannelProvider channelProvider , NoCredentialsProvider credentialsProvider ) throws IOException { TopicAdminSettings topicAdminSettings = TopicAdminSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); try ( TopicAdminClient topicAdminClient = TopicAdminClient . create ( topicAdminSettings )) { TopicName topicName = TopicName . of ( PROJECT_ID , topicId ); topicAdminClient . createTopic ( topicName ); } } Create a test Pub/Sub subscription in the Emulator: Create a test subscription private void createSubscription ( String subscriptionId , String topicId , TransportChannelProvider channelProvider , NoCredentialsProvider credentialsProvider ) throws IOException { SubscriptionAdminSettings subscriptionAdminSettings = SubscriptionAdminSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); SubscriptionAdminClient subscriptionAdminClient = SubscriptionAdminClient . create ( subscriptionAdminSettings ); SubscriptionName subscriptionName = SubscriptionName . of ( PROJECT_ID , subscriptionId ); subscriptionAdminClient . createSubscription ( subscriptionName , TopicName . of ( PROJECT_ID , topicId ), PushConfig . getDefaultInstance (), 10 ); } And test against the Emulator: Testing with a Pub/Sub Emulator container public void testSimple () throws IOException { String hostport = emulator . getEmulatorEndpoint (); ManagedChannel channel = ManagedChannelBuilder . forTarget ( hostport ). usePlaintext (). build (); try { TransportChannelProvider channelProvider = FixedTransportChannelProvider . create ( GrpcTransportChannel . create ( channel ) ); NoCredentialsProvider credentialsProvider = NoCredentialsProvider . create (); String topicId = \"my-topic-id\" ; createTopic ( topicId , channelProvider , credentialsProvider ); String subscriptionId = \"my-subscription-id\" ; createSubscription ( subscriptionId , topicId , channelProvider , credentialsProvider ); Publisher publisher = Publisher . newBuilder ( TopicName . of ( PROJECT_ID , topicId )) . setChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); PubsubMessage message = PubsubMessage . newBuilder (). setData ( ByteString . copyFromUtf8 ( \"test message\" )). build (); publisher . publish ( message ); SubscriberStubSettings subscriberStubSettings = SubscriberStubSettings . newBuilder () . setTransportChannelProvider ( channelProvider ) . setCredentialsProvider ( credentialsProvider ) . build (); try ( SubscriberStub subscriber = GrpcSubscriberStub . create ( subscriberStubSettings )) { PullRequest pullRequest = PullRequest . newBuilder () . setMaxMessages ( 1 ) . setSubscription ( ProjectSubscriptionName . format ( PROJECT_ID , subscriptionId )) . build (); PullResponse pullResponse = subscriber . pullCallable (). call ( pullRequest ); assertThat ( pullResponse . getReceivedMessagesList ()). hasSize ( 1 ); assertThat ( pullResponse . getReceivedMessages ( 0 ). getMessage (). getData (). toStringUtf8 ()) . isEqualTo ( \"test message\" ); } } finally { channel . shutdown (); } } See more examples: Full sample code With Spring Boot","title":"Pub/Sub"},{"location":"modules/gcloud/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:gcloud:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> gcloud </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/grafana/","text":"Grafana Testcontainers module for Grafana OTel LGTM . LGTM's usage examples You can start a Grafana OTel LGTM container instance from any Java application by using: Grafana Otel LGTM container LgtmStackContainer lgtm = new LgtmStackContainer ( \"grafana/otel-lgtm:0.6.0\" ) Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:grafana:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> grafana </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Grafana"},{"location":"modules/grafana/#grafana","text":"Testcontainers module for Grafana OTel LGTM .","title":"Grafana"},{"location":"modules/grafana/#lgtms-usage-examples","text":"You can start a Grafana OTel LGTM container instance from any Java application by using: Grafana Otel LGTM container LgtmStackContainer lgtm = new LgtmStackContainer ( \"grafana/otel-lgtm:0.6.0\" ) Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:grafana:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> grafana </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"LGTM's usage examples"},{"location":"modules/hivemq/","text":"HiveMQ Module Automatic starting HiveMQ docker containers for JUnit4 and JUnit5 tests. This enables testing MQTT client applications and integration testing of custom HiveMQ extensions. Community forum: https://community.hivemq.com/ HiveMQ website: https://www.hivemq.com/ MQTT resources: MQTT Essentials MQTT 5 Essentials Please make sure to check out the hivemq-docs for the Community Edition and the Enterprise Edition . Using HiveMQ CE/EE HiveMQ provides different editions of on Docker Hub : the open source Community Edition which is published as hivemq/hivemq-ce . the Enterprise Edition which is published as hivemq/hivemq4 . Both editions can be used directly: Using the Community Edition: Community Edition HiveMQ image @Container final HiveMQContainer hivemqCe = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" )) . withLogLevel ( Level . DEBUG ); Using the Enterprise Edition: Enterprise Edition HiveMQ image @Container final HiveMQContainer hivemqEe = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" )) . withLogLevel ( Level . DEBUG ); Using a specific version is possible by using the tag: Specific HiveMQ Version @Container final HiveMQContainer hivemqSpecificVersion = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce:2024.3\" )); Test your MQTT 3 and MQTT 5 client application Using an Mqtt-client (e.g. the HiveMQ-Mqtt-Client ) you can start testing directly. MQTT5 Client final Mqtt5BlockingClient client = Mqtt5Client . builder () . serverPort ( hivemqCe . getMqttPort ()) . serverHost ( hivemqCe . getHost ()) . buildBlocking (); client . connect (); client . disconnect (); Settings There are several things that can be adjusted before container setup. The following example shows how to enable the Control Center (this is an enterprise feature), set the log level to DEBUG and load a HiveMQ-config-file from the classpath. Config Examples @Container final HiveMQContainer hivemqEeWithControlCenter = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withLogLevel ( Level . DEBUG ) . withHiveMQConfig ( MountableFile . forClasspathResource ( \"/inMemoryConfig.xml\" )) . withControlCenter (); Note: The Control Center of HiveMQ can be accessed via the URL presented in the output of the starting container: 2021-09-10 10:35:53,511 INFO - The HiveMQ Control Center is reachable under: http://localhost:55032 Please be aware that the Control Center is a feature of the enterprise edition of HiveMQ and thus only available with the enterprise image. Testing HiveMQ extensions Using the Extension SDK the functionality of all editions of HiveMQ can be extended. The HiveMQ module also supports testing your own custom extensions. Wait Strategy The raw HiveMQ module is built to wait for certain startup log messages to signal readiness. Since extensions are loaded dynamically they can be available a short while after the main container has started. We therefore provide custom wait conditions for HiveMQ Extensions: The following will specify an extension to be loaded from src/test/resources/modifier-extension into the container and wait for an extension named 'My Extension Name' to be started: Custom Wait Strategy @Container final HiveMQContainer hivemqWithWaitStrategy = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withExtension ( MountableFile . forClasspathResource ( \"/modifier-extension\" )) . waitForExtension ( \"Modifier Extension\" ); Next up we have an example for using an extension directly from the classpath and waiting directly on the extension: Extension from Classpath final HiveMQExtension hiveMQEClasspathxtension = HiveMQExtension . builder () . id ( \"extension-1\" ) . name ( \"my-extension\" ) . version ( \"1.0\" ) . mainClass ( MyExtensionWithSubclasses . class ) . build (); @Container final HiveMQContainer hivemqWithClasspathExtension = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" ) ) . waitForExtension ( hiveMQEClasspathxtension ) . withExtension ( hiveMQEClasspathxtension ) . withHiveMQConfig ( MountableFile . forClasspathResource ( \"/inMemoryConfig.xml\" )); Note Debugging extensions Both examples contain .withDebugging() which enables remote debugging on the container. With debugging enabled you can start putting breakpoints right into your extensions. Testing extensions using Gradle In a Gradle based HiveMQ Extension project, testing is supported using the dedicated HiveMQ Extension Gradle Plugin . The plugin adds an integrationTest task which executes tests from the integrationTest source set. - Integration test source files are defined in src/integrationTest . - Integration test dependencies are defined via the integrationTestImplementation , integrationTestRuntimeOnly , etc. configurations. The integrationTest task builds the extension and unzips it to the build/hivemq-extension-test directory. The tests can then load the built extension into the HiveMQ Testcontainer. Extension from filesystem @Container final HiveMQContainer hivemqExtensionFromFilesystem = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withExtension ( MountableFile . forHostPath ( \"src/test/resources/modifier-extension\" )); Enable/Disable an extension It is possible to enable and disable HiveMQ extensions during runtime. Extensions can also be disabled on startup. Note : that disabling or enabling of extension during runtime is only supported in HiveMQ 4 Enterprise Edition Containers. The following example shows how to start a HiveMQ container with the extension called my-extension being disabled. Disable Extension at startup private final HiveMQExtension hiveMQExtension = HiveMQExtension . builder () . id ( \"extension-1\" ) . name ( \"my-extension\" ) . version ( \"1.0\" ) . disabledOnStartup ( true ) . mainClass ( MyExtension . class ) . build (); @Container final HiveMQContainer hivemq = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" )) . withExtension ( hiveMQExtension ); The following test then proceeds to enable and then disable the extension: Enable/Disable extension at runtime @Test void test_disable_enable_extension () throws Exception { hivemq . enableExtension ( hiveMQExtension ); hivemq . disableExtension ( hiveMQExtension ); } Enable/Disable an extension loaded from a folder Extensions loaded from an extension folder during runtime can also be enabled/disabled on the fly. If the extension folder contains a DISABLED file, the extension will be disabled during startup. Note : that disabling or enabling of extension during runtime is only supported in HiveMQ 4 Enterprise Edition Containers. We first load the extension from the filesystem: Extension from filesystem @Container final HiveMQContainer hivemqExtensionFromFilesystem = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withExtension ( MountableFile . forHostPath ( \"src/test/resources/modifier-extension\" )); Now we can enable/disable the extension using its name: Enable/Disable extension at runtime @Test void test_disable_enable_extension_from_filesystem () throws Exception { hivemqExtensionFromFilesystem . disableExtension ( \"Modifier Extension\" , \"modifier-extension\" ); hivemqExtensionFromFilesystem . enableExtension ( \"Modifier Extension\" , \"modifier-extension\" ); } Remove prepackaged HiveMQ Extensions Since HiveMQ's 4.4 release, HiveMQ Docker images come with the HiveMQ Extension for Kafka, the HiveMQ Enterprise Bridge Extension and the HiveMQ Enterprise Security Extension. These Extensions are disabled by default, but sometimes you my need to remove them before the container starts. Removing all extension is as simple as: Remove all extensions @Container final HiveMQContainer hivemqNoExtensions = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withoutPrepackagedExtensions (); A single extension (e.g. Kafka) can be removed as easily: Remove a specific extension @Container final HiveMQContainer hivemqNoKafkaExtension = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withoutPrepackagedExtensions ( \"hivemq-kafka-extension\" ); Put files into the container Put a file into HiveMQ home Put file into HiveMQ home final HiveMQContainer hivemqFileInHome = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" ) ) . withFileInHomeFolder ( MountableFile . forHostPath ( \"src/test/resources/additionalFile.txt\" ), \"/path/in/home/folder\" ); Put files into extension home Put file into HiveMQ-Extension home @Container final HiveMQContainer hivemqFileInExtensionHome = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" ) ) . withExtension ( HiveMQExtension . builder () . id ( \"extension-1\" ) . name ( \"my-extension\" ) . version ( \"1.0\" ) . mainClass ( MyExtension . class ) . build () ) . withFileInExtensionHomeFolder ( MountableFile . forHostPath ( \"src/test/resources/additionalFile.txt\" ), \"extension-1\" , \"/path/in/extension/home\" ); Put license files into the container Put license file into the HiveMQ container @Container final HiveMQContainer hivemq = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" )) . withLicense ( MountableFile . forHostPath ( \"src/test/resources/myLicense.lic\" )) . withLicense ( MountableFile . forHostPath ( \"src/test/resources/myExtensionLicense.elic\" )); Customize the Container further Since the HiveMQContainer extends from Testcontainer's GenericContainer the container can be customized as desired. Add to your project Gradle Add to build.gradle : testImplementation 'org.testcontainers:hivemq:1.20.6' Add to build.gradle.kts : testImplementation ( \"org.testcontainers:hivemq:1.20.6\" ) Maven Add to pom.xml : <dependency> <groupId> org.testcontainers </groupId> <artifactId> hivemq </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"HiveMQ Module"},{"location":"modules/hivemq/#hivemq-module","text":"Automatic starting HiveMQ docker containers for JUnit4 and JUnit5 tests. This enables testing MQTT client applications and integration testing of custom HiveMQ extensions. Community forum: https://community.hivemq.com/ HiveMQ website: https://www.hivemq.com/ MQTT resources: MQTT Essentials MQTT 5 Essentials Please make sure to check out the hivemq-docs for the Community Edition and the Enterprise Edition .","title":"HiveMQ Module"},{"location":"modules/hivemq/#using-hivemq-ceee","text":"HiveMQ provides different editions of on Docker Hub : the open source Community Edition which is published as hivemq/hivemq-ce . the Enterprise Edition which is published as hivemq/hivemq4 . Both editions can be used directly: Using the Community Edition: Community Edition HiveMQ image @Container final HiveMQContainer hivemqCe = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" )) . withLogLevel ( Level . DEBUG ); Using the Enterprise Edition: Enterprise Edition HiveMQ image @Container final HiveMQContainer hivemqEe = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" )) . withLogLevel ( Level . DEBUG ); Using a specific version is possible by using the tag: Specific HiveMQ Version @Container final HiveMQContainer hivemqSpecificVersion = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce:2024.3\" ));","title":"Using HiveMQ CE/EE"},{"location":"modules/hivemq/#test-your-mqtt-3-and-mqtt-5-client-application","text":"Using an Mqtt-client (e.g. the HiveMQ-Mqtt-Client ) you can start testing directly. MQTT5 Client final Mqtt5BlockingClient client = Mqtt5Client . builder () . serverPort ( hivemqCe . getMqttPort ()) . serverHost ( hivemqCe . getHost ()) . buildBlocking (); client . connect (); client . disconnect ();","title":"Test your MQTT 3 and MQTT 5 client application"},{"location":"modules/hivemq/#settings","text":"There are several things that can be adjusted before container setup. The following example shows how to enable the Control Center (this is an enterprise feature), set the log level to DEBUG and load a HiveMQ-config-file from the classpath. Config Examples @Container final HiveMQContainer hivemqEeWithControlCenter = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withLogLevel ( Level . DEBUG ) . withHiveMQConfig ( MountableFile . forClasspathResource ( \"/inMemoryConfig.xml\" )) . withControlCenter (); Note: The Control Center of HiveMQ can be accessed via the URL presented in the output of the starting container: 2021-09-10 10:35:53,511 INFO - The HiveMQ Control Center is reachable under: http://localhost:55032 Please be aware that the Control Center is a feature of the enterprise edition of HiveMQ and thus only available with the enterprise image.","title":"Settings"},{"location":"modules/hivemq/#testing-hivemq-extensions","text":"Using the Extension SDK the functionality of all editions of HiveMQ can be extended. The HiveMQ module also supports testing your own custom extensions.","title":"Testing HiveMQ extensions"},{"location":"modules/hivemq/#wait-strategy","text":"The raw HiveMQ module is built to wait for certain startup log messages to signal readiness. Since extensions are loaded dynamically they can be available a short while after the main container has started. We therefore provide custom wait conditions for HiveMQ Extensions: The following will specify an extension to be loaded from src/test/resources/modifier-extension into the container and wait for an extension named 'My Extension Name' to be started: Custom Wait Strategy @Container final HiveMQContainer hivemqWithWaitStrategy = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withExtension ( MountableFile . forClasspathResource ( \"/modifier-extension\" )) . waitForExtension ( \"Modifier Extension\" ); Next up we have an example for using an extension directly from the classpath and waiting directly on the extension: Extension from Classpath final HiveMQExtension hiveMQEClasspathxtension = HiveMQExtension . builder () . id ( \"extension-1\" ) . name ( \"my-extension\" ) . version ( \"1.0\" ) . mainClass ( MyExtensionWithSubclasses . class ) . build (); @Container final HiveMQContainer hivemqWithClasspathExtension = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" ) ) . waitForExtension ( hiveMQEClasspathxtension ) . withExtension ( hiveMQEClasspathxtension ) . withHiveMQConfig ( MountableFile . forClasspathResource ( \"/inMemoryConfig.xml\" )); Note Debugging extensions Both examples contain .withDebugging() which enables remote debugging on the container. With debugging enabled you can start putting breakpoints right into your extensions.","title":"Wait Strategy"},{"location":"modules/hivemq/#testing-extensions-using-gradle","text":"In a Gradle based HiveMQ Extension project, testing is supported using the dedicated HiveMQ Extension Gradle Plugin . The plugin adds an integrationTest task which executes tests from the integrationTest source set. - Integration test source files are defined in src/integrationTest . - Integration test dependencies are defined via the integrationTestImplementation , integrationTestRuntimeOnly , etc. configurations. The integrationTest task builds the extension and unzips it to the build/hivemq-extension-test directory. The tests can then load the built extension into the HiveMQ Testcontainer. Extension from filesystem @Container final HiveMQContainer hivemqExtensionFromFilesystem = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withExtension ( MountableFile . forHostPath ( \"src/test/resources/modifier-extension\" ));","title":"Testing extensions using Gradle"},{"location":"modules/hivemq/#enabledisable-an-extension","text":"It is possible to enable and disable HiveMQ extensions during runtime. Extensions can also be disabled on startup. Note : that disabling or enabling of extension during runtime is only supported in HiveMQ 4 Enterprise Edition Containers. The following example shows how to start a HiveMQ container with the extension called my-extension being disabled. Disable Extension at startup private final HiveMQExtension hiveMQExtension = HiveMQExtension . builder () . id ( \"extension-1\" ) . name ( \"my-extension\" ) . version ( \"1.0\" ) . disabledOnStartup ( true ) . mainClass ( MyExtension . class ) . build (); @Container final HiveMQContainer hivemq = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" )) . withExtension ( hiveMQExtension ); The following test then proceeds to enable and then disable the extension: Enable/Disable extension at runtime @Test void test_disable_enable_extension () throws Exception { hivemq . enableExtension ( hiveMQExtension ); hivemq . disableExtension ( hiveMQExtension ); }","title":"Enable/Disable an extension"},{"location":"modules/hivemq/#enabledisable-an-extension-loaded-from-a-folder","text":"Extensions loaded from an extension folder during runtime can also be enabled/disabled on the fly. If the extension folder contains a DISABLED file, the extension will be disabled during startup. Note : that disabling or enabling of extension during runtime is only supported in HiveMQ 4 Enterprise Edition Containers. We first load the extension from the filesystem: Extension from filesystem @Container final HiveMQContainer hivemqExtensionFromFilesystem = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withExtension ( MountableFile . forHostPath ( \"src/test/resources/modifier-extension\" )); Now we can enable/disable the extension using its name: Enable/Disable extension at runtime @Test void test_disable_enable_extension_from_filesystem () throws Exception { hivemqExtensionFromFilesystem . disableExtension ( \"Modifier Extension\" , \"modifier-extension\" ); hivemqExtensionFromFilesystem . enableExtension ( \"Modifier Extension\" , \"modifier-extension\" ); }","title":"Enable/Disable an extension loaded from a folder"},{"location":"modules/hivemq/#remove-prepackaged-hivemq-extensions","text":"Since HiveMQ's 4.4 release, HiveMQ Docker images come with the HiveMQ Extension for Kafka, the HiveMQ Enterprise Bridge Extension and the HiveMQ Enterprise Security Extension. These Extensions are disabled by default, but sometimes you my need to remove them before the container starts. Removing all extension is as simple as: Remove all extensions @Container final HiveMQContainer hivemqNoExtensions = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withoutPrepackagedExtensions (); A single extension (e.g. Kafka) can be removed as easily: Remove a specific extension @Container final HiveMQContainer hivemqNoKafkaExtension = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq4\" ). withTag ( \"4.7.4\" ) ) . withoutPrepackagedExtensions ( \"hivemq-kafka-extension\" );","title":"Remove prepackaged HiveMQ Extensions"},{"location":"modules/hivemq/#put-files-into-the-container","text":"","title":"Put files into the container"},{"location":"modules/hivemq/#put-a-file-into-hivemq-home","text":"Put file into HiveMQ home final HiveMQContainer hivemqFileInHome = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" ) ) . withFileInHomeFolder ( MountableFile . forHostPath ( \"src/test/resources/additionalFile.txt\" ), \"/path/in/home/folder\" );","title":"Put a file into HiveMQ home"},{"location":"modules/hivemq/#put-files-into-extension-home","text":"Put file into HiveMQ-Extension home @Container final HiveMQContainer hivemqFileInExtensionHome = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" ) ) . withExtension ( HiveMQExtension . builder () . id ( \"extension-1\" ) . name ( \"my-extension\" ) . version ( \"1.0\" ) . mainClass ( MyExtension . class ) . build () ) . withFileInExtensionHomeFolder ( MountableFile . forHostPath ( \"src/test/resources/additionalFile.txt\" ), \"extension-1\" , \"/path/in/extension/home\" );","title":"Put files into extension home"},{"location":"modules/hivemq/#put-license-files-into-the-container","text":"Put license file into the HiveMQ container @Container final HiveMQContainer hivemq = new HiveMQContainer ( DockerImageName . parse ( \"hivemq/hivemq-ce\" ). withTag ( \"2024.3\" )) . withLicense ( MountableFile . forHostPath ( \"src/test/resources/myLicense.lic\" )) . withLicense ( MountableFile . forHostPath ( \"src/test/resources/myExtensionLicense.elic\" ));","title":"Put license files into the container"},{"location":"modules/hivemq/#customize-the-container-further","text":"Since the HiveMQContainer extends from Testcontainer's GenericContainer the container can be customized as desired.","title":"Customize the Container further"},{"location":"modules/hivemq/#add-to-your-project","text":"","title":"Add to your project"},{"location":"modules/hivemq/#gradle","text":"Add to build.gradle : testImplementation 'org.testcontainers:hivemq:1.20.6' Add to build.gradle.kts : testImplementation ( \"org.testcontainers:hivemq:1.20.6\" )","title":"Gradle"},{"location":"modules/hivemq/#maven","text":"Add to pom.xml : <dependency> <groupId> org.testcontainers </groupId> <artifactId> hivemq </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Maven"},{"location":"modules/k3s/","text":"K3s Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for Rancher's K3s lightweight Kubernetes. This module is intended to be used for testing components that interact with Kubernetes APIs - for example, operators. Usage example Start a K3s server as follows: Starting a K3S server K3sContainer k3s = new K3sContainer ( DockerImageName . parse ( \"rancher/k3s:v1.21.3-k3s1\" )) . withLogConsumer ( new Slf4jLogConsumer ( log )) Connecting to the server K3sContainer exposes a working Kubernetes client configuration, as a YAML String, via the getKubeConfigYaml() method. This may be used with Kubernetes clients - e.g. for the official Java client and the Fabric8 Kubernetes client : Official Java client String kubeConfigYaml = k3s . getKubeConfigYaml (); ApiClient client = Config . fromConfig ( new StringReader ( kubeConfigYaml )); CoreV1Api api = new CoreV1Api ( client ); // interact with the running K3s server, e.g.: V1NodeList nodes = api . listNode ( null , null , null , null , null , null , null , null , null , null , null ); Fabric8 Kubernetes client // obtain a kubeconfig file which allows us to connect to k3s String kubeConfigYaml = k3s . getKubeConfigYaml (); // requires io.fabric8:kubernetes-client:5.11.0 or higher Config config = Config . fromKubeconfig ( kubeConfigYaml ); DefaultKubernetesClient client = new DefaultKubernetesClient ( config ); // interact with the running K3s server, e.g.: List < Node > nodes = client . nodes (). list (). getItems (); Known limitations Warning K3sContainer runs as a privileged container and needs to be able to spawn its own containers. For these reasons, K3sContainer will not work in certain rootless Docker, Docker-in-Docker, or other environments where privileged containers are disallowed. k3s containers may be unable to run on host machines where /var/lib/docker is on a BTRFS filesystem. See k3s-io/k3s#4863 for an example. You may experience PKIX exceptions when trying to use a configured Fabric8 client. This is down to newer distributions of k3s issuing elliptic curve keys. This can be fixed by adding BouncyCastle PKI library to your classpath. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:k3s:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> k3s </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"K3s Module"},{"location":"modules/k3s/#k3s-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for Rancher's K3s lightweight Kubernetes. This module is intended to be used for testing components that interact with Kubernetes APIs - for example, operators.","title":"K3s Module"},{"location":"modules/k3s/#usage-example","text":"Start a K3s server as follows: Starting a K3S server K3sContainer k3s = new K3sContainer ( DockerImageName . parse ( \"rancher/k3s:v1.21.3-k3s1\" )) . withLogConsumer ( new Slf4jLogConsumer ( log ))","title":"Usage example"},{"location":"modules/k3s/#connecting-to-the-server","text":"K3sContainer exposes a working Kubernetes client configuration, as a YAML String, via the getKubeConfigYaml() method. This may be used with Kubernetes clients - e.g. for the official Java client and the Fabric8 Kubernetes client : Official Java client String kubeConfigYaml = k3s . getKubeConfigYaml (); ApiClient client = Config . fromConfig ( new StringReader ( kubeConfigYaml )); CoreV1Api api = new CoreV1Api ( client ); // interact with the running K3s server, e.g.: V1NodeList nodes = api . listNode ( null , null , null , null , null , null , null , null , null , null , null ); Fabric8 Kubernetes client // obtain a kubeconfig file which allows us to connect to k3s String kubeConfigYaml = k3s . getKubeConfigYaml (); // requires io.fabric8:kubernetes-client:5.11.0 or higher Config config = Config . fromKubeconfig ( kubeConfigYaml ); DefaultKubernetesClient client = new DefaultKubernetesClient ( config ); // interact with the running K3s server, e.g.: List < Node > nodes = client . nodes (). list (). getItems ();","title":"Connecting to the server"},{"location":"modules/k3s/#known-limitations","text":"Warning K3sContainer runs as a privileged container and needs to be able to spawn its own containers. For these reasons, K3sContainer will not work in certain rootless Docker, Docker-in-Docker, or other environments where privileged containers are disallowed. k3s containers may be unable to run on host machines where /var/lib/docker is on a BTRFS filesystem. See k3s-io/k3s#4863 for an example. You may experience PKIX exceptions when trying to use a configured Fabric8 client. This is down to newer distributions of k3s issuing elliptic curve keys. This can be fixed by adding BouncyCastle PKI library to your classpath.","title":"Known limitations"},{"location":"modules/k3s/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:k3s:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> k3s </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/k6/","text":"k6 Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for k6 . k6 is an extensible reliability testing tool built for developer happiness. Basic script execution Execute a simple k6 test script, test.js , with commandline options and injected script variable. Create a simple k6 test script to be executed as part of your tests: Setup the container K6Container container = new K6Container ( \"grafana/k6:0.49.0\" ) . withTestScript ( MountableFile . forClasspathResource ( \"scripts/test.js\" )) . withScriptVar ( \"MY_SCRIPT_VAR\" , \"are cool!\" ) . withScriptVar ( \"AN_UNUSED_VAR\" , \"unused\" ) . withCmdOptions ( \"--quiet\" , \"--no-usage-report\" ) Content of scripts/test.js // The most basic of k6 scripts. export default function (){ console . log ( `k6 tests ${ __ENV . MY_SCRIPT_VAR } ` ) } Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:k6:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> k6 </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"k6 Module"},{"location":"modules/k6/#k6-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Testcontainers module for k6 . k6 is an extensible reliability testing tool built for developer happiness.","title":"k6 Module"},{"location":"modules/k6/#basic-script-execution","text":"Execute a simple k6 test script, test.js , with commandline options and injected script variable. Create a simple k6 test script to be executed as part of your tests: Setup the container K6Container container = new K6Container ( \"grafana/k6:0.49.0\" ) . withTestScript ( MountableFile . forClasspathResource ( \"scripts/test.js\" )) . withScriptVar ( \"MY_SCRIPT_VAR\" , \"are cool!\" ) . withScriptVar ( \"AN_UNUSED_VAR\" , \"unused\" ) . withCmdOptions ( \"--quiet\" , \"--no-usage-report\" ) Content of scripts/test.js // The most basic of k6 scripts. export default function (){ console . log ( `k6 tests ${ __ENV . MY_SCRIPT_VAR } ` ) }","title":"Basic script execution"},{"location":"modules/k6/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:k6:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> k6 </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/kafka/","text":"Kafka Module Testcontainers can be used to automatically instantiate and manage Apache Kafka containers. Currently, two different Kafka images are supported: org.testcontainers.kafka.ConfluentKafkaContainer supports confluentinc/cp-kafka org.testcontainers.kafka.KafkaContainer supports apache/kafka and apache/kafka-native Note org.testcontainers.containers.KafkaContainer is deprecated. Please use org.testcontainers.kafka.ConfluentKafkaContainer or org.testcontainers.kafka.KafkaContainer instead, depending on the used image. Benefits Running a single node Kafka installation with just one line of code No need to manage external Zookeeper installation, required by Kafka. But see below Example Using org.testcontainers.containers.KafkaContainer Create a KafkaContainer to use it in your tests: Creating a KafkaContainer KafkaContainer kafka = new KafkaContainer ( DockerImageName . parse ( \"confluentinc/cp-kafka:6.2.1\" )) The correspondence between Confluent Platform versions and Kafka versions can be seen in Confluent documentation Now your tests or any other process running on your machine can get access to running Kafka broker by using the following bootstrap server location: Bootstrap Servers kafka . getBootstrapServers () Using org.testcontainers.kafka.ConfluentKafkaContainer Note Compatible with confluentinc/cp-kafka images version 7.4.0 and later. Create a ConfluentKafkaContainer to use it in your tests: Creating a ConfluentKafkaContainer ConfluentKafkaContainer kafka = new ConfluentKafkaContainer ( \"confluentinc/cp-kafka:7.4.0\" ) Using org.testcontainers.kafka.KafkaContainer Create a KafkaContainer to use it in your tests: Creating a KafkaContainer KafkaContainer kafka = new KafkaContainer ( \"apache/kafka-native:3.8.0\" ) Options Using external Zookeeper Note Only available for org.testcontainers.containers.KafkaContainer If for some reason you want to use an externally running Zookeeper, then just pass its location during construction: External Zookeeper KafkaContainer kafka = new KafkaContainer ( DockerImageName . parse ( \"confluentinc/cp-kafka:6.2.1\" )) . withNetwork ( network ) . withExternalZookeeper ( \"zookeeper:2181\" ); Using Kraft mode Note Only available for org.testcontainers.containers.KafkaContainer KRaft mode was declared production ready in 3.3.1 (confluentinc/cp-kafka:7.3.x) Kraft mode KafkaContainer kafka = new KafkaContainer ( DockerImageName . parse ( \"confluentinc/cp-kafka:7.4.0\" )). withKraft () See the versions interoperability matrix for more details. Register listeners There are scenarios where additional listeners are needed because the consumer/producer can be in another container in the same network or a different process where the port to connect differs from the default exposed port. E.g Toxiproxy . Register additional listener KafkaContainer kafka = new KafkaContainer ( KAFKA_KRAFT_TEST_IMAGE ) . withListener (() -> \"kafka:19092\" ) . withNetwork ( network ); Container defined in the same network: Create kcat container GenericContainer <?> kcat = new GenericContainer <> ( \"confluentinc/cp-kcat:7.9.0\" ) . withCreateContainerCmdModifier ( cmd -> { cmd . withEntrypoint ( \"sh\" ); }) . withCopyToContainer ( Transferable . of ( \"Message produced by kcat\" ), \"/data/msgs.txt\" ) . withNetwork ( network ) . withCommand ( \"-c\" , \"tail -f /dev/null\" ) Client using the new registered listener: Produce/Consume via new listener kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-t\" , \"msgs\" , \"-P\" , \"-l\" , \"/data/msgs.txt\" ); String stdout = kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-C\" , \"-t\" , \"msgs\" , \"-c\" , \"1\" ) . getStdout (); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:kafka:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> kafka </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Kafka Module"},{"location":"modules/kafka/#kafka-module","text":"Testcontainers can be used to automatically instantiate and manage Apache Kafka containers. Currently, two different Kafka images are supported: org.testcontainers.kafka.ConfluentKafkaContainer supports confluentinc/cp-kafka org.testcontainers.kafka.KafkaContainer supports apache/kafka and apache/kafka-native Note org.testcontainers.containers.KafkaContainer is deprecated. Please use org.testcontainers.kafka.ConfluentKafkaContainer or org.testcontainers.kafka.KafkaContainer instead, depending on the used image.","title":"Kafka Module"},{"location":"modules/kafka/#benefits","text":"Running a single node Kafka installation with just one line of code No need to manage external Zookeeper installation, required by Kafka. But see below","title":"Benefits"},{"location":"modules/kafka/#example","text":"","title":"Example"},{"location":"modules/kafka/#using-orgtestcontainerscontainerskafkacontainer","text":"Create a KafkaContainer to use it in your tests: Creating a KafkaContainer KafkaContainer kafka = new KafkaContainer ( DockerImageName . parse ( \"confluentinc/cp-kafka:6.2.1\" )) The correspondence between Confluent Platform versions and Kafka versions can be seen in Confluent documentation Now your tests or any other process running on your machine can get access to running Kafka broker by using the following bootstrap server location: Bootstrap Servers kafka . getBootstrapServers ()","title":"Using org.testcontainers.containers.KafkaContainer"},{"location":"modules/kafka/#using-orgtestcontainerskafkaconfluentkafkacontainer","text":"Note Compatible with confluentinc/cp-kafka images version 7.4.0 and later. Create a ConfluentKafkaContainer to use it in your tests: Creating a ConfluentKafkaContainer ConfluentKafkaContainer kafka = new ConfluentKafkaContainer ( \"confluentinc/cp-kafka:7.4.0\" )","title":"Using org.testcontainers.kafka.ConfluentKafkaContainer"},{"location":"modules/kafka/#using-orgtestcontainerskafkakafkacontainer","text":"Create a KafkaContainer to use it in your tests: Creating a KafkaContainer KafkaContainer kafka = new KafkaContainer ( \"apache/kafka-native:3.8.0\" )","title":"Using org.testcontainers.kafka.KafkaContainer"},{"location":"modules/kafka/#options","text":"","title":"Options"},{"location":"modules/kafka/#using-external-zookeeper","text":"Note Only available for org.testcontainers.containers.KafkaContainer If for some reason you want to use an externally running Zookeeper, then just pass its location during construction: External Zookeeper KafkaContainer kafka = new KafkaContainer ( DockerImageName . parse ( \"confluentinc/cp-kafka:6.2.1\" )) . withNetwork ( network ) . withExternalZookeeper ( \"zookeeper:2181\" );","title":"Using external Zookeeper"},{"location":"modules/kafka/#using-kraft-mode","text":"Note Only available for org.testcontainers.containers.KafkaContainer KRaft mode was declared production ready in 3.3.1 (confluentinc/cp-kafka:7.3.x) Kraft mode KafkaContainer kafka = new KafkaContainer ( DockerImageName . parse ( \"confluentinc/cp-kafka:7.4.0\" )). withKraft () See the versions interoperability matrix for more details.","title":"Using Kraft mode"},{"location":"modules/kafka/#register-listeners","text":"There are scenarios where additional listeners are needed because the consumer/producer can be in another container in the same network or a different process where the port to connect differs from the default exposed port. E.g Toxiproxy . Register additional listener KafkaContainer kafka = new KafkaContainer ( KAFKA_KRAFT_TEST_IMAGE ) . withListener (() -> \"kafka:19092\" ) . withNetwork ( network ); Container defined in the same network: Create kcat container GenericContainer <?> kcat = new GenericContainer <> ( \"confluentinc/cp-kcat:7.9.0\" ) . withCreateContainerCmdModifier ( cmd -> { cmd . withEntrypoint ( \"sh\" ); }) . withCopyToContainer ( Transferable . of ( \"Message produced by kcat\" ), \"/data/msgs.txt\" ) . withNetwork ( network ) . withCommand ( \"-c\" , \"tail -f /dev/null\" ) Client using the new registered listener: Produce/Consume via new listener kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-t\" , \"msgs\" , \"-P\" , \"-l\" , \"/data/msgs.txt\" ); String stdout = kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-C\" , \"-t\" , \"msgs\" , \"-c\" , \"1\" ) . getStdout ();","title":"Register listeners"},{"location":"modules/kafka/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:kafka:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> kafka </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/ldap/","text":"LDAP Testcontainers module for LLDAP . LLdapContainer's usage examples You can start a LLDAP container instance from any Java application by using: LLDAP container LLdapContainer lldap = new LLdapContainer ( \"lldap/lldap:v0.6.1-alpine\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:ldap:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> ldap </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"LDAP"},{"location":"modules/ldap/#ldap","text":"Testcontainers module for LLDAP .","title":"LDAP"},{"location":"modules/ldap/#lldapcontainers-usage-examples","text":"You can start a LLDAP container instance from any Java application by using: LLDAP container LLdapContainer lldap = new LLdapContainer ( \"lldap/lldap:v0.6.1-alpine\" )","title":"LLdapContainer's usage examples"},{"location":"modules/ldap/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:ldap:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> ldap </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/localstack/","text":"LocalStack Module Testcontainers module for LocalStack , 'a fully functional local AWS cloud stack', to develop and test your cloud and serverless apps without actually using the cloud. Usage example Running LocalStack as a stand-in for AWS S3 during a test: DockerImageName localstackImage = DockerImageName . parse ( \"localstack/localstack:3.5.0\" ); @Rule public LocalStackContainer localstack = new LocalStackContainer ( localstackImage ) . withServices ( S3 ); Creating a client using AWS SDK AWS SDK V1 AmazonS3 s3 = AmazonS3ClientBuilder . standard () . withEndpointConfiguration ( new AwsClientBuilder . EndpointConfiguration ( localstack . getEndpoint (). toString (), localstack . getRegion () ) ) . withCredentials ( new AWSStaticCredentialsProvider ( new BasicAWSCredentials ( localstack . getAccessKey (), localstack . getSecretKey ()) ) ) . build (); AWS SDK V2 S3Client s3 = S3Client . builder () . endpointOverride ( localstack . getEndpoint ()) . credentialsProvider ( StaticCredentialsProvider . create ( AwsBasicCredentials . create ( localstack . getAccessKey (), localstack . getSecretKey ()) ) ) . region ( Region . of ( localstack . getRegion ())) . build (); Environment variables listed in Localstack's README may be used to customize Localstack's configuration. Use the .withEnv(key, value) method on LocalStackContainer to apply configuration settings. HOSTNAME_EXTERNAL and hostname-sensitive services Some Localstack APIs, such as SQS, require the container to be aware of the hostname that it is accessible on - for example, for construction of queue URLs in responses. Testcontainers will inform Localstack of the best hostname automatically, using the HOSTNAME_EXTERNAL environment variable: when running the Localstack container directly without a custom network defined, it is expected that all calls to the container will be from the test host. As such, the container address will be used (typically localhost or the address where the Docker daemon is running). Localstack container running without a custom network @ClassRule public static LocalStackContainer localstack = new LocalStackContainer ( LocalstackTestImages . LOCALSTACK_IMAGE ) . withServices ( Service . S3 , Service . SQS , Service . CLOUDWATCHLOGS , Service . KMS , LocalStackContainer . EnabledService . named ( \"events\" ) ); when running the Localstack container with a custom network defined , it is expected that all calls to the container will be from other containers on that network . HOSTNAME_EXTERNAL will be set to the last network alias that has been configured for the Localstack container. Localstack container running with a custom network private static Network network = Network . newNetwork (); @ClassRule public static LocalStackContainer localstackInDockerNetwork = new LocalStackContainer ( LocalstackTestImages . LOCALSTACK_IMAGE ) . withNetwork ( network ) . withNetworkAliases ( \"notthis\" , \"localstack\" ) // the last alias is used for HOSTNAME_EXTERNAL . withServices ( Service . S3 , Service . SQS , Service . CLOUDWATCHLOGS ); Other usage scenarios, such as where the Localstack container is used from both the test host and containers on a custom network are not automatically supported. If you have this use case, you should set HOSTNAME_EXTERNAL manually. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:localstack:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> localstack </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"LocalStack Module"},{"location":"modules/localstack/#localstack-module","text":"Testcontainers module for LocalStack , 'a fully functional local AWS cloud stack', to develop and test your cloud and serverless apps without actually using the cloud.","title":"LocalStack Module"},{"location":"modules/localstack/#usage-example","text":"Running LocalStack as a stand-in for AWS S3 during a test: DockerImageName localstackImage = DockerImageName . parse ( \"localstack/localstack:3.5.0\" ); @Rule public LocalStackContainer localstack = new LocalStackContainer ( localstackImage ) . withServices ( S3 );","title":"Usage example"},{"location":"modules/localstack/#creating-a-client-using-aws-sdk","text":"AWS SDK V1 AmazonS3 s3 = AmazonS3ClientBuilder . standard () . withEndpointConfiguration ( new AwsClientBuilder . EndpointConfiguration ( localstack . getEndpoint (). toString (), localstack . getRegion () ) ) . withCredentials ( new AWSStaticCredentialsProvider ( new BasicAWSCredentials ( localstack . getAccessKey (), localstack . getSecretKey ()) ) ) . build (); AWS SDK V2 S3Client s3 = S3Client . builder () . endpointOverride ( localstack . getEndpoint ()) . credentialsProvider ( StaticCredentialsProvider . create ( AwsBasicCredentials . create ( localstack . getAccessKey (), localstack . getSecretKey ()) ) ) . region ( Region . of ( localstack . getRegion ())) . build (); Environment variables listed in Localstack's README may be used to customize Localstack's configuration. Use the .withEnv(key, value) method on LocalStackContainer to apply configuration settings.","title":"Creating a client using AWS SDK"},{"location":"modules/localstack/#hostname_external-and-hostname-sensitive-services","text":"Some Localstack APIs, such as SQS, require the container to be aware of the hostname that it is accessible on - for example, for construction of queue URLs in responses. Testcontainers will inform Localstack of the best hostname automatically, using the HOSTNAME_EXTERNAL environment variable: when running the Localstack container directly without a custom network defined, it is expected that all calls to the container will be from the test host. As such, the container address will be used (typically localhost or the address where the Docker daemon is running). Localstack container running without a custom network @ClassRule public static LocalStackContainer localstack = new LocalStackContainer ( LocalstackTestImages . LOCALSTACK_IMAGE ) . withServices ( Service . S3 , Service . SQS , Service . CLOUDWATCHLOGS , Service . KMS , LocalStackContainer . EnabledService . named ( \"events\" ) ); when running the Localstack container with a custom network defined , it is expected that all calls to the container will be from other containers on that network . HOSTNAME_EXTERNAL will be set to the last network alias that has been configured for the Localstack container. Localstack container running with a custom network private static Network network = Network . newNetwork (); @ClassRule public static LocalStackContainer localstackInDockerNetwork = new LocalStackContainer ( LocalstackTestImages . LOCALSTACK_IMAGE ) . withNetwork ( network ) . withNetworkAliases ( \"notthis\" , \"localstack\" ) // the last alias is used for HOSTNAME_EXTERNAL . withServices ( Service . S3 , Service . SQS , Service . CLOUDWATCHLOGS ); Other usage scenarios, such as where the Localstack container is used from both the test host and containers on a custom network are not automatically supported. If you have this use case, you should set HOSTNAME_EXTERNAL manually.","title":"HOSTNAME_EXTERNAL and hostname-sensitive services"},{"location":"modules/localstack/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:localstack:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> localstack </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/milvus/","text":"Milvus Testcontainers module for Milvus . Milvus's usage examples You can start a Milvus container instance from any Java application by using: Default config MilvusContainer milvus = new MilvusContainer ( \"milvusdb/milvus:v2.3.9\" ) With external Etcd: External Etcd Network network = Network . newNetwork (); GenericContainer <?> etcd = new GenericContainer <> ( \"quay.io/coreos/etcd:v3.5.5\" ) . withNetwork ( network ) . withNetworkAliases ( \"etcd\" ) . withCommand ( \"etcd\" , \"-advertise-client-urls=http://127.0.0.1:2379\" , \"-listen-client-urls=http://0.0.0.0:2379\" , \"--data-dir=/etcd\" ) . withEnv ( \"ETCD_AUTO_COMPACTION_MODE\" , \"revision\" ) . withEnv ( \"ETCD_AUTO_COMPACTION_RETENTION\" , \"1000\" ) . withEnv ( \"ETCD_QUOTA_BACKEND_BYTES\" , \"4294967296\" ) . withEnv ( \"ETCD_SNAPSHOT_COUNT\" , \"50000\" ) . waitingFor ( Wait . forLogMessage ( \".*ready to serve client requests.*\" , 1 )); MilvusContainer milvus = new MilvusContainer ( \"milvusdb/milvus:v2.3.9\" ) . withNetwork ( network ) . withEtcdEndpoint ( \"etcd:2379\" ) . dependsOn ( etcd ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:milvus:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> milvus </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Milvus"},{"location":"modules/milvus/#milvus","text":"Testcontainers module for Milvus .","title":"Milvus"},{"location":"modules/milvus/#milvuss-usage-examples","text":"You can start a Milvus container instance from any Java application by using: Default config MilvusContainer milvus = new MilvusContainer ( \"milvusdb/milvus:v2.3.9\" ) With external Etcd: External Etcd Network network = Network . newNetwork (); GenericContainer <?> etcd = new GenericContainer <> ( \"quay.io/coreos/etcd:v3.5.5\" ) . withNetwork ( network ) . withNetworkAliases ( \"etcd\" ) . withCommand ( \"etcd\" , \"-advertise-client-urls=http://127.0.0.1:2379\" , \"-listen-client-urls=http://0.0.0.0:2379\" , \"--data-dir=/etcd\" ) . withEnv ( \"ETCD_AUTO_COMPACTION_MODE\" , \"revision\" ) . withEnv ( \"ETCD_AUTO_COMPACTION_RETENTION\" , \"1000\" ) . withEnv ( \"ETCD_QUOTA_BACKEND_BYTES\" , \"4294967296\" ) . withEnv ( \"ETCD_SNAPSHOT_COUNT\" , \"50000\" ) . waitingFor ( Wait . forLogMessage ( \".*ready to serve client requests.*\" , 1 )); MilvusContainer milvus = new MilvusContainer ( \"milvusdb/milvus:v2.3.9\" ) . withNetwork ( network ) . withEtcdEndpoint ( \"etcd:2379\" ) . dependsOn ( etcd )","title":"Milvus's usage examples"},{"location":"modules/milvus/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:milvus:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> milvus </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/minio/","text":"MinIO Containers Testcontainers can be used to automatically instantiate and manage MinIO containers. Usage example Create a MinIOContainer to use it in your tests: Starting a MinIO container MinIOContainer container = new MinIOContainer ( \"minio/minio:RELEASE.2023-09-04T19-57-37Z\" ); The MinIO Java client can be configured with the container as such: Configuring a MinIO client MinioClient minioClient = MinioClient . builder () . endpoint ( container . getS3URL ()) . credentials ( container . getUserName (), container . getPassword ()) . build (); If needed the username and password can be overridden as such: Overriding a MinIO container MinIOContainer container = new MinIOContainer ( \"minio/minio:RELEASE.2023-09-04T19-57-37Z\" ) . withUserName ( \"testuser\" ) . withPassword ( \"testpassword\" ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:minio:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> minio </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"MinIO Containers"},{"location":"modules/minio/#minio-containers","text":"Testcontainers can be used to automatically instantiate and manage MinIO containers.","title":"MinIO Containers"},{"location":"modules/minio/#usage-example","text":"Create a MinIOContainer to use it in your tests: Starting a MinIO container MinIOContainer container = new MinIOContainer ( \"minio/minio:RELEASE.2023-09-04T19-57-37Z\" ); The MinIO Java client can be configured with the container as such: Configuring a MinIO client MinioClient minioClient = MinioClient . builder () . endpoint ( container . getS3URL ()) . credentials ( container . getUserName (), container . getPassword ()) . build (); If needed the username and password can be overridden as such: Overriding a MinIO container MinIOContainer container = new MinIOContainer ( \"minio/minio:RELEASE.2023-09-04T19-57-37Z\" ) . withUserName ( \"testuser\" ) . withPassword ( \"testpassword\" );","title":"Usage example"},{"location":"modules/minio/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:minio:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> minio </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/mockserver/","text":"Mockserver Module Mock Server can be used to mock HTTP services by matching requests against user-defined expectations. Usage example The following example shows how to start Mockserver. Creating a MockServer container public static final DockerImageName MOCKSERVER_IMAGE = DockerImageName . parse ( \"mockserver/mockserver\" ) . withTag ( \"mockserver-\" + MockServerClient . class . getPackage (). getImplementationVersion ()); @Rule public MockServerContainer mockServer = new MockServerContainer ( MOCKSERVER_IMAGE ); And how to set a simple expectation using the Java MockServerClient. Setting a simple expectation try ( MockServerClient mockServerClient = new MockServerClient ( mockServer . getHost (), mockServer . getServerPort ()) ) { mockServerClient . when ( request (). withPath ( \"/person\" ). withQueryStringParameter ( \"name\" , \"peter\" )) . respond ( response (). withBody ( \"Peter the person!\" )); // ...a GET request to '/person?name=peter' returns \"Peter the person!\" assertThat ( SimpleHttpClient . responseFromMockserver ( mockServer , \"/person?name=peter\" )) . as ( \"Expectation returns expected response body\" ) . contains ( \"Peter the person\" ); } Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mockserver:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mockserver </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Additionally, don't forget to add a client dependency org.mock-server:mockserver-client-java to be able to set expectations, it's not provided by the testcontainers module. Client version should match to the version in a container tag.","title":"Mockserver Module"},{"location":"modules/mockserver/#mockserver-module","text":"Mock Server can be used to mock HTTP services by matching requests against user-defined expectations.","title":"Mockserver Module"},{"location":"modules/mockserver/#usage-example","text":"The following example shows how to start Mockserver. Creating a MockServer container public static final DockerImageName MOCKSERVER_IMAGE = DockerImageName . parse ( \"mockserver/mockserver\" ) . withTag ( \"mockserver-\" + MockServerClient . class . getPackage (). getImplementationVersion ()); @Rule public MockServerContainer mockServer = new MockServerContainer ( MOCKSERVER_IMAGE ); And how to set a simple expectation using the Java MockServerClient. Setting a simple expectation try ( MockServerClient mockServerClient = new MockServerClient ( mockServer . getHost (), mockServer . getServerPort ()) ) { mockServerClient . when ( request (). withPath ( \"/person\" ). withQueryStringParameter ( \"name\" , \"peter\" )) . respond ( response (). withBody ( \"Peter the person!\" )); // ...a GET request to '/person?name=peter' returns \"Peter the person!\" assertThat ( SimpleHttpClient . responseFromMockserver ( mockServer , \"/person?name=peter\" )) . as ( \"Expectation returns expected response body\" ) . contains ( \"Peter the person\" ); }","title":"Usage example"},{"location":"modules/mockserver/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mockserver:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mockserver </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Additionally, don't forget to add a client dependency org.mock-server:mockserver-client-java to be able to set expectations, it's not provided by the testcontainers module. Client version should match to the version in a container tag.","title":"Adding this module to your project dependencies"},{"location":"modules/nginx/","text":"Nginx Module Nginx is a web server, reverse proxy and mail proxy and http cache. Usage example The following example shows how to start Nginx. Creating a Nginx container @Rule public NginxContainer <?> nginx = new NginxContainer <> ( NGINX_IMAGE ) . withCopyFileToContainer ( MountableFile . forHostPath ( tmpDirectory ), \"/usr/share/nginx/html\" ) . waitingFor ( new HttpWaitStrategy ()); How to add custom content to the Nginx server. Creating the static content to serve // Create a temporary dir File contentFolder = new File ( tmpDirectory ); contentFolder . mkdir (); contentFolder . deleteOnExit (); // And \"hello world\" HTTP file File indexFile = new File ( contentFolder , \"index.html\" ); indexFile . deleteOnExit (); @Cleanup PrintStream printStream = new PrintStream ( new FileOutputStream ( indexFile )); printStream . println ( \"<html><body>Hello World!</body></html>\" ); And how to query the Nginx server for the custom content added. Creating the static content to serve URL baseUrl = nginx . getBaseUrl ( \"http\" , 80 ); assertThat ( responseFromNginx ( baseUrl )) . as ( \"An HTTP GET from the Nginx server returns the index.html from the custom content directory\" ) . contains ( \"Hello World!\" ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:nginx:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> nginx </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Nginx Module"},{"location":"modules/nginx/#nginx-module","text":"Nginx is a web server, reverse proxy and mail proxy and http cache.","title":"Nginx Module"},{"location":"modules/nginx/#usage-example","text":"The following example shows how to start Nginx. Creating a Nginx container @Rule public NginxContainer <?> nginx = new NginxContainer <> ( NGINX_IMAGE ) . withCopyFileToContainer ( MountableFile . forHostPath ( tmpDirectory ), \"/usr/share/nginx/html\" ) . waitingFor ( new HttpWaitStrategy ()); How to add custom content to the Nginx server. Creating the static content to serve // Create a temporary dir File contentFolder = new File ( tmpDirectory ); contentFolder . mkdir (); contentFolder . deleteOnExit (); // And \"hello world\" HTTP file File indexFile = new File ( contentFolder , \"index.html\" ); indexFile . deleteOnExit (); @Cleanup PrintStream printStream = new PrintStream ( new FileOutputStream ( indexFile )); printStream . println ( \"<html><body>Hello World!</body></html>\" ); And how to query the Nginx server for the custom content added. Creating the static content to serve URL baseUrl = nginx . getBaseUrl ( \"http\" , 80 ); assertThat ( responseFromNginx ( baseUrl )) . as ( \"An HTTP GET from the Nginx server returns the index.html from the custom content directory\" ) . contains ( \"Hello World!\" );","title":"Usage example"},{"location":"modules/nginx/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:nginx:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> nginx </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/ollama/","text":"Ollama Testcontainers module for Ollama . Ollama's usage examples You can start an Ollama container instance from any Java application by using: Ollama container OllamaContainer ollama = new OllamaContainer ( \"ollama/ollama:0.1.26\" ) Pulling the model Testcontainers allows executing commands in the container . So, pulling the model is as simple as: Pull model ollama . execInContainer ( \"ollama\" , \"pull\" , \"all-minilm\" ); Create a new Image In order to create a new image that contains the model, you can use the following code: Commit Image ollama . commitToImage ( newImageName ); And use the new image along with Image name Substitution Use new Image OllamaContainer ollama = new OllamaContainer ( DockerImageName . parse ( newImageName ) . asCompatibleSubstituteFor ( \"ollama/ollama\" ) ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:ollama:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> ollama </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Ollama"},{"location":"modules/ollama/#ollama","text":"Testcontainers module for Ollama .","title":"Ollama"},{"location":"modules/ollama/#ollamas-usage-examples","text":"You can start an Ollama container instance from any Java application by using: Ollama container OllamaContainer ollama = new OllamaContainer ( \"ollama/ollama:0.1.26\" )","title":"Ollama's usage examples"},{"location":"modules/ollama/#pulling-the-model","text":"Testcontainers allows executing commands in the container . So, pulling the model is as simple as: Pull model ollama . execInContainer ( \"ollama\" , \"pull\" , \"all-minilm\" );","title":"Pulling the model"},{"location":"modules/ollama/#create-a-new-image","text":"In order to create a new image that contains the model, you can use the following code: Commit Image ollama . commitToImage ( newImageName ); And use the new image along with Image name Substitution Use new Image OllamaContainer ollama = new OllamaContainer ( DockerImageName . parse ( newImageName ) . asCompatibleSubstituteFor ( \"ollama/ollama\" ) )","title":"Create a new Image"},{"location":"modules/ollama/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:ollama:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> ollama </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/openfga/","text":"OpenFGA Testcontainers module for OpenFGA . OpenFGAContainer's usage examples You can start an OpenFGA container instance from any Java application by using: OpenFGA container OpenFGAContainer openfga = new OpenFGAContainer ( \"openfga/openfga:v1.4.3\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:openfga:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> openfga </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"OpenFGA"},{"location":"modules/openfga/#openfga","text":"Testcontainers module for OpenFGA .","title":"OpenFGA"},{"location":"modules/openfga/#openfgacontainers-usage-examples","text":"You can start an OpenFGA container instance from any Java application by using: OpenFGA container OpenFGAContainer openfga = new OpenFGAContainer ( \"openfga/openfga:v1.4.3\" )","title":"OpenFGAContainer's usage examples"},{"location":"modules/openfga/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:openfga:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> openfga </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/pinecone/","text":"Pinecone Testcontainers module for Pinecone Local . PineconeLocalContainer's usage examples You can start a Pinecone container instance from any Java application by using: Pinecone container PineconeLocalContainer container = new PineconeLocalContainer ( \"ghcr.io/pinecone-io/pinecone-local:v0.7.0\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:pinecone:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> pinecone </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Pinecone"},{"location":"modules/pinecone/#pinecone","text":"Testcontainers module for Pinecone Local .","title":"Pinecone"},{"location":"modules/pinecone/#pineconelocalcontainers-usage-examples","text":"You can start a Pinecone container instance from any Java application by using: Pinecone container PineconeLocalContainer container = new PineconeLocalContainer ( \"ghcr.io/pinecone-io/pinecone-local:v0.7.0\" )","title":"PineconeLocalContainer's usage examples"},{"location":"modules/pinecone/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:pinecone:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> pinecone </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/pulsar/","text":"Apache Pulsar Module Testcontainers can be used to automatically create Apache Pulsar containers without external services. It's based on the official Apache Pulsar docker image, it is recommended to read the official guide . Example Create a PulsarContainer to use it in your tests: Create a Pulsar container PulsarContainer pulsar = new PulsarContainer ( DockerImageName . parse ( \"apachepulsar/pulsar:3.0.0\" )); Then you can retrieve the broker and the admin url: Get broker and admin urls final String pulsarBrokerUrl = pulsar . getPulsarBrokerUrl (); final String httpServiceUrl = pulsar . getHttpServiceUrl (); Options Configuration If you need to set Pulsar configuration variables you can use the native APIs and set each variable with PULSAR_PREFIX_ as prefix. For example, if you want to enable brokerDeduplicationEnabled : Set configuration variables PulsarContainer pulsar = new PulsarContainer ( PULSAR_IMAGE ) . withEnv ( \"PULSAR_PREFIX_brokerDeduplicationEnabled\" , \"true\" ); Pulsar IO If you need to test Pulsar IO framework you can enable the Pulsar Functions Worker: Create a Pulsar container with functions worker PulsarContainer pulsar = new PulsarContainer ( DockerImageName . parse ( \"apachepulsar/pulsar:3.0.0\" )) . withFunctionsWorker (); Pulsar Transactions If you need to test Pulsar Transactions you can enable the transactions feature: Create a Pulsar container with transactions PulsarContainer pulsar = new PulsarContainer ( PULSAR_IMAGE ). withTransactions (); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:pulsar:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> pulsar </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Apache Pulsar Module"},{"location":"modules/pulsar/#apache-pulsar-module","text":"Testcontainers can be used to automatically create Apache Pulsar containers without external services. It's based on the official Apache Pulsar docker image, it is recommended to read the official guide .","title":"Apache Pulsar Module"},{"location":"modules/pulsar/#example","text":"Create a PulsarContainer to use it in your tests: Create a Pulsar container PulsarContainer pulsar = new PulsarContainer ( DockerImageName . parse ( \"apachepulsar/pulsar:3.0.0\" )); Then you can retrieve the broker and the admin url: Get broker and admin urls final String pulsarBrokerUrl = pulsar . getPulsarBrokerUrl (); final String httpServiceUrl = pulsar . getHttpServiceUrl ();","title":"Example"},{"location":"modules/pulsar/#options","text":"","title":"Options"},{"location":"modules/pulsar/#configuration","text":"If you need to set Pulsar configuration variables you can use the native APIs and set each variable with PULSAR_PREFIX_ as prefix. For example, if you want to enable brokerDeduplicationEnabled : Set configuration variables PulsarContainer pulsar = new PulsarContainer ( PULSAR_IMAGE ) . withEnv ( \"PULSAR_PREFIX_brokerDeduplicationEnabled\" , \"true\" );","title":"Configuration"},{"location":"modules/pulsar/#pulsar-io","text":"If you need to test Pulsar IO framework you can enable the Pulsar Functions Worker: Create a Pulsar container with functions worker PulsarContainer pulsar = new PulsarContainer ( DockerImageName . parse ( \"apachepulsar/pulsar:3.0.0\" )) . withFunctionsWorker ();","title":"Pulsar IO"},{"location":"modules/pulsar/#pulsar-transactions","text":"If you need to test Pulsar Transactions you can enable the transactions feature: Create a Pulsar container with transactions PulsarContainer pulsar = new PulsarContainer ( PULSAR_IMAGE ). withTransactions ();","title":"Pulsar Transactions"},{"location":"modules/pulsar/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:pulsar:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> pulsar </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/qdrant/","text":"Qdrant Testcontainers module for Qdrant Qdrant's usage examples You can start a Qdrant container instance from any Java application by using: Default QDrant container QdrantContainer qdrant = new QdrantContainer ( \"qdrant/qdrant:v1.7.4\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:qdrant:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> qdrant </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Qdrant"},{"location":"modules/qdrant/#qdrant","text":"Testcontainers module for Qdrant","title":"Qdrant"},{"location":"modules/qdrant/#qdrants-usage-examples","text":"You can start a Qdrant container instance from any Java application by using: Default QDrant container QdrantContainer qdrant = new QdrantContainer ( \"qdrant/qdrant:v1.7.4\" )","title":"Qdrant's usage examples"},{"location":"modules/qdrant/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:qdrant:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> qdrant </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/rabbitmq/","text":"RabbitMQ Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:rabbitmq:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> rabbitmq </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"RabbitMQ Module"},{"location":"modules/rabbitmq/#rabbitmq-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy.","title":"RabbitMQ Module"},{"location":"modules/rabbitmq/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:rabbitmq:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> rabbitmq </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/redpanda/","text":"Redpanda Testcontainers can be used to automatically instantiate and manage Redpanda containers. More precisely Testcontainers uses the official Docker images for Redpanda Note This module uses features provided in docker.redpanda.com/redpandadata/redpanda . Example Create a Redpanda to use it in your tests: Creating a Redpanda RedpandaContainer container = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.2\" ) Now your tests or any other process running on your machine can get access to running Redpanda broker by using the following bootstrap server location: Bootstrap Servers container . getBootstrapServers () Redpanda also provides a schema registry implementation. Like the Redpanda broker, you can access by using the following schema registry location: Schema Registry container . getSchemaRegistryAddress () It is also possible to enable security capabilities of Redpanda by using: Enable security RedpandaContainer redpanda = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . enableAuthorization () . enableSasl () . withSuperuser ( \"superuser-1\" ) Superusers can be created by using: Register Superuser String adminUrl = String . format ( \"%s/v1/security/users\" , redpanda . getAdminAddress ()); RestAssured . given () . contentType ( \"application/json\" ) . body ( \"{\\\"username\\\": \\\"superuser-1\\\", \\\"password\\\": \\\"test\\\", \\\"algorithm\\\": \\\"SCRAM-SHA-256\\\"}\" ) . post ( adminUrl ) . then () . statusCode ( 200 ); Below is an example of how to create the AdminClient : Create Admin Client AdminClient adminClient = AdminClient . create ( ImmutableMap . of ( AdminClientConfig . BOOTSTRAP_SERVERS_CONFIG , bootstrapServer , AdminClientConfig . SECURITY_PROTOCOL_CONFIG , \"SASL_PLAINTEXT\" , SaslConfigs . SASL_MECHANISM , \"SCRAM-SHA-256\" , SaslConfigs . SASL_JAAS_CONFIG , \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"superuser-1\\\" password=\\\"test\\\";\" ) ); There are scenarios where additional listeners are needed because the consumer/producer can be another container in the same network or a different process where the port to connect differs from the default exposed port 9092 . E.g Toxiproxy . Register additional listener RedpandaContainer kafka = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . withListener ( \"kafka:19092\" ) . withNetwork ( network ); \u22ef RedpandaContainer kafka = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . withListener ( \"kafka:19092\" , () -> socat . getHost () + \":\" + socat . getMappedPort ( 2000 )) . withNetwork ( network ) Container defined in the same network: Create kcat container GenericContainer <?> kcat = new GenericContainer <> ( \"confluentinc/cp-kcat:7.9.0\" ) . withCreateContainerCmdModifier ( cmd -> { cmd . withEntrypoint ( \"sh\" ); }) . withCopyToContainer ( Transferable . of ( \"Message produced by kcat\" ), \"/data/msgs.txt\" ) . withNetwork ( network ) . withCommand ( \"-c\" , \"tail -f /dev/null\" ) Client using the new registered listener: Produce/Consume via new listener kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-t\" , \"msgs\" , \"-P\" , \"-l\" , \"/data/msgs.txt\" ); String stdout = kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-C\" , \"-t\" , \"msgs\" , \"-c\" , \"1\" ) . getStdout (); \u22ef String bootstrapServers = String . format ( \"%s:%s\" , socat . getHost (), socat . getMappedPort ( 2000 )); testKafkaFunctionality ( bootstrapServers ); The following examples shows how to register a proxy as a new listener in RedpandaContainer : Use SocatContainer to create the proxy Create Proxy SocatContainer socat = new SocatContainer (). withNetwork ( network ). withTarget ( 2000 , \"kafka\" , 19092 ); Register the listener and advertised listener Register Listener RedpandaContainer kafka = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . withListener ( \"kafka:19092\" , () -> socat . getHost () + \":\" + socat . getMappedPort ( 2000 )) . withNetwork ( network ) Client using the new registered listener: Produce/Consume via new listener String bootstrapServers = String . format ( \"%s:%s\" , socat . getHost (), socat . getMappedPort ( 2000 )); testKafkaFunctionality ( bootstrapServers ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:redpanda:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> redpanda </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Redpanda"},{"location":"modules/redpanda/#redpanda","text":"Testcontainers can be used to automatically instantiate and manage Redpanda containers. More precisely Testcontainers uses the official Docker images for Redpanda Note This module uses features provided in docker.redpanda.com/redpandadata/redpanda .","title":"Redpanda"},{"location":"modules/redpanda/#example","text":"Create a Redpanda to use it in your tests: Creating a Redpanda RedpandaContainer container = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.2\" ) Now your tests or any other process running on your machine can get access to running Redpanda broker by using the following bootstrap server location: Bootstrap Servers container . getBootstrapServers () Redpanda also provides a schema registry implementation. Like the Redpanda broker, you can access by using the following schema registry location: Schema Registry container . getSchemaRegistryAddress () It is also possible to enable security capabilities of Redpanda by using: Enable security RedpandaContainer redpanda = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . enableAuthorization () . enableSasl () . withSuperuser ( \"superuser-1\" ) Superusers can be created by using: Register Superuser String adminUrl = String . format ( \"%s/v1/security/users\" , redpanda . getAdminAddress ()); RestAssured . given () . contentType ( \"application/json\" ) . body ( \"{\\\"username\\\": \\\"superuser-1\\\", \\\"password\\\": \\\"test\\\", \\\"algorithm\\\": \\\"SCRAM-SHA-256\\\"}\" ) . post ( adminUrl ) . then () . statusCode ( 200 ); Below is an example of how to create the AdminClient : Create Admin Client AdminClient adminClient = AdminClient . create ( ImmutableMap . of ( AdminClientConfig . BOOTSTRAP_SERVERS_CONFIG , bootstrapServer , AdminClientConfig . SECURITY_PROTOCOL_CONFIG , \"SASL_PLAINTEXT\" , SaslConfigs . SASL_MECHANISM , \"SCRAM-SHA-256\" , SaslConfigs . SASL_JAAS_CONFIG , \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"superuser-1\\\" password=\\\"test\\\";\" ) ); There are scenarios where additional listeners are needed because the consumer/producer can be another container in the same network or a different process where the port to connect differs from the default exposed port 9092 . E.g Toxiproxy . Register additional listener RedpandaContainer kafka = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . withListener ( \"kafka:19092\" ) . withNetwork ( network ); \u22ef RedpandaContainer kafka = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . withListener ( \"kafka:19092\" , () -> socat . getHost () + \":\" + socat . getMappedPort ( 2000 )) . withNetwork ( network ) Container defined in the same network: Create kcat container GenericContainer <?> kcat = new GenericContainer <> ( \"confluentinc/cp-kcat:7.9.0\" ) . withCreateContainerCmdModifier ( cmd -> { cmd . withEntrypoint ( \"sh\" ); }) . withCopyToContainer ( Transferable . of ( \"Message produced by kcat\" ), \"/data/msgs.txt\" ) . withNetwork ( network ) . withCommand ( \"-c\" , \"tail -f /dev/null\" ) Client using the new registered listener: Produce/Consume via new listener kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-t\" , \"msgs\" , \"-P\" , \"-l\" , \"/data/msgs.txt\" ); String stdout = kcat . execInContainer ( \"kcat\" , \"-b\" , \"kafka:19092\" , \"-C\" , \"-t\" , \"msgs\" , \"-c\" , \"1\" ) . getStdout (); \u22ef String bootstrapServers = String . format ( \"%s:%s\" , socat . getHost (), socat . getMappedPort ( 2000 )); testKafkaFunctionality ( bootstrapServers ); The following examples shows how to register a proxy as a new listener in RedpandaContainer : Use SocatContainer to create the proxy Create Proxy SocatContainer socat = new SocatContainer (). withNetwork ( network ). withTarget ( 2000 , \"kafka\" , 19092 ); Register the listener and advertised listener Register Listener RedpandaContainer kafka = new RedpandaContainer ( \"docker.redpanda.com/redpandadata/redpanda:v23.1.7\" ) . withListener ( \"kafka:19092\" , () -> socat . getHost () + \":\" + socat . getMappedPort ( 2000 )) . withNetwork ( network ) Client using the new registered listener: Produce/Consume via new listener String bootstrapServers = String . format ( \"%s:%s\" , socat . getHost (), socat . getMappedPort ( 2000 )); testKafkaFunctionality ( bootstrapServers );","title":"Example"},{"location":"modules/redpanda/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:redpanda:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> redpanda </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/solace/","text":"Solace Container This module helps running Solace PubSub+ using Testcontainers. Note that it's based on the official Docker image . Usage example You can start a solace container instance from any Java application by using: Solace container setup with simple authentication SolaceContainer solaceContainer = new SolaceContainer ( \"solace/solace-pubsub-standard:10.2\" ) . withCredentials ( \"user\" , \"pass\" ) . withTopic ( \"Topic/ActualTopic\" , Service . SMF ) . withVpn ( \"test_vpn\" ) Solace container setup with SSL SolaceContainer solaceContainer = new SolaceContainer ( \"solace/solace-pubsub-standard:10.6\" ) . withClientCert ( MountableFile . forClasspathResource ( \"solace.pem\" ), MountableFile . forClasspathResource ( \"rootCA.crt\" ) ) . withTopic ( \"Topic/ActualTopic\" , Service . SMF_SSL ) Using a Solace container Session session = createSession ( solaceContainer . getUsername (), solaceContainer . getPassword (), solaceContainer . getOrigin ( Service . AMQP ) ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:solace:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> solace </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Solace Container"},{"location":"modules/solace/#solace-container","text":"This module helps running Solace PubSub+ using Testcontainers. Note that it's based on the official Docker image .","title":"Solace Container"},{"location":"modules/solace/#usage-example","text":"You can start a solace container instance from any Java application by using: Solace container setup with simple authentication SolaceContainer solaceContainer = new SolaceContainer ( \"solace/solace-pubsub-standard:10.2\" ) . withCredentials ( \"user\" , \"pass\" ) . withTopic ( \"Topic/ActualTopic\" , Service . SMF ) . withVpn ( \"test_vpn\" ) Solace container setup with SSL SolaceContainer solaceContainer = new SolaceContainer ( \"solace/solace-pubsub-standard:10.6\" ) . withClientCert ( MountableFile . forClasspathResource ( \"solace.pem\" ), MountableFile . forClasspathResource ( \"rootCA.crt\" ) ) . withTopic ( \"Topic/ActualTopic\" , Service . SMF_SSL ) Using a Solace container Session session = createSession ( solaceContainer . getUsername (), solaceContainer . getPassword (), solaceContainer . getOrigin ( Service . AMQP ) );","title":"Usage example"},{"location":"modules/solace/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:solace:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> solace </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/solr/","text":"Solr Container Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. This module helps running solr using Testcontainers. Note that it's based on the official Docker image . Usage example You can start a solr container instance from any Java application by using: Using a Solr container // Create the solr container. SolrContainer container = new SolrContainer ( solrImage ); // Start the container. This step might take some time... container . start (); // Do whatever you want with the client ... SolrClient client = new Http2SolrClient . Builder ( \"http://\" + container . getHost () + \":\" + container . getSolrPort () + \"/solr\" ) . build (); SolrPingResponse response = client . ping ( \"dummy\" ); // Stop the container. container . stop (); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:solr:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> solr </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Solr Container"},{"location":"modules/solr/#solr-container","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. This module helps running solr using Testcontainers. Note that it's based on the official Docker image .","title":"Solr Container"},{"location":"modules/solr/#usage-example","text":"You can start a solr container instance from any Java application by using: Using a Solr container // Create the solr container. SolrContainer container = new SolrContainer ( solrImage ); // Start the container. This step might take some time... container . start (); // Do whatever you want with the client ... SolrClient client = new Http2SolrClient . Builder ( \"http://\" + container . getHost () + \":\" + container . getSolrPort () + \"/solr\" ) . build (); SolrPingResponse response = client . ping ( \"dummy\" ); // Stop the container. container . stop ();","title":"Usage example"},{"location":"modules/solr/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:solr:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> solr </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/toxiproxy/","text":"Toxiproxy Module Testcontainers module for Shopify's Toxiproxy . This TCP proxy can be used to simulate network failure conditions. You can simulate network failures: between Java code and containers, ideal for testing resilience features of client code between containers, for testing resilience and emergent behaviour of multi-container systems if desired, between Java code/containers and external resources (non-Dockerized!), for scenarios where not all dependencies can be/have been dockerized Testcontainers Toxiproxy support allows resilience features to be easily verified as part of isolated dev/CI testing. This allows earlier testing of resilience features, and broader sets of failure conditions to be covered. Usage example A Toxiproxy container can be placed in between test code and a container, or in between containers. In either scenario, it is necessary to create a ToxiproxyContainer instance on the same Docker network, as follows: Creating a Toxiproxy container // Create a common docker network so that containers can communicate @Rule public Network network = Network . newNetwork (); // The target container - this could be anything @Rule public GenericContainer <?> redis = new GenericContainer <> ( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) . withNetwork ( network ) . withNetworkAliases ( \"redis\" ); // Toxiproxy container, which will be used as a TCP proxy @Rule public ToxiproxyContainer toxiproxy = new ToxiproxyContainer ( \"ghcr.io/shopify/toxiproxy:2.5.0\" ) . withNetwork ( network ); Next, it is necessary to instruct Toxiproxy to start proxying connections. Each ToxiproxyContainer can proxy to many target containers if necessary. We do this as follows: Starting proxying connections to a target container final ToxiproxyClient toxiproxyClient = new ToxiproxyClient ( toxiproxy . getHost (), toxiproxy . getControlPort ()); final Proxy proxy = toxiproxyClient . createProxy ( \"redis\" , \"0.0.0.0:8666\" , \"redis:6379\" ); To establish a connection from the test code (on the host machine) to the target container via Toxiproxy, we obtain Toxiproxy's proxy host IP and port: Obtaining proxied host and port final String ipAddressViaToxiproxy = toxiproxy . getHost (); final int portViaToxiproxy = toxiproxy . getMappedPort ( 8666 ); Code under test should connect to this proxied host IP and port. Note Currently, ToxiProxyContainer will reserve 31 ports, starting at 8666. Other containers should connect to this proxied host and port. Having done this, it is possible to trigger failure conditions ('Toxics') through the proxy.toxics() object: bandwidth - Limit a connection to a maximum number of kilobytes per second. latency - Add a delay to all data going through the proxy. The delay is equal to latency +/- jitter . slicer - Slices TCP data up into small bits, optionally adding a delay between each sliced \"packet\". slowClose - Delay the TCP socket from closing until delay milliseconds has elapsed. timeout - Stops all data from getting through, and closes the connection after timeout . If timeout is 0 , the connection won't close, and data will be delayed until the toxic is removed. limitData - Closes connection when transmitted data exceeded limit. Please see the Toxiproxy documentation for full details on the available Toxics. As one example, we can introduce latency and random jitter to proxied connections as follows: Adding latency to a connection proxy . toxics () . latency ( \"latency\" , ToxicDirection . DOWNSTREAM , 1_100 ) . setJitter ( 100 ); // from now on the connection latency should be from 1000-1200 ms. Additionally we can disable the proxy to simulate a complete interruption to the network connection: Cutting a connection proxy . toxics (). bandwidth ( \"CUT_CONNECTION_DOWNSTREAM\" , ToxicDirection . DOWNSTREAM , 0 ); proxy . toxics (). bandwidth ( \"CUT_CONNECTION_UPSTREAM\" , ToxicDirection . UPSTREAM , 0 ); // for example, expect failure when the connection is cut assertThat ( catchThrowable (() -> { jedis . get ( \"somekey\" ); }) ) . as ( \"calls fail when the connection is cut\" ) . isInstanceOf ( JedisConnectionException . class ); proxy . toxics (). get ( \"CUT_CONNECTION_DOWNSTREAM\" ). remove (); proxy . toxics (). get ( \"CUT_CONNECTION_UPSTREAM\" ). remove (); jedis . close (); // and with the connection re-established, expect success assertThat ( jedis . get ( \"somekey\" )) . as ( \"access to the container works OK after re-establishing the connection\" ) . isEqualTo ( \"somevalue\" ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:toxiproxy:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> toxiproxy </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Acknowledgements This module was inspired by a hotels.com blog post . toxiproxy-java is used to help control failure conditions.","title":"Toxiproxy Module"},{"location":"modules/toxiproxy/#toxiproxy-module","text":"Testcontainers module for Shopify's Toxiproxy . This TCP proxy can be used to simulate network failure conditions. You can simulate network failures: between Java code and containers, ideal for testing resilience features of client code between containers, for testing resilience and emergent behaviour of multi-container systems if desired, between Java code/containers and external resources (non-Dockerized!), for scenarios where not all dependencies can be/have been dockerized Testcontainers Toxiproxy support allows resilience features to be easily verified as part of isolated dev/CI testing. This allows earlier testing of resilience features, and broader sets of failure conditions to be covered.","title":"Toxiproxy Module"},{"location":"modules/toxiproxy/#usage-example","text":"A Toxiproxy container can be placed in between test code and a container, or in between containers. In either scenario, it is necessary to create a ToxiproxyContainer instance on the same Docker network, as follows: Creating a Toxiproxy container // Create a common docker network so that containers can communicate @Rule public Network network = Network . newNetwork (); // The target container - this could be anything @Rule public GenericContainer <?> redis = new GenericContainer <> ( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) . withNetwork ( network ) . withNetworkAliases ( \"redis\" ); // Toxiproxy container, which will be used as a TCP proxy @Rule public ToxiproxyContainer toxiproxy = new ToxiproxyContainer ( \"ghcr.io/shopify/toxiproxy:2.5.0\" ) . withNetwork ( network ); Next, it is necessary to instruct Toxiproxy to start proxying connections. Each ToxiproxyContainer can proxy to many target containers if necessary. We do this as follows: Starting proxying connections to a target container final ToxiproxyClient toxiproxyClient = new ToxiproxyClient ( toxiproxy . getHost (), toxiproxy . getControlPort ()); final Proxy proxy = toxiproxyClient . createProxy ( \"redis\" , \"0.0.0.0:8666\" , \"redis:6379\" ); To establish a connection from the test code (on the host machine) to the target container via Toxiproxy, we obtain Toxiproxy's proxy host IP and port: Obtaining proxied host and port final String ipAddressViaToxiproxy = toxiproxy . getHost (); final int portViaToxiproxy = toxiproxy . getMappedPort ( 8666 ); Code under test should connect to this proxied host IP and port. Note Currently, ToxiProxyContainer will reserve 31 ports, starting at 8666. Other containers should connect to this proxied host and port. Having done this, it is possible to trigger failure conditions ('Toxics') through the proxy.toxics() object: bandwidth - Limit a connection to a maximum number of kilobytes per second. latency - Add a delay to all data going through the proxy. The delay is equal to latency +/- jitter . slicer - Slices TCP data up into small bits, optionally adding a delay between each sliced \"packet\". slowClose - Delay the TCP socket from closing until delay milliseconds has elapsed. timeout - Stops all data from getting through, and closes the connection after timeout . If timeout is 0 , the connection won't close, and data will be delayed until the toxic is removed. limitData - Closes connection when transmitted data exceeded limit. Please see the Toxiproxy documentation for full details on the available Toxics. As one example, we can introduce latency and random jitter to proxied connections as follows: Adding latency to a connection proxy . toxics () . latency ( \"latency\" , ToxicDirection . DOWNSTREAM , 1_100 ) . setJitter ( 100 ); // from now on the connection latency should be from 1000-1200 ms. Additionally we can disable the proxy to simulate a complete interruption to the network connection: Cutting a connection proxy . toxics (). bandwidth ( \"CUT_CONNECTION_DOWNSTREAM\" , ToxicDirection . DOWNSTREAM , 0 ); proxy . toxics (). bandwidth ( \"CUT_CONNECTION_UPSTREAM\" , ToxicDirection . UPSTREAM , 0 ); // for example, expect failure when the connection is cut assertThat ( catchThrowable (() -> { jedis . get ( \"somekey\" ); }) ) . as ( \"calls fail when the connection is cut\" ) . isInstanceOf ( JedisConnectionException . class ); proxy . toxics (). get ( \"CUT_CONNECTION_DOWNSTREAM\" ). remove (); proxy . toxics (). get ( \"CUT_CONNECTION_UPSTREAM\" ). remove (); jedis . close (); // and with the connection re-established, expect success assertThat ( jedis . get ( \"somekey\" )) . as ( \"access to the container works OK after re-establishing the connection\" ) . isEqualTo ( \"somevalue\" );","title":"Usage example"},{"location":"modules/toxiproxy/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:toxiproxy:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> toxiproxy </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/toxiproxy/#acknowledgements","text":"This module was inspired by a hotels.com blog post . toxiproxy-java is used to help control failure conditions.","title":"Acknowledgements"},{"location":"modules/typesense/","text":"Typesense Testcontainers module for Typesense . TypesenseContainer's usage examples You can start a Typesense container instance from any Java application by using: Typesense container TypesenseContainer typesense = new TypesenseContainer ( \"typesense/typesense:27.1\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:typesense:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> typesense </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Typesense"},{"location":"modules/typesense/#typesense","text":"Testcontainers module for Typesense .","title":"Typesense"},{"location":"modules/typesense/#typesensecontainers-usage-examples","text":"You can start a Typesense container instance from any Java application by using: Typesense container TypesenseContainer typesense = new TypesenseContainer ( \"typesense/typesense:27.1\" )","title":"TypesenseContainer's usage examples"},{"location":"modules/typesense/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:typesense:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> typesense </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/vault/","text":"Hashicorp Vault Module Testcontainers module for Vault . Vault is a tool for managing secrets. More information on Vault here . Usage example Start Vault container as a @ClassRule : Starting a Vault container public static VaultContainer <?> vaultContainer = new VaultContainer <> ( \"hashicorp/vault:1.13\" ) . withVaultToken ( VAULT_TOKEN ) . withInitCommand ( \"secrets enable transit\" , \"write -f transit/keys/my-key\" , \"kv put secret/testing1 top_secret=password123\" , \"kv put secret/testing2 secret_one=password1 secret_two=password2 secret_three=password3 secret_three=password3 secret_four=password4\" ); Use CLI to read data from Vault container: Use CLI to read data GenericContainer . ExecResult result = vaultContainer . execInContainer ( \"vault\" , \"kv\" , \"get\" , \"-format=json\" , \"secret/testing1\" ); assertThat ( result . getStdout ()). contains ( \"password123\" ); Use Http API to read data from Vault container: Use Http API to read data Response response = given () . header ( \"X-Vault-Token\" , VAULT_TOKEN ) . when () . get ( vaultContainer . getHttpHostAddress () + \"/v1/secret/data/testing1\" ) . thenReturn (); assertThat ( response . body (). jsonPath (). getString ( \"data.data.top_secret\" )). isEqualTo ( \"password123\" ); Use client library to read data from Vault container: Use library to read data public void readFirstSecretPathOverClientLibrary () throws Exception { final VaultConfig config = new VaultConfig () . address ( vaultContainer . getHttpHostAddress ()) . token ( VAULT_TOKEN ) . build (); final Vault vault = new Vault ( config ); final Map < String , String > value = vault . logical (). read ( \"secret/testing1\" ). getData (); assertThat ( value ). containsEntry ( \"top_secret\" , \"password123\" ); } See full example. Why Vault in Junit tests? With the increasing popularity of Vault and secret management, applications are now needing to source secrets from Vault. This can prove challenging in the development phase without a running Vault instance readily on hand. This library aims to solve your apps integration testing with Vault. You can also use it to test how your application behaves with Vault by writing different test scenarios in Junit. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:vault:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> vault </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> License See LICENSE . Copyright Copyright (c) 2017 Capital One Services, LLC and other authors. See AUTHORS for contributors.","title":"Hashicorp Vault Module"},{"location":"modules/vault/#hashicorp-vault-module","text":"Testcontainers module for Vault . Vault is a tool for managing secrets. More information on Vault here .","title":"Hashicorp Vault Module"},{"location":"modules/vault/#usage-example","text":"Start Vault container as a @ClassRule : Starting a Vault container public static VaultContainer <?> vaultContainer = new VaultContainer <> ( \"hashicorp/vault:1.13\" ) . withVaultToken ( VAULT_TOKEN ) . withInitCommand ( \"secrets enable transit\" , \"write -f transit/keys/my-key\" , \"kv put secret/testing1 top_secret=password123\" , \"kv put secret/testing2 secret_one=password1 secret_two=password2 secret_three=password3 secret_three=password3 secret_four=password4\" ); Use CLI to read data from Vault container: Use CLI to read data GenericContainer . ExecResult result = vaultContainer . execInContainer ( \"vault\" , \"kv\" , \"get\" , \"-format=json\" , \"secret/testing1\" ); assertThat ( result . getStdout ()). contains ( \"password123\" ); Use Http API to read data from Vault container: Use Http API to read data Response response = given () . header ( \"X-Vault-Token\" , VAULT_TOKEN ) . when () . get ( vaultContainer . getHttpHostAddress () + \"/v1/secret/data/testing1\" ) . thenReturn (); assertThat ( response . body (). jsonPath (). getString ( \"data.data.top_secret\" )). isEqualTo ( \"password123\" ); Use client library to read data from Vault container: Use library to read data public void readFirstSecretPathOverClientLibrary () throws Exception { final VaultConfig config = new VaultConfig () . address ( vaultContainer . getHttpHostAddress ()) . token ( VAULT_TOKEN ) . build (); final Vault vault = new Vault ( config ); final Map < String , String > value = vault . logical (). read ( \"secret/testing1\" ). getData (); assertThat ( value ). containsEntry ( \"top_secret\" , \"password123\" ); } See full example.","title":"Usage example"},{"location":"modules/vault/#why-vault-in-junit-tests","text":"With the increasing popularity of Vault and secret management, applications are now needing to source secrets from Vault. This can prove challenging in the development phase without a running Vault instance readily on hand. This library aims to solve your apps integration testing with Vault. You can also use it to test how your application behaves with Vault by writing different test scenarios in Junit.","title":"Why Vault in Junit tests?"},{"location":"modules/vault/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:vault:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> vault </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/vault/#license","text":"See LICENSE .","title":"License"},{"location":"modules/vault/#copyright","text":"Copyright (c) 2017 Capital One Services, LLC and other authors. See AUTHORS for contributors.","title":"Copyright"},{"location":"modules/weaviate/","text":"Weaviate Testcontainers module for Weaviate WeaviateContainer's usage examples You can start a Weaviate container instance from any Java application by using: Default Weaviate container WeaviateContainer weaviate = new WeaviateContainer ( \"cr.weaviate.io/semitechnologies/weaviate:1.25.5\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:weaviate:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> weaviate </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Weaviate"},{"location":"modules/weaviate/#weaviate","text":"Testcontainers module for Weaviate","title":"Weaviate"},{"location":"modules/weaviate/#weaviatecontainers-usage-examples","text":"You can start a Weaviate container instance from any Java application by using: Default Weaviate container WeaviateContainer weaviate = new WeaviateContainer ( \"cr.weaviate.io/semitechnologies/weaviate:1.25.5\" )","title":"WeaviateContainer's usage examples"},{"location":"modules/weaviate/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:weaviate:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> weaviate </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/webdriver_containers/","text":"Webdriver Containers Testcontainers can be used to automatically instantiate and manage containers that include web browsers, such as those from SeleniumHQ's docker-selenium project. Benefits Fully compatible with Selenium 3 & 4 tests for Chrome and Firefox and Selenium 4 tests for Edge, by providing a RemoteWebDriver instance No need to have specific web browsers, or even a desktop environment, installed on test servers. The only dependency is a working Docker installation and your Java JUnit test suite. Browsers are always launched from a fixed, clean image. This means no configuration drift from user changes or automatic browser upgrades. Compatibility between browser version and the Selenium API is assured: a compatible version of the browser docker images will be automatically selected to match the version of selenium-api-*.jar on the classpath Additionally the use of a clean browser prevents leakage of cookies, cached data or other state between tests. VNC screen recording : Testcontainers can automatically record video of test runs (optionally capturing just failing tests) Creation of browser containers is fast, so it's actually quite feasible to have a totally fresh browser instance for every test. Example The following field in your JUnit UI test class will prepare a container running Chrome: Chrome @Rule public BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) Now, instead of instantiating an instance of WebDriver directly, use the following to obtain an instance inside your test methods: RemoteWebDriver RemoteWebDriver driver = new RemoteWebDriver ( chrome . getSeleniumAddress (), new ChromeOptions ()); You can then use this driver instance like a regular WebDriver. Note that, if you want to test a web application running on the host machine (the machine the JUnit tests are running on - which is quite likely), you'll need to use the host exposing feature of Testcontainers, e.g.: Open Web Page Testcontainers . exposeHostPorts ( localPort ); driver . get ( \"http://host.testcontainers.internal:\" + localPort ); Options Other browsers At the moment, Chrome, Firefox and Edge are supported. To switch, simply change the first parameter to the rule constructor: Chrome @Rule public BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) Firefox @Rule public BrowserWebDriverContainer <?> firefox = new BrowserWebDriverContainer <> () . withCapabilities ( new FirefoxOptions ()) Edge @Rule public BrowserWebDriverContainer <?> edge = new BrowserWebDriverContainer <> () . withCapabilities ( new EdgeOptions ()) Recording videos By default, no videos will be recorded. However, you can instruct Testcontainers to capture videos for all tests or just for failing tests. Record all Tests // To do this, simply add extra parameters to the rule constructor, so video will default to FLV format: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_ALL , target ) Record failing Tests // or if you only want videos for test failures: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_FAILING , target ) Note that the second parameter of withRecordingMode should be a directory where recordings can be saved. By default, the video will be recorded in FLV format, but you can specify it explicitly or change it to MP4 using withRecordingMode method with VncRecordingFormat option: Video Format in MP4 // Set MP4 format for recorded video: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_ALL , target , VncRecordingFormat . MP4 ) Video Format in FLV // Set (explicitly) FLV format for recorded video: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_ALL , target , VncRecordingFormat . FLV ) If you would like to customise the file name of the recording, or provide a different directory at runtime based on the description of the test and/or its success or failure, you may provide a custom recording file factory as follows: CustomRecordingFileFactory BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () \u22ef . withRecordingFileFactory ( new CustomRecordingFileFactory ()) Note the factory must implement org.testcontainers.containers.RecordingFileFactory . More examples A few different examples are shown in ChromeWebDriverContainerTest.java . Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:selenium:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> selenium </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a Selenium Webdriver JAR to your project. You should ensure that your project also has suitable Selenium dependencies in place, for example: Gradle Maven compile \"org.seleniumhq.selenium:selenium-remote-driver:3.141.59\" <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-remote-driver </artifactId> <version> 3.141.59 </version> </dependency> Testcontainers will try and match the version of the Dockerized browser to whichever version of Selenium is found on the classpath","title":"Webdriver Containers"},{"location":"modules/webdriver_containers/#webdriver-containers","text":"Testcontainers can be used to automatically instantiate and manage containers that include web browsers, such as those from SeleniumHQ's docker-selenium project.","title":"Webdriver Containers"},{"location":"modules/webdriver_containers/#benefits","text":"Fully compatible with Selenium 3 & 4 tests for Chrome and Firefox and Selenium 4 tests for Edge, by providing a RemoteWebDriver instance No need to have specific web browsers, or even a desktop environment, installed on test servers. The only dependency is a working Docker installation and your Java JUnit test suite. Browsers are always launched from a fixed, clean image. This means no configuration drift from user changes or automatic browser upgrades. Compatibility between browser version and the Selenium API is assured: a compatible version of the browser docker images will be automatically selected to match the version of selenium-api-*.jar on the classpath Additionally the use of a clean browser prevents leakage of cookies, cached data or other state between tests. VNC screen recording : Testcontainers can automatically record video of test runs (optionally capturing just failing tests) Creation of browser containers is fast, so it's actually quite feasible to have a totally fresh browser instance for every test.","title":"Benefits"},{"location":"modules/webdriver_containers/#example","text":"The following field in your JUnit UI test class will prepare a container running Chrome: Chrome @Rule public BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) Now, instead of instantiating an instance of WebDriver directly, use the following to obtain an instance inside your test methods: RemoteWebDriver RemoteWebDriver driver = new RemoteWebDriver ( chrome . getSeleniumAddress (), new ChromeOptions ()); You can then use this driver instance like a regular WebDriver. Note that, if you want to test a web application running on the host machine (the machine the JUnit tests are running on - which is quite likely), you'll need to use the host exposing feature of Testcontainers, e.g.: Open Web Page Testcontainers . exposeHostPorts ( localPort ); driver . get ( \"http://host.testcontainers.internal:\" + localPort );","title":"Example"},{"location":"modules/webdriver_containers/#options","text":"","title":"Options"},{"location":"modules/webdriver_containers/#other-browsers","text":"At the moment, Chrome, Firefox and Edge are supported. To switch, simply change the first parameter to the rule constructor: Chrome @Rule public BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) Firefox @Rule public BrowserWebDriverContainer <?> firefox = new BrowserWebDriverContainer <> () . withCapabilities ( new FirefoxOptions ()) Edge @Rule public BrowserWebDriverContainer <?> edge = new BrowserWebDriverContainer <> () . withCapabilities ( new EdgeOptions ())","title":"Other browsers"},{"location":"modules/webdriver_containers/#recording-videos","text":"By default, no videos will be recorded. However, you can instruct Testcontainers to capture videos for all tests or just for failing tests. Record all Tests // To do this, simply add extra parameters to the rule constructor, so video will default to FLV format: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_ALL , target ) Record failing Tests // or if you only want videos for test failures: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_FAILING , target ) Note that the second parameter of withRecordingMode should be a directory where recordings can be saved. By default, the video will be recorded in FLV format, but you can specify it explicitly or change it to MP4 using withRecordingMode method with VncRecordingFormat option: Video Format in MP4 // Set MP4 format for recorded video: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_ALL , target , VncRecordingFormat . MP4 ) Video Format in FLV // Set (explicitly) FLV format for recorded video: BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () . withCapabilities ( new ChromeOptions ()) . withRecordingMode ( VncRecordingMode . RECORD_ALL , target , VncRecordingFormat . FLV ) If you would like to customise the file name of the recording, or provide a different directory at runtime based on the description of the test and/or its success or failure, you may provide a custom recording file factory as follows: CustomRecordingFileFactory BrowserWebDriverContainer <?> chrome = new BrowserWebDriverContainer <> () \u22ef . withRecordingFileFactory ( new CustomRecordingFileFactory ()) Note the factory must implement org.testcontainers.containers.RecordingFileFactory .","title":"Recording videos"},{"location":"modules/webdriver_containers/#more-examples","text":"A few different examples are shown in ChromeWebDriverContainerTest.java .","title":"More examples"},{"location":"modules/webdriver_containers/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:selenium:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> selenium </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a Selenium Webdriver JAR to your project. You should ensure that your project also has suitable Selenium dependencies in place, for example: Gradle Maven compile \"org.seleniumhq.selenium:selenium-remote-driver:3.141.59\" <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-remote-driver </artifactId> <version> 3.141.59 </version> </dependency> Testcontainers will try and match the version of the Dockerized browser to whichever version of Selenium is found on the classpath","title":"Adding this module to your project dependencies"},{"location":"modules/databases/","text":"Database containers Overview You might want to use Testcontainers' database support: Instead of H2 database for DAO unit tests that depend on database features that H2 doesn't emulate. Testcontainers is not as performant as H2, but does give you the benefit of 100% database compatibility (since it runs a real DB inside of a container). Instead of a database running on the local machine or in a VM for DAO unit tests or end-to-end integration tests that need a database to be present. In this context, the benefit of Testcontainers is that the database always starts in a known state, without any contamination between test runs or on developers' local machines. Note Of course, it's still important to have as few tests that hit the database as possible, and make good use of mocks for components higher up the stack. See JDBC and R2DBC for information on how to use Testcontainers with SQL-like databases.","title":"Database containers"},{"location":"modules/databases/#database-containers","text":"","title":"Database containers"},{"location":"modules/databases/#overview","text":"You might want to use Testcontainers' database support: Instead of H2 database for DAO unit tests that depend on database features that H2 doesn't emulate. Testcontainers is not as performant as H2, but does give you the benefit of 100% database compatibility (since it runs a real DB inside of a container). Instead of a database running on the local machine or in a VM for DAO unit tests or end-to-end integration tests that need a database to be present. In this context, the benefit of Testcontainers is that the database always starts in a known state, without any contamination between test runs or on developers' local machines. Note Of course, it's still important to have as few tests that hit the database as possible, and make good use of mocks for components higher up the stack. See JDBC and R2DBC for information on how to use Testcontainers with SQL-like databases.","title":"Overview"},{"location":"modules/databases/cassandra/","text":"Cassandra Module Usage example This example connects to the Cassandra cluster: Define a container: Container definition CassandraContainer cassandraContainer = new CassandraContainer ( \"cassandra:3.11.2\" ) Build a CqlSession : Building CqlSession final CqlSession cqlSession = CqlSession . builder () . addContactPoint ( cassandraContainer . getContactPoint ()) . withLocalDatacenter ( cassandraContainer . getLocalDatacenter ()) . build (); Define a container with custom cassandra.yaml located in a directory cassandra-auth-required-configuration : Running init script with required authentication CassandraContainer cassandraContainer = new CassandraContainer ( CASSANDRA_IMAGE ) . withConfigurationOverride ( \"cassandra-auth-required-configuration\" ) . withInitScript ( \"initial.cql\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:cassandra:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> cassandra </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Cassandra Module"},{"location":"modules/databases/cassandra/#cassandra-module","text":"","title":"Cassandra Module"},{"location":"modules/databases/cassandra/#usage-example","text":"This example connects to the Cassandra cluster: Define a container: Container definition CassandraContainer cassandraContainer = new CassandraContainer ( \"cassandra:3.11.2\" ) Build a CqlSession : Building CqlSession final CqlSession cqlSession = CqlSession . builder () . addContactPoint ( cassandraContainer . getContactPoint ()) . withLocalDatacenter ( cassandraContainer . getLocalDatacenter ()) . build (); Define a container with custom cassandra.yaml located in a directory cassandra-auth-required-configuration : Running init script with required authentication CassandraContainer cassandraContainer = new CassandraContainer ( CASSANDRA_IMAGE ) . withConfigurationOverride ( \"cassandra-auth-required-configuration\" ) . withInitScript ( \"initial.cql\" )","title":"Usage example"},{"location":"modules/databases/cassandra/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:cassandra:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> cassandra </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/databases/clickhouse/","text":"Clickhouse Module Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:clickhouse:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> clickhouse </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Clickhouse Module"},{"location":"modules/databases/clickhouse/#clickhouse-module","text":"","title":"Clickhouse Module"},{"location":"modules/databases/clickhouse/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:clickhouse:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> clickhouse </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/cockroachdb/","text":"CockroachDB Module See Database containers for documentation and usage that is common to all relational database container types. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:cockroachdb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> cockroachdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"CockroachDB Module"},{"location":"modules/databases/cockroachdb/#cockroachdb-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"CockroachDB Module"},{"location":"modules/databases/cockroachdb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:cockroachdb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> cockroachdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/couchbase/","text":"Couchbase Module Testcontainers module for Couchbase. Couchbase is a document oriented NoSQL database. Usage example Running Couchbase as a stand-in in a test: Define a bucket: Bucket Definition BucketDefinition bucketDefinition = new BucketDefinition ( \"mybucket\" ); define a container: Container definition CouchbaseContainer container = new CouchbaseContainer ( couchbaseImage ). withBucket ( bucketDefinition ) create an cluster: Cluster creation Cluster cluster = Cluster . connect ( container . getConnectionString (), container . getUsername (), container . getPassword () ); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:couchbase:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> couchbase </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Couchbase Module"},{"location":"modules/databases/couchbase/#couchbase-module","text":"Testcontainers module for Couchbase. Couchbase is a document oriented NoSQL database.","title":"Couchbase Module"},{"location":"modules/databases/couchbase/#usage-example","text":"Running Couchbase as a stand-in in a test: Define a bucket: Bucket Definition BucketDefinition bucketDefinition = new BucketDefinition ( \"mybucket\" ); define a container: Container definition CouchbaseContainer container = new CouchbaseContainer ( couchbaseImage ). withBucket ( bucketDefinition ) create an cluster: Cluster creation Cluster cluster = Cluster . connect ( container . getConnectionString (), container . getUsername (), container . getPassword () );","title":"Usage example"},{"location":"modules/databases/couchbase/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:couchbase:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> couchbase </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/databases/cratedb/","text":"CrateDB Module See Database containers for documentation and usage that is common to all relational database container types. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:cratedb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> cratedb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"CrateDB Module"},{"location":"modules/databases/cratedb/#cratedb-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"CrateDB Module"},{"location":"modules/databases/cratedb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:cratedb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> cratedb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/databend/","text":"Databend Module Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:databend:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> databend </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Databend Module"},{"location":"modules/databases/databend/#databend-module","text":"","title":"Databend Module"},{"location":"modules/databases/databend/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:databend:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> databend </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/db2/","text":"DB2 Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. See Database containers for documentation and usage that is common to all relational database container types. Usage example Running DB2 as a stand-in for in a test: public class SomeTest { @ClassRule public Db2Container db2 = new Db2Container () . acceptLicense (); @Test public void someTestMethod () { String url = db2 . getJdbcUrl (); ... create a connection and run test as normal } EULA Acceptance Due to licencing restrictions you are required to accept an EULA for this container image. To indicate that you accept the DB2 image EULA, call the acceptLicense() method, or place a file at the root of the classpath named container-license-acceptance.txt , e.g. at src/test/resources/container-license-acceptance.txt . This file should contain the line: ibmcom/db2:11.5.0.0a (or, if you are overriding the docker image name/tag, update accordingly). Please see the ibmcom/db2 image documentation for a link to the EULA document. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:db2:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> db2 </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"DB2 Module"},{"location":"modules/databases/db2/#db2-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. See Database containers for documentation and usage that is common to all relational database container types.","title":"DB2 Module"},{"location":"modules/databases/db2/#usage-example","text":"Running DB2 as a stand-in for in a test: public class SomeTest { @ClassRule public Db2Container db2 = new Db2Container () . acceptLicense (); @Test public void someTestMethod () { String url = db2 . getJdbcUrl (); ... create a connection and run test as normal } EULA Acceptance Due to licencing restrictions you are required to accept an EULA for this container image. To indicate that you accept the DB2 image EULA, call the acceptLicense() method, or place a file at the root of the classpath named container-license-acceptance.txt , e.g. at src/test/resources/container-license-acceptance.txt . This file should contain the line: ibmcom/db2:11.5.0.0a (or, if you are overriding the docker image name/tag, update accordingly). Please see the ibmcom/db2 image documentation for a link to the EULA document.","title":"Usage example"},{"location":"modules/databases/db2/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:db2:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> db2 </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/dynalite/","text":"Dynalite Module Testcontainers module for Dynalite . Dynalite is a clone of DynamoDB, enabling local testing. Usage example Running Dynalite as a stand-in for DynamoDB in a test: public class SomeTest { @Rule public DynaliteContainer dynamoDB = new DynaliteContainer (); @Test public void someTestMethod () { // getClient() returns a preconfigured DynamoDB client that is connected to the // dynalite container final AmazonDynamoDB client = dynamoDB . getClient (); ... interact with client as if using DynamoDB normally Why Dynalite for DynamoDB testing? In part, because it's light and quick to run. Also, please see the reasons given by the author of Dynalite and the problems with Amazon's DynamoDB Local . Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:dynalite:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> dynalite </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add an AWS SDK JAR to your project. You should ensure that your project also has a suitable AWS SDK JAR as a dependency.","title":"Dynalite Module"},{"location":"modules/databases/dynalite/#dynalite-module","text":"Testcontainers module for Dynalite . Dynalite is a clone of DynamoDB, enabling local testing.","title":"Dynalite Module"},{"location":"modules/databases/dynalite/#usage-example","text":"Running Dynalite as a stand-in for DynamoDB in a test: public class SomeTest { @Rule public DynaliteContainer dynamoDB = new DynaliteContainer (); @Test public void someTestMethod () { // getClient() returns a preconfigured DynamoDB client that is connected to the // dynalite container final AmazonDynamoDB client = dynamoDB . getClient (); ... interact with client as if using DynamoDB normally","title":"Usage example"},{"location":"modules/databases/dynalite/#why-dynalite-for-dynamodb-testing","text":"In part, because it's light and quick to run. Also, please see the reasons given by the author of Dynalite and the problems with Amazon's DynamoDB Local .","title":"Why Dynalite for DynamoDB testing?"},{"location":"modules/databases/dynalite/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:dynalite:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> dynalite </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add an AWS SDK JAR to your project. You should ensure that your project also has a suitable AWS SDK JAR as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/influxdb/","text":"InfluxDB Module Testcontainers module for InfluxData InfluxDB . Important note There are breaking changes in InfluxDB 2.x. For more information refer to the main documentation . You can find more information about the official InfluxDB image on Docker Hub . InfluxDB 2.x usage example Running a InfluxDBContainer as a stand-in for InfluxDB in a test: Create an InfluxDB container final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:2.0.7\" ) ) The InfluxDB instance will be setup with the following data: Property Default Value username test-user password test-password organization test-org bucket test-bucket retention 0 (infinite) adminToken - For more details about the InfluxDB setup, please visit the official InfluxDB documentation . It is possible to overwrite the default property values. Create a container with InfluxDB admin token: Create an InfluxDB container with admin token final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:2.0.7\" ) ) . withAdminToken ( ADMIN_TOKEN ) Or create a container with custom username, password, bucket, organization, and retention time: Create an InfluxDB container with custom settings final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:2.0.7\" ) ) . withUsername ( USERNAME ) . withPassword ( PASSWORD ) . withOrganization ( ORG ) . withBucket ( BUCKET ) . withRetention ( RETENTION ); The following code snippet shows how you can create an InfluxDB Java client: Create an InfluxDB Java client public static InfluxDBClient createClient ( final InfluxDBContainer <?> influxDBContainer ) { final InfluxDBClientOptions influxDBClientOptions = InfluxDBClientOptions . builder () . url ( influxDBContainer . getUrl ()) . authenticate ( influxDBContainer . getUsername (), influxDBContainer . getPassword (). toCharArray ()) . bucket ( influxDBContainer . getBucket ()) . org ( influxDBContainer . getOrganization ()) . build (); return InfluxDBClientFactory . create ( influxDBClientOptions ); } Hint You can find the latest documentation about the InfluxDB 2.x Java client here . InfluxDB 1.x usage example Running a InfluxDBContainer as a stand-in for InfluxDB in a test with default env variables: Create an InfluxDB container final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:1.4.3\" ) ) The InfluxDB instance will be setup with the following data: Property Default Value username test-user password test-password authEnabled true admin admin adminPassword password database - It is possible to overwrite the default values. For instance, creating an InfluxDB container with a custom username, password, and database name: Create an InfluxDB container with custom settings final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:1.4.3\" ) ) . withDatabase ( DATABASE ) . withUsername ( USER ) . withPassword ( PASSWORD ) In the following example you will find a snippet to create an InfluxDB client using the official Java client: Create an InfluxDB Java client public static InfluxDB createInfluxDBWithUrl ( final InfluxDBContainer <?> container ) { InfluxDB influxDB = InfluxDBFactory . connect ( container . getUrl (), container . getUsername (), container . getPassword () ); influxDB . setDatabase ( container . getDatabase ()); return influxDB ; } Hint You can find the latest documentation about the InfluxDB 1.x Java client here . Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:influxdb:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> influxdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"InfluxDB Module"},{"location":"modules/databases/influxdb/#influxdb-module","text":"Testcontainers module for InfluxData InfluxDB .","title":"InfluxDB Module"},{"location":"modules/databases/influxdb/#important-note","text":"There are breaking changes in InfluxDB 2.x. For more information refer to the main documentation . You can find more information about the official InfluxDB image on Docker Hub .","title":"Important note"},{"location":"modules/databases/influxdb/#influxdb-2x-usage-example","text":"Running a InfluxDBContainer as a stand-in for InfluxDB in a test: Create an InfluxDB container final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:2.0.7\" ) ) The InfluxDB instance will be setup with the following data: Property Default Value username test-user password test-password organization test-org bucket test-bucket retention 0 (infinite) adminToken - For more details about the InfluxDB setup, please visit the official InfluxDB documentation . It is possible to overwrite the default property values. Create a container with InfluxDB admin token: Create an InfluxDB container with admin token final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:2.0.7\" ) ) . withAdminToken ( ADMIN_TOKEN ) Or create a container with custom username, password, bucket, organization, and retention time: Create an InfluxDB container with custom settings final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:2.0.7\" ) ) . withUsername ( USERNAME ) . withPassword ( PASSWORD ) . withOrganization ( ORG ) . withBucket ( BUCKET ) . withRetention ( RETENTION ); The following code snippet shows how you can create an InfluxDB Java client: Create an InfluxDB Java client public static InfluxDBClient createClient ( final InfluxDBContainer <?> influxDBContainer ) { final InfluxDBClientOptions influxDBClientOptions = InfluxDBClientOptions . builder () . url ( influxDBContainer . getUrl ()) . authenticate ( influxDBContainer . getUsername (), influxDBContainer . getPassword (). toCharArray ()) . bucket ( influxDBContainer . getBucket ()) . org ( influxDBContainer . getOrganization ()) . build (); return InfluxDBClientFactory . create ( influxDBClientOptions ); } Hint You can find the latest documentation about the InfluxDB 2.x Java client here .","title":"InfluxDB 2.x usage example"},{"location":"modules/databases/influxdb/#influxdb-1x-usage-example","text":"Running a InfluxDBContainer as a stand-in for InfluxDB in a test with default env variables: Create an InfluxDB container final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:1.4.3\" ) ) The InfluxDB instance will be setup with the following data: Property Default Value username test-user password test-password authEnabled true admin admin adminPassword password database - It is possible to overwrite the default values. For instance, creating an InfluxDB container with a custom username, password, and database name: Create an InfluxDB container with custom settings final InfluxDBContainer <?> influxDBContainer = new InfluxDBContainer <> ( DockerImageName . parse ( \"influxdb:1.4.3\" ) ) . withDatabase ( DATABASE ) . withUsername ( USER ) . withPassword ( PASSWORD ) In the following example you will find a snippet to create an InfluxDB client using the official Java client: Create an InfluxDB Java client public static InfluxDB createInfluxDBWithUrl ( final InfluxDBContainer <?> container ) { InfluxDB influxDB = InfluxDBFactory . connect ( container . getUrl (), container . getUsername (), container . getPassword () ); influxDB . setDatabase ( container . getDatabase ()); return influxDB ; } Hint You can find the latest documentation about the InfluxDB 1.x Java client here .","title":"InfluxDB 1.x usage example"},{"location":"modules/databases/influxdb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:influxdb:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> influxdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/jdbc/","text":"JDBC support You can obtain a temporary database in one of two ways: Using a specially modified JDBC URL : after making a very simple modification to your system's JDBC URL string, Testcontainers will provide a disposable stand-in database that can be used without requiring modification to your application code. JUnit @Rule/@ClassRule : this mode starts a database inside a container before your tests and tears it down afterwards. Database containers launched via JDBC URL scheme As long as you have Testcontainers and the appropriate JDBC driver on your classpath, you can simply modify regular JDBC connection URLs to get a fresh containerized instance of the database each time your application starts up. N.B: TC needs to be on your application's classpath at runtime for this to work For Spring Boot (Before version 2.3.0 ) you need to specify the driver manually spring.datasource.driver-class-name=org.testcontainers.jdbc.ContainerDatabaseDriver Original URL : jdbc:mysql://localhost:3306/databasename Insert tc: after jdbc: as follows. Note that the hostname, port and database name will be ignored; you can leave these as-is or set them to any value. Note We will use /// (host-less URIs) from now on to emphasis the unimportance of the host:port pair. From Testcontainers' perspective, jdbc:mysql:8.0.36://localhost:3306/databasename and jdbc:mysql:8.0.36:///databasename is the same URI. Warning If you're using the JDBC URL support, there is no need to instantiate an instance of the container - Testcontainers will do it automagically. JDBC URL examples Using ClickHouse jdbc:tc:clickhouse:18.10.3:///databasename Using CockroachDB jdbc:tc:cockroach:v21.2.3:///databasename Using CrateDB jdbc:tc:cratedb:5.2.3//localhost:5432/crate Using DB2 jdbc:tc:db2:11.5.0.0a//localhost:5432/crate Using MariaDB jdbc:tc:mariadb:10.3.39:///databasename Using MySQL jdbc:tc:mysql:8.0.36:///databasename Using MSSQL Server jdbc:tc:sqlserver:2017-CU12:///databasename Using OceanBase jdbc:tc:oceanbasece:4.2.1-lts:///databasename Using Oracle jdbc:tc:oracle:21-slim-faststart:///databasename Using PostGIS jdbc:tc:postgis:9.6-2.5:///databasename Using PostgreSQL jdbc:tc:postgresql:9.6.8:///databasename Using QuestDB jdbc:tc:questdb:6.5.3:///databasename Using TimescaleDB jdbc:tc:timescaledb:2.1.0-pg13:///databasename Using PGVector jdbc:tc:pgvector:pg16:///databasename Using TiDB jdbc:tc:tidb:v6.1.0:///databasename Using Timeplus jdbc:tc:timeplus:2.3.21:///databasename Using Trino jdbc:tc:trino:352://localhost/memory/default Using YugabyteDB jdbc:tc:yugabyte:2.14.4.0-b26:///databasename Using a classpath init script Testcontainers can run an init script after the database container is started, but before your code is given a connection to it. The script must be on the classpath, and is referenced as follows: jdbc:tc:mysql:8.0.36:///databasename?TC_INITSCRIPT=somepath/init_mysql.sql This is useful if you have a fixed script for setting up database schema, etc. Using an init script from a file If the init script path is prefixed file: , it will be loaded from a file (relative to the working directory, which will usually be the project root). jdbc:tc:mysql:8.0.36:///databasename?TC_INITSCRIPT=file:src/main/resources/init_mysql.sql Using an init function Instead of running a fixed script for DB setup, it may be useful to call a Java function that you define. This is intended to allow you to trigger database schema migration tools. To do this, add TC_INITFUNCTION to the URL as follows, passing a full path to the class name and method: jdbc:tc:mysql:8.0.36:///databasename?TC_INITFUNCTION=org.testcontainers.jdbc.JDBCDriverTest::sampleInitFunction The init function must be a public static method which takes a java.sql.Connection as its only parameter, e.g. public class JDBCDriverTest { public static void sampleInitFunction ( Connection connection ) throws SQLException { // e.g. run schema setup or Flyway/liquibase/etc DB migrations here... } ... Running container in daemon mode By default database container is being stopped as soon as last connection is closed. There are cases when you might need to start container and keep it running till you stop it explicitly or JVM is shutdown. To do this, add TC_DAEMON parameter to the URL as follows: jdbc:tc:mysql:8.0.36:///databasename?TC_DAEMON=true With this parameter database container will keep running even when there's no open connections. Running container with tmpfs options Container can have tmpfs mounts for storing data in host memory. This is useful if you want to speed up your database tests. Be aware that the data will be lost when the container stops. To pass this option to the container, add TC_TMPFS parameter to the URL as follows: jdbc:tc:postgresql:9.6.8:///databasename?TC_TMPFS=/testtmpfs:rw If you need more than one option, separate them by comma (e.g. TC_TMPFS=key:value,key1:value1&other_parameters=foo ). For more information about tmpfs mount, see the official Docker documentation . Database container objects In case you can't use the URL support, or need to fine-tune the container, you can instantiate it yourself. Add a @Rule or @ClassRule to your test class, e.g.: public class SimpleMySQLTest { @Rule public MySQLContainer mysql = new MySQLContainer (); Now, in your test code (or a suitable setup method), you can obtain details necessary to connect to this database: mysql.getJdbcUrl() provides a JDBC URL your code can connect to mysql.getUsername() provides the username your code should pass to the driver mysql.getPassword() provides the password your code should pass to the driver Note that if you use @Rule , you will be given an isolated container for each test method. If you use @ClassRule , you will get on isolated container for all the methods in the test class. Examples/Tests: MySQL PostgreSQL","title":"JDBC support"},{"location":"modules/databases/jdbc/#jdbc-support","text":"You can obtain a temporary database in one of two ways: Using a specially modified JDBC URL : after making a very simple modification to your system's JDBC URL string, Testcontainers will provide a disposable stand-in database that can be used without requiring modification to your application code. JUnit @Rule/@ClassRule : this mode starts a database inside a container before your tests and tears it down afterwards.","title":"JDBC support"},{"location":"modules/databases/jdbc/#database-containers-launched-via-jdbc-url-scheme","text":"As long as you have Testcontainers and the appropriate JDBC driver on your classpath, you can simply modify regular JDBC connection URLs to get a fresh containerized instance of the database each time your application starts up. N.B: TC needs to be on your application's classpath at runtime for this to work For Spring Boot (Before version 2.3.0 ) you need to specify the driver manually spring.datasource.driver-class-name=org.testcontainers.jdbc.ContainerDatabaseDriver Original URL : jdbc:mysql://localhost:3306/databasename Insert tc: after jdbc: as follows. Note that the hostname, port and database name will be ignored; you can leave these as-is or set them to any value. Note We will use /// (host-less URIs) from now on to emphasis the unimportance of the host:port pair. From Testcontainers' perspective, jdbc:mysql:8.0.36://localhost:3306/databasename and jdbc:mysql:8.0.36:///databasename is the same URI. Warning If you're using the JDBC URL support, there is no need to instantiate an instance of the container - Testcontainers will do it automagically.","title":"Database containers launched via JDBC URL scheme"},{"location":"modules/databases/jdbc/#jdbc-url-examples","text":"","title":"JDBC URL examples"},{"location":"modules/databases/jdbc/#using-clickhouse","text":"jdbc:tc:clickhouse:18.10.3:///databasename","title":"Using ClickHouse"},{"location":"modules/databases/jdbc/#using-cockroachdb","text":"jdbc:tc:cockroach:v21.2.3:///databasename","title":"Using CockroachDB"},{"location":"modules/databases/jdbc/#using-cratedb","text":"jdbc:tc:cratedb:5.2.3//localhost:5432/crate","title":"Using CrateDB"},{"location":"modules/databases/jdbc/#using-db2","text":"jdbc:tc:db2:11.5.0.0a//localhost:5432/crate","title":"Using DB2"},{"location":"modules/databases/jdbc/#using-mariadb","text":"jdbc:tc:mariadb:10.3.39:///databasename","title":"Using MariaDB"},{"location":"modules/databases/jdbc/#using-mysql","text":"jdbc:tc:mysql:8.0.36:///databasename","title":"Using MySQL"},{"location":"modules/databases/jdbc/#using-mssql-server","text":"jdbc:tc:sqlserver:2017-CU12:///databasename","title":"Using MSSQL Server"},{"location":"modules/databases/jdbc/#using-oceanbase","text":"jdbc:tc:oceanbasece:4.2.1-lts:///databasename","title":"Using OceanBase"},{"location":"modules/databases/jdbc/#using-oracle","text":"jdbc:tc:oracle:21-slim-faststart:///databasename","title":"Using Oracle"},{"location":"modules/databases/jdbc/#using-postgis","text":"jdbc:tc:postgis:9.6-2.5:///databasename","title":"Using PostGIS"},{"location":"modules/databases/jdbc/#using-postgresql","text":"jdbc:tc:postgresql:9.6.8:///databasename","title":"Using PostgreSQL"},{"location":"modules/databases/jdbc/#using-questdb","text":"jdbc:tc:questdb:6.5.3:///databasename","title":"Using QuestDB"},{"location":"modules/databases/jdbc/#using-timescaledb","text":"jdbc:tc:timescaledb:2.1.0-pg13:///databasename","title":"Using TimescaleDB"},{"location":"modules/databases/jdbc/#using-pgvector","text":"jdbc:tc:pgvector:pg16:///databasename","title":"Using PGVector"},{"location":"modules/databases/jdbc/#using-tidb","text":"jdbc:tc:tidb:v6.1.0:///databasename","title":"Using TiDB"},{"location":"modules/databases/jdbc/#using-timeplus","text":"jdbc:tc:timeplus:2.3.21:///databasename","title":"Using Timeplus"},{"location":"modules/databases/jdbc/#using-trino","text":"jdbc:tc:trino:352://localhost/memory/default","title":"Using Trino"},{"location":"modules/databases/jdbc/#using-yugabytedb","text":"jdbc:tc:yugabyte:2.14.4.0-b26:///databasename","title":"Using YugabyteDB"},{"location":"modules/databases/jdbc/#using-a-classpath-init-script","text":"Testcontainers can run an init script after the database container is started, but before your code is given a connection to it. The script must be on the classpath, and is referenced as follows: jdbc:tc:mysql:8.0.36:///databasename?TC_INITSCRIPT=somepath/init_mysql.sql This is useful if you have a fixed script for setting up database schema, etc.","title":"Using a classpath init script"},{"location":"modules/databases/jdbc/#using-an-init-script-from-a-file","text":"If the init script path is prefixed file: , it will be loaded from a file (relative to the working directory, which will usually be the project root). jdbc:tc:mysql:8.0.36:///databasename?TC_INITSCRIPT=file:src/main/resources/init_mysql.sql","title":"Using an init script from a file"},{"location":"modules/databases/jdbc/#using-an-init-function","text":"Instead of running a fixed script for DB setup, it may be useful to call a Java function that you define. This is intended to allow you to trigger database schema migration tools. To do this, add TC_INITFUNCTION to the URL as follows, passing a full path to the class name and method: jdbc:tc:mysql:8.0.36:///databasename?TC_INITFUNCTION=org.testcontainers.jdbc.JDBCDriverTest::sampleInitFunction The init function must be a public static method which takes a java.sql.Connection as its only parameter, e.g. public class JDBCDriverTest { public static void sampleInitFunction ( Connection connection ) throws SQLException { // e.g. run schema setup or Flyway/liquibase/etc DB migrations here... } ...","title":"Using an init function"},{"location":"modules/databases/jdbc/#running-container-in-daemon-mode","text":"By default database container is being stopped as soon as last connection is closed. There are cases when you might need to start container and keep it running till you stop it explicitly or JVM is shutdown. To do this, add TC_DAEMON parameter to the URL as follows: jdbc:tc:mysql:8.0.36:///databasename?TC_DAEMON=true With this parameter database container will keep running even when there's no open connections.","title":"Running container in daemon mode"},{"location":"modules/databases/jdbc/#running-container-with-tmpfs-options","text":"Container can have tmpfs mounts for storing data in host memory. This is useful if you want to speed up your database tests. Be aware that the data will be lost when the container stops. To pass this option to the container, add TC_TMPFS parameter to the URL as follows: jdbc:tc:postgresql:9.6.8:///databasename?TC_TMPFS=/testtmpfs:rw If you need more than one option, separate them by comma (e.g. TC_TMPFS=key:value,key1:value1&other_parameters=foo ). For more information about tmpfs mount, see the official Docker documentation .","title":"Running container with tmpfs options"},{"location":"modules/databases/jdbc/#database-container-objects","text":"In case you can't use the URL support, or need to fine-tune the container, you can instantiate it yourself. Add a @Rule or @ClassRule to your test class, e.g.: public class SimpleMySQLTest { @Rule public MySQLContainer mysql = new MySQLContainer (); Now, in your test code (or a suitable setup method), you can obtain details necessary to connect to this database: mysql.getJdbcUrl() provides a JDBC URL your code can connect to mysql.getUsername() provides the username your code should pass to the driver mysql.getPassword() provides the password your code should pass to the driver Note that if you use @Rule , you will be given an isolated container for each test method. If you use @ClassRule , you will get on isolated container for all the methods in the test class. Examples/Tests: MySQL PostgreSQL","title":"Database container objects"},{"location":"modules/databases/mariadb/","text":"MariaDB Module See Database containers for documentation and usage that is common to all relational database container types. MariaDB root user password If no custom password is specified, the container will use the default user password test for the root user as well. When you specify a custom password for the database user, this will also act as the password of the MariaDB root user automatically. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mariadb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mariadb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"MariaDB Module"},{"location":"modules/databases/mariadb/#mariadb-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"MariaDB Module"},{"location":"modules/databases/mariadb/#mariadb-root-user-password","text":"If no custom password is specified, the container will use the default user password test for the root user as well. When you specify a custom password for the database user, this will also act as the password of the MariaDB root user automatically.","title":"MariaDB root user password"},{"location":"modules/databases/mariadb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mariadb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mariadb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/mongodb/","text":"MongoDB Module The MongoDB module provides two Testcontainers for MongoDB unit testing: MongoDBContainer - the core MongoDB database MongoDBAtlasLocalContainer - the core MongoDB database combined with MongoDB Atlas Search + Atlas Vector Search MongoDBContainer Usage example The following example shows how to create a MongoDBContainer: Creating a MongoDB container final MongoDBContainer mongoDBContainer = new MongoDBContainer ( \"mongo:4.0.10\" ) And how to start it: Starting a MongoDB container mongoDBContainer . start (); Note To construct a multi-node MongoDB cluster, consider the mongodb-replica-set project Motivation Implement a reusable, cross-platform, simple to install solution that doesn't depend on fixed ports to test MongoDB transactions. General info MongoDB starting from version 4 supports multi-document transactions only for a replica set. For instance, to initialize a single node replica set on fixed ports via Docker, one has to do the following: Run a MongoDB container of version 4 and up specifying --replSet command Initialize a single replica set via executing a proper command Wait for the initialization to complete Provide a special url for a user to employ with a MongoDB driver without specifying replicaSet As we can see, there is a lot of operations to execute and we even haven't touched a non-fixed port approach. That's where the MongoDBContainer might come in handy. MongoDBAtlasLocalContainer Usage example The following example shows how to create a MongoDBAtlasLocalContainer: Creating a MongoDB Atlas Local Container MongoDBAtlasLocalContainer atlasLocalContainer = new MongoDBAtlasLocalContainer ( \"mongodb/mongodb-atlas-local:7.0.9\" ); And how to start it: Start the Container atlasLocalContainer . start (); The connection string provided by the MongoDBAtlasLocalContainer's getConnectionString() method includes the dynamically allocated port: Get the Connection String String connectionString = atlasLocalContainer . getConnectionString (); e.g. mongodb://localhost:12345/?directConnection=true References MongoDB Atlas Local combines the MongoDB database engine with MongoT, a sidecar process for advanced searching capabilities built by MongoDB and powered by Apache Lucene . The container (mongodb/mongodb-atlas-local) documentation can be found here . General information about Atlas Search can be found here . Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mongodb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mongodb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency Copyright Copyright (c) 2019 Konstantin Silaev silaev256@gmail.com","title":"MongoDB Module"},{"location":"modules/databases/mongodb/#mongodb-module","text":"The MongoDB module provides two Testcontainers for MongoDB unit testing: MongoDBContainer - the core MongoDB database MongoDBAtlasLocalContainer - the core MongoDB database combined with MongoDB Atlas Search + Atlas Vector Search","title":"MongoDB Module"},{"location":"modules/databases/mongodb/#mongodbcontainer","text":"","title":"MongoDBContainer"},{"location":"modules/databases/mongodb/#usage-example","text":"The following example shows how to create a MongoDBContainer: Creating a MongoDB container final MongoDBContainer mongoDBContainer = new MongoDBContainer ( \"mongo:4.0.10\" ) And how to start it: Starting a MongoDB container mongoDBContainer . start (); Note To construct a multi-node MongoDB cluster, consider the mongodb-replica-set project","title":"Usage example"},{"location":"modules/databases/mongodb/#motivation","text":"Implement a reusable, cross-platform, simple to install solution that doesn't depend on fixed ports to test MongoDB transactions.","title":"Motivation"},{"location":"modules/databases/mongodb/#general-info","text":"MongoDB starting from version 4 supports multi-document transactions only for a replica set. For instance, to initialize a single node replica set on fixed ports via Docker, one has to do the following: Run a MongoDB container of version 4 and up specifying --replSet command Initialize a single replica set via executing a proper command Wait for the initialization to complete Provide a special url for a user to employ with a MongoDB driver without specifying replicaSet As we can see, there is a lot of operations to execute and we even haven't touched a non-fixed port approach. That's where the MongoDBContainer might come in handy.","title":"General info"},{"location":"modules/databases/mongodb/#mongodbatlaslocalcontainer","text":"","title":"MongoDBAtlasLocalContainer"},{"location":"modules/databases/mongodb/#usage-example_1","text":"The following example shows how to create a MongoDBAtlasLocalContainer: Creating a MongoDB Atlas Local Container MongoDBAtlasLocalContainer atlasLocalContainer = new MongoDBAtlasLocalContainer ( \"mongodb/mongodb-atlas-local:7.0.9\" ); And how to start it: Start the Container atlasLocalContainer . start (); The connection string provided by the MongoDBAtlasLocalContainer's getConnectionString() method includes the dynamically allocated port: Get the Connection String String connectionString = atlasLocalContainer . getConnectionString (); e.g. mongodb://localhost:12345/?directConnection=true","title":"Usage example"},{"location":"modules/databases/mongodb/#references","text":"MongoDB Atlas Local combines the MongoDB database engine with MongoT, a sidecar process for advanced searching capabilities built by MongoDB and powered by Apache Lucene . The container (mongodb/mongodb-atlas-local) documentation can be found here . General information about Atlas Search can be found here .","title":"References"},{"location":"modules/databases/mongodb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mongodb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mongodb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency","title":"Adding this module to your project dependencies"},{"location":"modules/databases/mongodb/#copyright","text":"Copyright (c) 2019 Konstantin Silaev silaev256@gmail.com","title":"Copyright"},{"location":"modules/databases/mssqlserver/","text":"MS SQL Server Module See Database containers for documentation and usage that is common to all relational database container types. Usage example Running MS SQL Server as a stand-in for in a test: public class SomeTest { @Rule public MSSQLServerContainer mssqlserver = new MSSQLServerContainer () . acceptLicense (); @Test public void someTestMethod () { String url = mssqlserver . getJdbcUrl (); ... create a connection and run test as normal EULA Acceptance Due to licencing restrictions you are required to accept an EULA for this container image. To indicate that you accept the MS SQL Server image EULA, call the acceptLicense() method, or place a file at the root of the classpath named container-license-acceptance.txt , e.g. at src/test/resources/container-license-acceptance.txt . This file should contain the line: mcr.microsoft.com/mssql/server:2017-CU12 (or, if you are overriding the docker image name/tag, update accordingly). Please see the microsoft-mssql-server image documentation for a link to the EULA document. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mssqlserver:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mssqlserver </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency. License See LICENSE . Copyright Copyright (c) 2017 - 2019 G DATA Software AG and other authors. See AUTHORS for contributors.","title":"MS SQL Server Module"},{"location":"modules/databases/mssqlserver/#ms-sql-server-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"MS SQL Server Module"},{"location":"modules/databases/mssqlserver/#usage-example","text":"Running MS SQL Server as a stand-in for in a test: public class SomeTest { @Rule public MSSQLServerContainer mssqlserver = new MSSQLServerContainer () . acceptLicense (); @Test public void someTestMethod () { String url = mssqlserver . getJdbcUrl (); ... create a connection and run test as normal EULA Acceptance Due to licencing restrictions you are required to accept an EULA for this container image. To indicate that you accept the MS SQL Server image EULA, call the acceptLicense() method, or place a file at the root of the classpath named container-license-acceptance.txt , e.g. at src/test/resources/container-license-acceptance.txt . This file should contain the line: mcr.microsoft.com/mssql/server:2017-CU12 (or, if you are overriding the docker image name/tag, update accordingly). Please see the microsoft-mssql-server image documentation for a link to the EULA document.","title":"Usage example"},{"location":"modules/databases/mssqlserver/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mssqlserver:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mssqlserver </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/mssqlserver/#license","text":"See LICENSE .","title":"License"},{"location":"modules/databases/mssqlserver/#copyright","text":"Copyright (c) 2017 - 2019 G DATA Software AG and other authors. See AUTHORS for contributors.","title":"Copyright"},{"location":"modules/databases/mysql/","text":"MySQL Module See Database containers for documentation and usage that is common to all relational database container types. Overriding MySQL my.cnf settings For MySQL databases, it is possible to override configuration settings using resources on the classpath. Assuming somepath/mysql_conf_override is a directory on the classpath containing .cnf files, the following URL can be used: jdbc:tc:mysql:8.0.36://hostname/databasename?TC_MY_CNF=somepath/mysql_conf_override Any .cnf files in this classpath directory will be mapped into the database container's /etc/mysql/conf.d directory, and will be able to override server settings when the container starts. MySQL root user password If no custom password is specified, the container will use the default user password test for the root user as well. When you specify a custom password for the database user, this will also act as the password of the MySQL root user automatically. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mysql:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mysql </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency. Start Using MySQL Container in Integration Test import org.testcontainers.containers.MySQLContainer import org.testcontainers.spock.Testcontainers import spock.lang.Shared import spock.lang.Specification @Testcontainers class MyITSpec extends Specification { @Shared final MySQLContainer MYSQL = new MySQLContainer ( \"mysql:5.7.43\" ). withDatabaseName ( \"testDbName\" ) def setupSpec () { System . setProperty ( \"DB_URL\" , String . format ( \"jdbc:mysql://localhost:%s/elide?serverTimezone=UTC\" , MYSQL . firstMappedPort ) ) } } Hint If withDatabaseName is invoked, DB container will create a database as well in the container. This is very useful for IT tests that requires a pre-configured DB to be ready","title":"MySQL Module"},{"location":"modules/databases/mysql/#mysql-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"MySQL Module"},{"location":"modules/databases/mysql/#overriding-mysql-mycnf-settings","text":"For MySQL databases, it is possible to override configuration settings using resources on the classpath. Assuming somepath/mysql_conf_override is a directory on the classpath containing .cnf files, the following URL can be used: jdbc:tc:mysql:8.0.36://hostname/databasename?TC_MY_CNF=somepath/mysql_conf_override Any .cnf files in this classpath directory will be mapped into the database container's /etc/mysql/conf.d directory, and will be able to override server settings when the container starts.","title":"Overriding MySQL my.cnf settings"},{"location":"modules/databases/mysql/#mysql-root-user-password","text":"If no custom password is specified, the container will use the default user password test for the root user as well. When you specify a custom password for the database user, this will also act as the password of the MySQL root user automatically.","title":"MySQL root user password"},{"location":"modules/databases/mysql/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:mysql:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> mysql </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/mysql/#start-using-mysql-container-in-integration-test","text":"import org.testcontainers.containers.MySQLContainer import org.testcontainers.spock.Testcontainers import spock.lang.Shared import spock.lang.Specification @Testcontainers class MyITSpec extends Specification { @Shared final MySQLContainer MYSQL = new MySQLContainer ( \"mysql:5.7.43\" ). withDatabaseName ( \"testDbName\" ) def setupSpec () { System . setProperty ( \"DB_URL\" , String . format ( \"jdbc:mysql://localhost:%s/elide?serverTimezone=UTC\" , MYSQL . firstMappedPort ) ) } } Hint If withDatabaseName is invoked, DB container will create a database as well in the container. This is very useful for IT tests that requires a pre-configured DB to be ready","title":"Start Using MySQL Container in Integration Test"},{"location":"modules/databases/neo4j/","text":"Neo4j Module This module helps to run Neo4j using Testcontainers. Note that it's based on the official Docker image provided by Neo4j, Inc. Even though the latest LTS version of Neo4j 4.4 is used in the examples of this documentation, the Testcontainers integration supports also newer 5.x images of Neo4j. Usage example Declare your Testcontainers as a @ClassRule or @Rule in a JUnit 4 test or as static or member attribute of a JUnit 5 test annotated with @Container as you would with other Testcontainers. You can either use call getBoltUrl() or getHttpUrl() on the Neo4j container. getBoltUrl() is meant to be used with one of the official Bolt drivers while getHttpUrl() gives you the HTTP-address of the transactional HTTP endpoint. On the JVM you would most likely use the Java driver . The following example uses the JUnit 5 extension @Testcontainers and demonstrates both the usage of the Java Driver and the REST endpoint: JUnit 5 example @Testcontainers class Neo4jExampleTest { @Container private static Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( DockerImageName . parse ( \"neo4j:4.4\" )) . withoutAuthentication (); // Disable password @Test void testSomethingUsingBolt () { // Retrieve the Bolt URL from the container String boltUrl = neo4jContainer . getBoltUrl (); try ( Driver driver = GraphDatabase . driver ( boltUrl , AuthTokens . none ()); Session session = driver . session ()) { long one = session . run ( \"RETURN 1\" , Collections . emptyMap ()). next (). get ( 0 ). asLong (); assertThat ( one ). isEqualTo ( 1L ); } catch ( Exception e ) { fail ( e . getMessage ()); } } @Test void testSomethingUsingHttp () throws IOException { // Retrieve the HTTP URL from the container String httpUrl = neo4jContainer . getHttpUrl (); URL url = new URL ( httpUrl + \"/db/data/transaction/commit\" ); HttpURLConnection con = ( HttpURLConnection ) url . openConnection (); con . setRequestMethod ( \"POST\" ); con . setRequestProperty ( \"Content-Type\" , \"application/json\" ); con . setDoOutput ( true ); try ( Writer out = new OutputStreamWriter ( con . getOutputStream ())) { out . write ( \"{\\\"statements\\\":[{\\\"statement\\\":\\\"RETURN 1\\\"}]}\" ); out . flush (); } assertThat ( con . getResponseCode ()). isEqualTo ( HttpURLConnection . HTTP_OK ); try ( BufferedReader buffer = new BufferedReader ( new InputStreamReader ( con . getInputStream ()))) { String expectedResponse = \"{\\\"results\\\":[{\\\"columns\\\":[\\\"1\\\"],\\\"data\\\":[{\\\"row\\\":[1],\\\"meta\\\":[null]}]}],\\\"errors\\\":[]}\" ; String response = buffer . lines (). collect ( Collectors . joining ( \"\\n\" )); assertThat ( response ). isEqualTo ( expectedResponse ); } } } You are not limited to Unit tests, and you can use an instance of the Neo4j Testcontainers in vanilla Java code as well. Additional features Custom password A custom password can be provided: Custom password Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ). withAdminPassword ( \"verySecret\" ); Disable authentication Authentication can be disabled: Disable authentication Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withoutAuthentication () Random password A random ( UUID -random based) password can be set: Random password Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ). withRandomPassword (); Neo4j-Configuration Neo4j's Docker image needs Neo4j configuration options in a dedicated format. The container takes care of that, and you can configure the database with standard options like the following: Neo4j configuration Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withNeo4jConfig ( \"dbms.security.procedures.unrestricted\" , \"apoc.*,algo.*\" ) . withNeo4jConfig ( \"dbms.tx_log.rotation.size\" , \"42M\" ); Add custom plugins Custom plugins, like APOC, can be copied over to the container from any classpath or host resource like this: Plugin jar Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withPlugins ( MountableFile . forClasspathResource ( \"/custom-plugins/hello-world.jar\" )) Whole directories work as well: Plugin folder Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withPlugins ( MountableFile . forClasspathResource ( \"/custom-plugins\" )) Add Neo4j Docker Labs plugins Add any Neo4j Labs plugin from the Neo4j 4.4 Docker Labs plugin list or Neo4j 5 plugin list . Note The methods withLabsPlugins(Neo4jLabsPlugin...) and withLabsPlugins(String... plugins) are deprecated. Please the method withPlugins(String... plugins) . Configure Neo4j Labs Plugins Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) // . withPlugins ( \"apoc\" , \"bloom\" ); Start the container with a predefined database If you have an existing database ( graph.db ) you want to work with, copy it over to the container like this: Copy database Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:3.5.30\" ) . withDatabase ( MountableFile . forClasspathResource ( \"/test-graph.db\" )) Note The withDatabase method will only work with Neo4j 3.5 and throw an exception if used in combination with a newer version. Choose your Neo4j license If you need the Neo4j enterprise license, you can declare your Neo4j container like this: Enterprise edition Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withEnterpriseEdition () This creates a Testcontainers based on the Docker image build with the Enterprise version of Neo4j 4.4. The call to withEnterpriseEdition adds the required environment variable that you accepted the terms and condition of the enterprise version. You accept those by adding a file named container-license-acceptance.txt to the root of your classpath containing the text neo4j:4.4-enterprise in one line. If you are planning to run a newer Neo4j 5.x enterprise edition image, you have to manually define the proper enterprise image (e.g. neo4j:5-enterprise ) and set the environment variable NEO4J_ACCEPT_LICENSE_AGREEMENT by adding .withEnv(\"NEO4J_ACCEPT_LICENSE_AGREEMENT\", \"yes\") to your container definition. You'll find more information about licensing Neo4j here: About Neo4j Licenses . Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:neo4j:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> neo4j </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Add the Neo4j Java driver if you plan to access the Testcontainers via Bolt: Gradle Maven compile \"org.neo4j.driver:neo4j-java-driver:4.4.13\" <dependency> <groupId> org.neo4j.driver </groupId> <artifactId> neo4j-java-driver </artifactId> <version> 4.4.13 </version> </dependency>","title":"Neo4j Module"},{"location":"modules/databases/neo4j/#neo4j-module","text":"This module helps to run Neo4j using Testcontainers. Note that it's based on the official Docker image provided by Neo4j, Inc. Even though the latest LTS version of Neo4j 4.4 is used in the examples of this documentation, the Testcontainers integration supports also newer 5.x images of Neo4j.","title":"Neo4j Module"},{"location":"modules/databases/neo4j/#usage-example","text":"Declare your Testcontainers as a @ClassRule or @Rule in a JUnit 4 test or as static or member attribute of a JUnit 5 test annotated with @Container as you would with other Testcontainers. You can either use call getBoltUrl() or getHttpUrl() on the Neo4j container. getBoltUrl() is meant to be used with one of the official Bolt drivers while getHttpUrl() gives you the HTTP-address of the transactional HTTP endpoint. On the JVM you would most likely use the Java driver . The following example uses the JUnit 5 extension @Testcontainers and demonstrates both the usage of the Java Driver and the REST endpoint: JUnit 5 example @Testcontainers class Neo4jExampleTest { @Container private static Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( DockerImageName . parse ( \"neo4j:4.4\" )) . withoutAuthentication (); // Disable password @Test void testSomethingUsingBolt () { // Retrieve the Bolt URL from the container String boltUrl = neo4jContainer . getBoltUrl (); try ( Driver driver = GraphDatabase . driver ( boltUrl , AuthTokens . none ()); Session session = driver . session ()) { long one = session . run ( \"RETURN 1\" , Collections . emptyMap ()). next (). get ( 0 ). asLong (); assertThat ( one ). isEqualTo ( 1L ); } catch ( Exception e ) { fail ( e . getMessage ()); } } @Test void testSomethingUsingHttp () throws IOException { // Retrieve the HTTP URL from the container String httpUrl = neo4jContainer . getHttpUrl (); URL url = new URL ( httpUrl + \"/db/data/transaction/commit\" ); HttpURLConnection con = ( HttpURLConnection ) url . openConnection (); con . setRequestMethod ( \"POST\" ); con . setRequestProperty ( \"Content-Type\" , \"application/json\" ); con . setDoOutput ( true ); try ( Writer out = new OutputStreamWriter ( con . getOutputStream ())) { out . write ( \"{\\\"statements\\\":[{\\\"statement\\\":\\\"RETURN 1\\\"}]}\" ); out . flush (); } assertThat ( con . getResponseCode ()). isEqualTo ( HttpURLConnection . HTTP_OK ); try ( BufferedReader buffer = new BufferedReader ( new InputStreamReader ( con . getInputStream ()))) { String expectedResponse = \"{\\\"results\\\":[{\\\"columns\\\":[\\\"1\\\"],\\\"data\\\":[{\\\"row\\\":[1],\\\"meta\\\":[null]}]}],\\\"errors\\\":[]}\" ; String response = buffer . lines (). collect ( Collectors . joining ( \"\\n\" )); assertThat ( response ). isEqualTo ( expectedResponse ); } } } You are not limited to Unit tests, and you can use an instance of the Neo4j Testcontainers in vanilla Java code as well.","title":"Usage example"},{"location":"modules/databases/neo4j/#additional-features","text":"","title":"Additional features"},{"location":"modules/databases/neo4j/#custom-password","text":"A custom password can be provided: Custom password Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ). withAdminPassword ( \"verySecret\" );","title":"Custom password"},{"location":"modules/databases/neo4j/#disable-authentication","text":"Authentication can be disabled: Disable authentication Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withoutAuthentication ()","title":"Disable authentication"},{"location":"modules/databases/neo4j/#random-password","text":"A random ( UUID -random based) password can be set: Random password Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ). withRandomPassword ();","title":"Random password"},{"location":"modules/databases/neo4j/#neo4j-configuration","text":"Neo4j's Docker image needs Neo4j configuration options in a dedicated format. The container takes care of that, and you can configure the database with standard options like the following: Neo4j configuration Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withNeo4jConfig ( \"dbms.security.procedures.unrestricted\" , \"apoc.*,algo.*\" ) . withNeo4jConfig ( \"dbms.tx_log.rotation.size\" , \"42M\" );","title":"Neo4j-Configuration"},{"location":"modules/databases/neo4j/#add-custom-plugins","text":"Custom plugins, like APOC, can be copied over to the container from any classpath or host resource like this: Plugin jar Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withPlugins ( MountableFile . forClasspathResource ( \"/custom-plugins/hello-world.jar\" )) Whole directories work as well: Plugin folder Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withPlugins ( MountableFile . forClasspathResource ( \"/custom-plugins\" ))","title":"Add custom plugins"},{"location":"modules/databases/neo4j/#add-neo4j-docker-labs-plugins","text":"Add any Neo4j Labs plugin from the Neo4j 4.4 Docker Labs plugin list or Neo4j 5 plugin list . Note The methods withLabsPlugins(Neo4jLabsPlugin...) and withLabsPlugins(String... plugins) are deprecated. Please the method withPlugins(String... plugins) . Configure Neo4j Labs Plugins Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) // . withPlugins ( \"apoc\" , \"bloom\" );","title":"Add Neo4j Docker Labs plugins"},{"location":"modules/databases/neo4j/#start-the-container-with-a-predefined-database","text":"If you have an existing database ( graph.db ) you want to work with, copy it over to the container like this: Copy database Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:3.5.30\" ) . withDatabase ( MountableFile . forClasspathResource ( \"/test-graph.db\" )) Note The withDatabase method will only work with Neo4j 3.5 and throw an exception if used in combination with a newer version.","title":"Start the container with a predefined database"},{"location":"modules/databases/neo4j/#choose-your-neo4j-license","text":"If you need the Neo4j enterprise license, you can declare your Neo4j container like this: Enterprise edition Neo4jContainer <?> neo4jContainer = new Neo4jContainer <> ( \"neo4j:4.4\" ) . withEnterpriseEdition () This creates a Testcontainers based on the Docker image build with the Enterprise version of Neo4j 4.4. The call to withEnterpriseEdition adds the required environment variable that you accepted the terms and condition of the enterprise version. You accept those by adding a file named container-license-acceptance.txt to the root of your classpath containing the text neo4j:4.4-enterprise in one line. If you are planning to run a newer Neo4j 5.x enterprise edition image, you have to manually define the proper enterprise image (e.g. neo4j:5-enterprise ) and set the environment variable NEO4J_ACCEPT_LICENSE_AGREEMENT by adding .withEnv(\"NEO4J_ACCEPT_LICENSE_AGREEMENT\", \"yes\") to your container definition. You'll find more information about licensing Neo4j here: About Neo4j Licenses .","title":"Choose your Neo4j license"},{"location":"modules/databases/neo4j/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:neo4j:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> neo4j </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Add the Neo4j Java driver if you plan to access the Testcontainers via Bolt: Gradle Maven compile \"org.neo4j.driver:neo4j-java-driver:4.4.13\" <dependency> <groupId> org.neo4j.driver </groupId> <artifactId> neo4j-java-driver </artifactId> <version> 4.4.13 </version> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/databases/oceanbase/","text":"OceanBase Module See Database containers for documentation and usage that is common to all relational database container types. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:oceanbase:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> oceanbase </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"OceanBase Module"},{"location":"modules/databases/oceanbase/#oceanbase-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"OceanBase Module"},{"location":"modules/databases/oceanbase/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:oceanbase:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> oceanbase </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/oraclefree/","text":"Oracle Database Free Module See Database containers for documentation and usage that is common to all relational database container types. Usage example You can use OracleContainer like any other JDBC container: Container creation OracleContainer oracle = new OracleContainer ( \"gvenzl/oracle-free:slim-faststart\" ) . withDatabaseName ( \"testDB\" ) . withUsername ( \"testUser\" ) . withPassword ( \"testPassword\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:oracle-free:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> oracle-free </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Oracle Database Free Module"},{"location":"modules/databases/oraclefree/#oracle-database-free-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"Oracle Database Free Module"},{"location":"modules/databases/oraclefree/#usage-example","text":"You can use OracleContainer like any other JDBC container: Container creation OracleContainer oracle = new OracleContainer ( \"gvenzl/oracle-free:slim-faststart\" ) . withDatabaseName ( \"testDB\" ) . withUsername ( \"testUser\" ) . withPassword ( \"testPassword\" )","title":"Usage example"},{"location":"modules/databases/oraclefree/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:oracle-free:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> oracle-free </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/oraclexe/","text":"Oracle-XE Module See Database containers for documentation and usage that is common to all relational database container types. Usage example You can use OracleContainer like any other JDBC container: Container creation OracleContainer oracle = new OracleContainer ( \"gvenzl/oracle-xe:21-slim-faststart\" ) . withDatabaseName ( \"testDB\" ) . withUsername ( \"testUser\" ) . withPassword ( \"testPassword\" ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:oracle-xe:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> oracle-xe </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Oracle-XE Module"},{"location":"modules/databases/oraclexe/#oracle-xe-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"Oracle-XE Module"},{"location":"modules/databases/oraclexe/#usage-example","text":"You can use OracleContainer like any other JDBC container: Container creation OracleContainer oracle = new OracleContainer ( \"gvenzl/oracle-xe:21-slim-faststart\" ) . withDatabaseName ( \"testDB\" ) . withUsername ( \"testUser\" ) . withPassword ( \"testPassword\" )","title":"Usage example"},{"location":"modules/databases/oraclexe/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:oracle-xe:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> oracle-xe </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/orientdb/","text":"OrientDB Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. This module helps running OrientDB using Testcontainers. Note that it's based on the official Docker image provided by OrientDB. Usage example Declare your Testcontainers instance as a @ClassRule or @Rule in a JUnit 4 test or as static or member attribute of a JUnit 5 test annotated with @Container as you would with other Testcontainers. You can call getDbUrl() OrientDB container and build the ODatabaseSession by your own, but a more useful getSession() method is provided. On the JVM you would most likely use the Java driver . The following example uses the JUnit 5 extension @Testcontainers and demonstrates both the usage of the Java Client: JUnit 5 example @Testcontainers public class ExampleTest { @Container private static OrientDBContainer container = new OrientDBContainer (); @Test void testDbCreation () { final ODatabaseSession session = container . getSession (); session . command ( \"CREATE CLASS Person EXTENDS V\" ); session . command ( \"INSERT INTO Person set name='john'\" ); session . command ( \"INSERT INTO Person set name='jane'\" ); assertThat ( session . query ( \"SELECT FROM Person\" ). stream ()). hasSize ( 2 ); } } You are not limited to Unit tests and can of course use an instance of the OrientDB Testcontainers implementation in vanilla Java code as well. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:orientdb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> orientdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Add the OrientDB Java client if you plan to access the Testcontainer: Gradle Maven compile \"com.orientechnologies:orientdb-client:3.0.24\" <dependency> <groupId> com.orientechnologies </groupId> <artifactId> orientdb-client </artifactId> <version> 3.0.24 </version> </dependency>","title":"OrientDB Module"},{"location":"modules/databases/orientdb/#orientdb-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. This module helps running OrientDB using Testcontainers. Note that it's based on the official Docker image provided by OrientDB.","title":"OrientDB Module"},{"location":"modules/databases/orientdb/#usage-example","text":"Declare your Testcontainers instance as a @ClassRule or @Rule in a JUnit 4 test or as static or member attribute of a JUnit 5 test annotated with @Container as you would with other Testcontainers. You can call getDbUrl() OrientDB container and build the ODatabaseSession by your own, but a more useful getSession() method is provided. On the JVM you would most likely use the Java driver . The following example uses the JUnit 5 extension @Testcontainers and demonstrates both the usage of the Java Client: JUnit 5 example @Testcontainers public class ExampleTest { @Container private static OrientDBContainer container = new OrientDBContainer (); @Test void testDbCreation () { final ODatabaseSession session = container . getSession (); session . command ( \"CREATE CLASS Person EXTENDS V\" ); session . command ( \"INSERT INTO Person set name='john'\" ); session . command ( \"INSERT INTO Person set name='jane'\" ); assertThat ( session . query ( \"SELECT FROM Person\" ). stream ()). hasSize ( 2 ); } } You are not limited to Unit tests and can of course use an instance of the OrientDB Testcontainers implementation in vanilla Java code as well.","title":"Usage example"},{"location":"modules/databases/orientdb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:orientdb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> orientdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Add the OrientDB Java client if you plan to access the Testcontainer: Gradle Maven compile \"com.orientechnologies:orientdb-client:3.0.24\" <dependency> <groupId> com.orientechnologies </groupId> <artifactId> orientdb-client </artifactId> <version> 3.0.24 </version> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/databases/postgres/","text":"Postgres Module See Database containers for documentation and usage that is common to all relational database container types. Compatible images PostgreSQLContainer can also be used with the following images: pgvector/pgvector Using pgvector PostgreSQLContainer <?> pgvector = new PostgreSQLContainer <> ( \"pgvector/pgvector:pg16\" ) postgis/postgis Using PostGIS PostgreSQLContainer <?> postgis = new PostgreSQLContainer <> ( DockerImageName . parse ( \"postgis/postgis:16-3.4-alpine\" ). asCompatibleSubstituteFor ( \"postgres\" ) ) timescale/timescaledb Using TimescaleDB PostgreSQLContainer <?> timescaledb = new PostgreSQLContainer <> ( DockerImageName . parse ( \"timescale/timescaledb:2.14.2-pg16\" ). asCompatibleSubstituteFor ( \"postgres\" ) ) Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:postgresql:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> postgresql </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Postgres Module"},{"location":"modules/databases/postgres/#postgres-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"Postgres Module"},{"location":"modules/databases/postgres/#compatible-images","text":"PostgreSQLContainer can also be used with the following images: pgvector/pgvector Using pgvector PostgreSQLContainer <?> pgvector = new PostgreSQLContainer <> ( \"pgvector/pgvector:pg16\" ) postgis/postgis Using PostGIS PostgreSQLContainer <?> postgis = new PostgreSQLContainer <> ( DockerImageName . parse ( \"postgis/postgis:16-3.4-alpine\" ). asCompatibleSubstituteFor ( \"postgres\" ) ) timescale/timescaledb Using TimescaleDB PostgreSQLContainer <?> timescaledb = new PostgreSQLContainer <> ( DockerImageName . parse ( \"timescale/timescaledb:2.14.2-pg16\" ). asCompatibleSubstituteFor ( \"postgres\" ) )","title":"Compatible images"},{"location":"modules/databases/postgres/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:postgresql:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> postgresql </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/presto/","text":"Presto Module Note This module is deprecated, use Trino module. See Database containers for documentation and usage that is common to all database container types. Usage example Running Presto as a stand-in for in a test: public class SomeTest { @Rule public PrestoContainer presto = new PrestoContainer (); @Test public void someTestMethod () { String url = presto . getJdbcUrl (); ... create a connection and run test as normal Presto comes with several catalogs preconfigured. Most useful ones for testing are tpch catalog using the Presto TPCH Connector . This is a read-only catalog that defines standard TPCH schema, so is available for querying without a need to create any tables. memory catalog using the Presto Memory Connector . This catalog can be used for creating schemas and tables and does not require any storage, as everything is stored fully in-memory. Example test using the tpch and memory catalogs: public class SomeTest { @Rule public PrestoContainer prestoSql = new PrestoContainer (); @Test public void queryMemoryAndTpchConnectors () throws SQLException { try ( Connection connection = prestoSql . createConnection (); Statement statement = connection . createStatement ()) { // Prepare data statement . execute ( \"CREATE TABLE memory.default.table_with_array AS SELECT 1 id, ARRAY[1, 42, 2, 42, 4, 42] my_array\" ); // Query Presto using newly created table and a builtin connector try ( ResultSet resultSet = statement . executeQuery ( \"\" + \"SELECT nationkey, element \" + \"FROM tpch.tiny.nation \" + \"JOIN memory.default.table_with_array twa ON nationkey = twa.id \" + \"LEFT JOIN UNNEST(my_array) a(element) ON true \" + \"ORDER BY element OFFSET 1 FETCH NEXT 3 ROWS WITH TIES \" )) { List < Integer > actualElements = new ArrayList <> (); while ( resultSet . next ()) { actualElements . add ( resultSet . getInt ( \"element\" )); } Assert . assertEquals ( Arrays . asList ( 2 , 4 , 42 , 42 , 42 ), actualElements ); } } } } Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:presto:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> presto </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add the Presto JDBC driver JAR to your project. You should ensure that your project has the Presto JDBC driver as a dependency, if you plan on using it. Refer to Presto project download page for instructions.","title":"Presto Module"},{"location":"modules/databases/presto/#presto-module","text":"Note This module is deprecated, use Trino module. See Database containers for documentation and usage that is common to all database container types.","title":"Presto Module"},{"location":"modules/databases/presto/#usage-example","text":"Running Presto as a stand-in for in a test: public class SomeTest { @Rule public PrestoContainer presto = new PrestoContainer (); @Test public void someTestMethod () { String url = presto . getJdbcUrl (); ... create a connection and run test as normal Presto comes with several catalogs preconfigured. Most useful ones for testing are tpch catalog using the Presto TPCH Connector . This is a read-only catalog that defines standard TPCH schema, so is available for querying without a need to create any tables. memory catalog using the Presto Memory Connector . This catalog can be used for creating schemas and tables and does not require any storage, as everything is stored fully in-memory. Example test using the tpch and memory catalogs: public class SomeTest { @Rule public PrestoContainer prestoSql = new PrestoContainer (); @Test public void queryMemoryAndTpchConnectors () throws SQLException { try ( Connection connection = prestoSql . createConnection (); Statement statement = connection . createStatement ()) { // Prepare data statement . execute ( \"CREATE TABLE memory.default.table_with_array AS SELECT 1 id, ARRAY[1, 42, 2, 42, 4, 42] my_array\" ); // Query Presto using newly created table and a builtin connector try ( ResultSet resultSet = statement . executeQuery ( \"\" + \"SELECT nationkey, element \" + \"FROM tpch.tiny.nation \" + \"JOIN memory.default.table_with_array twa ON nationkey = twa.id \" + \"LEFT JOIN UNNEST(my_array) a(element) ON true \" + \"ORDER BY element OFFSET 1 FETCH NEXT 3 ROWS WITH TIES \" )) { List < Integer > actualElements = new ArrayList <> (); while ( resultSet . next ()) { actualElements . add ( resultSet . getInt ( \"element\" )); } Assert . assertEquals ( Arrays . asList ( 2 , 4 , 42 , 42 , 42 ), actualElements ); } } } }","title":"Usage example"},{"location":"modules/databases/presto/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:presto:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> presto </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add the Presto JDBC driver JAR to your project. You should ensure that your project has the Presto JDBC driver as a dependency, if you plan on using it. Refer to Presto project download page for instructions.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/questdb/","text":"QuestDB Module Testcontainers module for QuestDB . QuestDB is a high-performance, open-source SQL database for applications in financial services, IoT, machine learning, DevOps and observability. See Database containers for documentation and usage that is common to all relational database container types. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:questdb:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> questdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"QuestDB Module"},{"location":"modules/databases/questdb/#questdb-module","text":"Testcontainers module for QuestDB . QuestDB is a high-performance, open-source SQL database for applications in financial services, IoT, machine learning, DevOps and observability. See Database containers for documentation and usage that is common to all relational database container types.","title":"QuestDB Module"},{"location":"modules/databases/questdb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle testImplementation \"org.testcontainers:questdb:1.20.6\" Maven <dependency> <groupId> org.testcontainers </groupId> <artifactId> questdb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/databases/r2dbc/","text":"R2DBC support You can obtain a temporary database in one of two ways: Using a specially modified R2DBC URL : after making a very simple modification to your system's R2DBC URL string, Testcontainers will provide a disposable stand-in database that can be used without requiring modification to your application code. JUnit @Rule/@ClassRule : this mode starts a database inside a container before your tests and tears it down afterwards. Database containers launched via R2DBC URL scheme As long as you have Testcontainers and the appropriate R2DBC driver on your classpath, you can simply modify regular R2DBC connection URLs to get a fresh containerized instance of the database each time your application starts up. The started container will be terminated when the ConnectionFactory is closed. Warning Both the database module (e.g. org.testcontainers:mysql ) and org.testcontainers:r2dbc need to be on your application's classpath at runtime. Original URL : r2dbc:mysql://localhost:3306/databasename Insert tc: after r2dbc: as follows. Note that the hostname, port and database name will be ignored; you can leave these as-is or set them to any value. Specify the mandatory Docker tag of the database's official image that you want using a TC_IMAGE_TAG query parameter. Note that, unlike Testcontainers' JDBC URL support, it is not possible to specify an image tag in the 'scheme' part of the URL, and it is always necessary to specify a tag using TC_IMAGE_TAG . So that the URL becomes: r2dbc:tc:mysql:///databasename?TC_IMAGE_TAG=8.0.36 Note We will use /// (host-less URIs) from now on to emphasis the unimportance of the host:port pair. From Testcontainers' perspective, r2dbc:mysql://localhost:3306/databasename and r2dbc:mysql:///databasename is the same URI. Warning If you're using the R2DBC URL support, there is no need to instantiate an instance of the container - Testcontainers will do it automagically. R2DBC URL examples Using ClickHouse r2dbc:tc:clickhouse:///databasename?TC_IMAGE_TAG=21.9.2-alpine Using MySQL r2dbc:tc:mysql:///databasename?TC_IMAGE_TAG=8.0.36 Using MariaDB r2dbc:tc:mariadb:///databasename?TC_IMAGE_TAG=10.3.39 Using PostgreSQL r2dbc:tc:postgresql:///databasename?TC_IMAGE_TAG=9.6.8 Using MSSQL: r2dbc:tc:sqlserver:///?TC_IMAGE_TAG=2017-CU12 Using Oracle: r2dbc:tc:oracle:///?TC_IMAGE_TAG=21-slim-faststart Obtaining ConnectionFactoryOptions from database container objects If you already have an instance of the database container, you can get an instance of ConnectionFactoryOptions from it: Creating ConnectionFactoryOptions from an instance) ConnectionFactoryOptions options = PostgreSQLR2DBCDatabaseContainer . getOptions ( container );","title":"R2DBC support"},{"location":"modules/databases/r2dbc/#r2dbc-support","text":"You can obtain a temporary database in one of two ways: Using a specially modified R2DBC URL : after making a very simple modification to your system's R2DBC URL string, Testcontainers will provide a disposable stand-in database that can be used without requiring modification to your application code. JUnit @Rule/@ClassRule : this mode starts a database inside a container before your tests and tears it down afterwards.","title":"R2DBC support"},{"location":"modules/databases/r2dbc/#database-containers-launched-via-r2dbc-url-scheme","text":"As long as you have Testcontainers and the appropriate R2DBC driver on your classpath, you can simply modify regular R2DBC connection URLs to get a fresh containerized instance of the database each time your application starts up. The started container will be terminated when the ConnectionFactory is closed. Warning Both the database module (e.g. org.testcontainers:mysql ) and org.testcontainers:r2dbc need to be on your application's classpath at runtime. Original URL : r2dbc:mysql://localhost:3306/databasename Insert tc: after r2dbc: as follows. Note that the hostname, port and database name will be ignored; you can leave these as-is or set them to any value. Specify the mandatory Docker tag of the database's official image that you want using a TC_IMAGE_TAG query parameter. Note that, unlike Testcontainers' JDBC URL support, it is not possible to specify an image tag in the 'scheme' part of the URL, and it is always necessary to specify a tag using TC_IMAGE_TAG . So that the URL becomes: r2dbc:tc:mysql:///databasename?TC_IMAGE_TAG=8.0.36 Note We will use /// (host-less URIs) from now on to emphasis the unimportance of the host:port pair. From Testcontainers' perspective, r2dbc:mysql://localhost:3306/databasename and r2dbc:mysql:///databasename is the same URI. Warning If you're using the R2DBC URL support, there is no need to instantiate an instance of the container - Testcontainers will do it automagically.","title":"Database containers launched via R2DBC URL scheme"},{"location":"modules/databases/r2dbc/#r2dbc-url-examples","text":"","title":"R2DBC URL examples"},{"location":"modules/databases/r2dbc/#using-clickhouse","text":"r2dbc:tc:clickhouse:///databasename?TC_IMAGE_TAG=21.9.2-alpine","title":"Using ClickHouse"},{"location":"modules/databases/r2dbc/#using-mysql","text":"r2dbc:tc:mysql:///databasename?TC_IMAGE_TAG=8.0.36","title":"Using MySQL"},{"location":"modules/databases/r2dbc/#using-mariadb","text":"r2dbc:tc:mariadb:///databasename?TC_IMAGE_TAG=10.3.39","title":"Using MariaDB"},{"location":"modules/databases/r2dbc/#using-postgresql","text":"r2dbc:tc:postgresql:///databasename?TC_IMAGE_TAG=9.6.8","title":"Using PostgreSQL"},{"location":"modules/databases/r2dbc/#using-mssql","text":"r2dbc:tc:sqlserver:///?TC_IMAGE_TAG=2017-CU12","title":"Using MSSQL:"},{"location":"modules/databases/r2dbc/#using-oracle","text":"r2dbc:tc:oracle:///?TC_IMAGE_TAG=21-slim-faststart","title":"Using Oracle:"},{"location":"modules/databases/r2dbc/#obtaining-connectionfactoryoptions-from-database-container-objects","text":"If you already have an instance of the database container, you can get an instance of ConnectionFactoryOptions from it: Creating ConnectionFactoryOptions from an instance) ConnectionFactoryOptions options = PostgreSQLR2DBCDatabaseContainer . getOptions ( container );","title":"Obtaining ConnectionFactoryOptions from database container objects"},{"location":"modules/databases/scylladb/","text":"ScyllaDB Testcontainers module for ScyllaDB ScyllaDB's usage examples You can start a ScyllaDB container instance from any Java application by using: Create container ScyllaDBContainer scylladb = new ScyllaDBContainer ( \"scylladb/scylla:6.2\" ) Custom config file ScyllaDBContainer scylladb = new ScyllaDBContainer ( \"scylladb/scylla:6.2\" ) . withConfigurationOverride ( \"scylla-test-ssl\" ) . withSsl ( MountableFile . forClasspathResource ( \"keys/scylla.cer.pem\" ), MountableFile . forClasspathResource ( \"keys/scylla.key.pem\" ), MountableFile . forClasspathResource ( \"keys/scylla.truststore\" ) ) Building CqlSession Using CQL port CqlSession session = CqlSession . builder () . addContactPoint ( scylladb . getContactPoint ()) . withLocalDatacenter ( \"datacenter1\" ) . build (); Using SSL String testResourcesDir = getClass (). getClassLoader (). getResource ( \"keys/\" ). getPath (); KeyStore keyStore = KeyStore . getInstance ( \"PKCS12\" ); keyStore . load ( Files . newInputStream ( Paths . get ( testResourcesDir + \"scylla.keystore\" )), \"scylla\" . toCharArray () ); KeyStore trustStore = KeyStore . getInstance ( \"PKCS12\" ); trustStore . load ( Files . newInputStream ( Paths . get ( testResourcesDir + \"scylla.truststore\" )), \"scylla\" . toCharArray () ); KeyManagerFactory keyManagerFactory = KeyManagerFactory . getInstance ( KeyManagerFactory . getDefaultAlgorithm () ); keyManagerFactory . init ( keyStore , \"scylla\" . toCharArray ()); TrustManagerFactory trustManagerFactory = TrustManagerFactory . getInstance ( TrustManagerFactory . getDefaultAlgorithm () ); trustManagerFactory . init ( trustStore ); SSLContext sslContext = SSLContext . getInstance ( \"TLS\" ); sslContext . init ( keyManagerFactory . getKeyManagers (), trustManagerFactory . getTrustManagers (), null ); Using Shard Awareness port CqlSession session = CqlSession . builder () . addContactPoint ( scylladb . getShardAwareContactPoint ()) . withLocalDatacenter ( \"datacenter1\" ) . build (); Alternator Enabling Alternator ScyllaDBContainer scylladb = new ScyllaDBContainer ( SCYLLADB_IMAGE ). withAlternator () DynamoDbClient with Alternator DynamoDbClient client = DynamoDbClient . builder () . endpointOverride ( URI . create ( scylladb . getAlternatorEndpoint ())) . credentialsProvider ( StaticCredentialsProvider . create ( AwsBasicCredentials . create ( \"test\" , \"test\" ))) . region ( Region . US_EAST_1 ) . build (); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:scylladb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> scylladb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"ScyllaDB"},{"location":"modules/databases/scylladb/#scylladb","text":"Testcontainers module for ScyllaDB","title":"ScyllaDB"},{"location":"modules/databases/scylladb/#scylladbs-usage-examples","text":"You can start a ScyllaDB container instance from any Java application by using: Create container ScyllaDBContainer scylladb = new ScyllaDBContainer ( \"scylladb/scylla:6.2\" ) Custom config file ScyllaDBContainer scylladb = new ScyllaDBContainer ( \"scylladb/scylla:6.2\" ) . withConfigurationOverride ( \"scylla-test-ssl\" ) . withSsl ( MountableFile . forClasspathResource ( \"keys/scylla.cer.pem\" ), MountableFile . forClasspathResource ( \"keys/scylla.key.pem\" ), MountableFile . forClasspathResource ( \"keys/scylla.truststore\" ) )","title":"ScyllaDB's usage examples"},{"location":"modules/databases/scylladb/#building-cqlsession","text":"Using CQL port CqlSession session = CqlSession . builder () . addContactPoint ( scylladb . getContactPoint ()) . withLocalDatacenter ( \"datacenter1\" ) . build (); Using SSL String testResourcesDir = getClass (). getClassLoader (). getResource ( \"keys/\" ). getPath (); KeyStore keyStore = KeyStore . getInstance ( \"PKCS12\" ); keyStore . load ( Files . newInputStream ( Paths . get ( testResourcesDir + \"scylla.keystore\" )), \"scylla\" . toCharArray () ); KeyStore trustStore = KeyStore . getInstance ( \"PKCS12\" ); trustStore . load ( Files . newInputStream ( Paths . get ( testResourcesDir + \"scylla.truststore\" )), \"scylla\" . toCharArray () ); KeyManagerFactory keyManagerFactory = KeyManagerFactory . getInstance ( KeyManagerFactory . getDefaultAlgorithm () ); keyManagerFactory . init ( keyStore , \"scylla\" . toCharArray ()); TrustManagerFactory trustManagerFactory = TrustManagerFactory . getInstance ( TrustManagerFactory . getDefaultAlgorithm () ); trustManagerFactory . init ( trustStore ); SSLContext sslContext = SSLContext . getInstance ( \"TLS\" ); sslContext . init ( keyManagerFactory . getKeyManagers (), trustManagerFactory . getTrustManagers (), null ); Using Shard Awareness port CqlSession session = CqlSession . builder () . addContactPoint ( scylladb . getShardAwareContactPoint ()) . withLocalDatacenter ( \"datacenter1\" ) . build ();","title":"Building CqlSession"},{"location":"modules/databases/scylladb/#alternator","text":"Enabling Alternator ScyllaDBContainer scylladb = new ScyllaDBContainer ( SCYLLADB_IMAGE ). withAlternator () DynamoDbClient with Alternator DynamoDbClient client = DynamoDbClient . builder () . endpointOverride ( URI . create ( scylladb . getAlternatorEndpoint ())) . credentialsProvider ( StaticCredentialsProvider . create ( AwsBasicCredentials . create ( \"test\" , \"test\" ))) . region ( Region . US_EAST_1 ) . build ();","title":"Alternator"},{"location":"modules/databases/scylladb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:scylladb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> scylladb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding this module to your project dependencies"},{"location":"modules/databases/tidb/","text":"TiDB Module See Database containers for documentation and usage that is common to all relational database container types. Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:tidb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> tidb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"TiDB Module"},{"location":"modules/databases/tidb/#tidb-module","text":"See Database containers for documentation and usage that is common to all relational database container types.","title":"TiDB Module"},{"location":"modules/databases/tidb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:tidb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> tidb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/timeplus/","text":"Timeplus Module Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:timeplus:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> timeplus </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Timeplus Module"},{"location":"modules/databases/timeplus/#timeplus-module","text":"","title":"Timeplus Module"},{"location":"modules/databases/timeplus/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:timeplus:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> timeplus </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add a database driver JAR to your project. You should ensure that your project also has a suitable database driver as a dependency.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/trino/","text":"Trino Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. See Database containers for documentation and usage that is common to all database container types. Usage example Running Trino as a stand-in for in a test: public class SomeTest { @Rule public TrinoContainer trino = new TrinoContainer (); @Test public void someTestMethod () { String url = trino . getJdbcUrl (); ... create a connection and run test as normal Trino comes with several catalogs preconfigured. Most useful ones for testing are tpch catalog using the Trino TPCH Connector . This is a read-only catalog that defines standard TPCH schema, so is available for querying without a need to create any tables. memory catalog using the Trino Memory Connector . This catalog can be used for creating schemas and tables and does not require any storage, as everything is stored fully in-memory. Example test using the tpch and memory catalogs: public class SomeTest { @Rule public TrinoContainer trino = new TrinoContainer (); @Test public void queryMemoryAndTpchConnectors () throws SQLException { try ( Connection connection = trino . createConnection (); Statement statement = connection . createStatement ()) { // Prepare data statement . execute ( \"CREATE TABLE memory.default.table_with_array AS SELECT 1 id, ARRAY[1, 42, 2, 42, 4, 42] my_array\" ); // Query Trino using newly created table and a builtin connector try ( ResultSet resultSet = statement . executeQuery ( \"\" + \"SELECT nationkey, element \" + \"FROM tpch.tiny.nation \" + \"JOIN memory.default.table_with_array twa ON nationkey = twa.id \" + \"LEFT JOIN UNNEST(my_array) a(element) ON true \" + \"ORDER BY element OFFSET 1 FETCH NEXT 3 ROWS WITH TIES \" )) { List < Integer > actualElements = new ArrayList <> (); while ( resultSet . next ()) { actualElements . add ( resultSet . getInt ( \"element\" )); } Assert . assertEquals ( Arrays . asList ( 2 , 4 , 42 , 42 , 42 ), actualElements ); } } } } Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:trino:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> trino </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add the Trino JDBC driver JAR to your project. You should ensure that your project has the Trino JDBC driver as a dependency, if you plan on using it. Refer to Trino project download page for instructions.","title":"Trino Module"},{"location":"modules/databases/trino/#trino-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. See Database containers for documentation and usage that is common to all database container types.","title":"Trino Module"},{"location":"modules/databases/trino/#usage-example","text":"Running Trino as a stand-in for in a test: public class SomeTest { @Rule public TrinoContainer trino = new TrinoContainer (); @Test public void someTestMethod () { String url = trino . getJdbcUrl (); ... create a connection and run test as normal Trino comes with several catalogs preconfigured. Most useful ones for testing are tpch catalog using the Trino TPCH Connector . This is a read-only catalog that defines standard TPCH schema, so is available for querying without a need to create any tables. memory catalog using the Trino Memory Connector . This catalog can be used for creating schemas and tables and does not require any storage, as everything is stored fully in-memory. Example test using the tpch and memory catalogs: public class SomeTest { @Rule public TrinoContainer trino = new TrinoContainer (); @Test public void queryMemoryAndTpchConnectors () throws SQLException { try ( Connection connection = trino . createConnection (); Statement statement = connection . createStatement ()) { // Prepare data statement . execute ( \"CREATE TABLE memory.default.table_with_array AS SELECT 1 id, ARRAY[1, 42, 2, 42, 4, 42] my_array\" ); // Query Trino using newly created table and a builtin connector try ( ResultSet resultSet = statement . executeQuery ( \"\" + \"SELECT nationkey, element \" + \"FROM tpch.tiny.nation \" + \"JOIN memory.default.table_with_array twa ON nationkey = twa.id \" + \"LEFT JOIN UNNEST(my_array) a(element) ON true \" + \"ORDER BY element OFFSET 1 FETCH NEXT 3 ROWS WITH TIES \" )) { List < Integer > actualElements = new ArrayList <> (); while ( resultSet . next ()) { actualElements . add ( resultSet . getInt ( \"element\" )); } Assert . assertEquals ( Arrays . asList ( 2 , 4 , 42 , 42 , 42 ), actualElements ); } } } }","title":"Usage example"},{"location":"modules/databases/trino/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:trino:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> trino </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add the Trino JDBC driver JAR to your project. You should ensure that your project has the Trino JDBC driver as a dependency, if you plan on using it. Refer to Trino project download page for instructions.","title":"Adding this module to your project dependencies"},{"location":"modules/databases/yugabytedb/","text":"YugabyteDB Module Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. See Database containers for documentation and usage that is common to all database container types. YugabyteDB supports two APIs. - Yugabyte Structured Query Language YSQL is a fully-relational API that is built by the PostgreSQL code - Yugabyte Cloud Query Language YCQL is a semi-relational SQL API that has its roots in the Cassandra Query Language Usage example YSQL API Creating a YSQL container final YugabyteDBYSQLContainer ysqlContainer = new YugabyteDBYSQLContainer ( \"yugabytedb/yugabyte:2.14.4.0-b26\" ) Starting a YSQL container ysqlContainer . start (); YCQL API Creating a YCQL container final YugabyteDBYCQLContainer ycqlContainer = new YugabyteDBYCQLContainer ( \"yugabytedb/yugabyte:2.14.4.0-b26\" ) . withUsername ( \"cassandra\" ) . withPassword ( \"cassandra\" ) Starting a YCQL container ycqlContainer . start (); Adding this module to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:yugabytedb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> yugabytedb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add the Yugabytedb driver JAR to your project. You should ensure that your project has the Yugabytedb driver as a dependency, if you plan on using it. Refer to the driver page YSQL and YCQL for instructions.","title":"YugabyteDB Module"},{"location":"modules/databases/yugabytedb/#yugabytedb-module","text":"Note This module is INCUBATING. While it is ready for use and operational in the current version of Testcontainers, it is possible that it may receive breaking changes in the future. See our contributing guidelines for more information on our incubating modules policy. See Database containers for documentation and usage that is common to all database container types. YugabyteDB supports two APIs. - Yugabyte Structured Query Language YSQL is a fully-relational API that is built by the PostgreSQL code - Yugabyte Cloud Query Language YCQL is a semi-relational SQL API that has its roots in the Cassandra Query Language","title":"YugabyteDB Module"},{"location":"modules/databases/yugabytedb/#usage-example","text":"","title":"Usage example"},{"location":"modules/databases/yugabytedb/#ysql-api","text":"Creating a YSQL container final YugabyteDBYSQLContainer ysqlContainer = new YugabyteDBYSQLContainer ( \"yugabytedb/yugabyte:2.14.4.0-b26\" ) Starting a YSQL container ysqlContainer . start ();","title":"YSQL API"},{"location":"modules/databases/yugabytedb/#ycql-api","text":"Creating a YCQL container final YugabyteDBYCQLContainer ycqlContainer = new YugabyteDBYCQLContainer ( \"yugabytedb/yugabyte:2.14.4.0-b26\" ) . withUsername ( \"cassandra\" ) . withPassword ( \"cassandra\" ) Starting a YCQL container ycqlContainer . start ();","title":"YCQL API"},{"location":"modules/databases/yugabytedb/#adding-this-module-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:yugabytedb:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> yugabytedb </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Hint Adding this Testcontainers library JAR will not automatically add the Yugabytedb driver JAR to your project. You should ensure that your project has the Yugabytedb driver as a dependency, if you plan on using it. Refer to the driver page YSQL and YCQL for instructions.","title":"Adding this module to your project dependencies"},{"location":"quickstart/junit_4_quickstart/","text":"JUnit 4 Quickstart It's easy to add Testcontainers to your project - let's walk through a quick example to see how. Let's imagine we have a simple program that has a dependency on Redis, and we want to add some tests for it. In our imaginary program, there is a RedisBackedCache class which stores data in Redis. You can see an example test that could have been written for it (without using Testcontainers): Pre-Testcontainers test code public class RedisBackedCacheIntTestStep0 { private RedisBackedCache underTest ; @Before public void setUp () { // Assume that we have Redis running locally? underTest = new RedisBackedCache ( \"localhost\" , 6379 ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } } Notice that the existing test has a problem - it's relying on a local installation of Redis, which is a red flag for test reliability. This may work if we were sure that every developer and CI machine had Redis installed, but would fail otherwise. We might also have problems if we attempted to run tests in parallel, such as state bleeding between tests, or port clashes. Let's start from here, and see how to improve the test with Testcontainers: 1. Add Testcontainers as a test-scoped dependency First, add Testcontainers as a dependency as follows: Gradle Maven testImplementation \"org.testcontainers:testcontainers:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> 2. Get Testcontainers to run a Redis container during our tests Simply add the following to the body of our test class: JUnit 4 Rule @Rule public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); The @Rule annotation tells JUnit to notify this field about various events in the test lifecycle. In this case, our rule object is a Testcontainers GenericContainer , configured to use a specific Redis image from Docker Hub, and configured to expose a port. If we run our test as-is, then regardless of the actual test outcome, we'll see logs showing us that Testcontainers: was activated before our test method ran discovered and quickly tested our local Docker setup pulled the image if necessary started a new container and waited for it to be ready shut down and deleted the container after the test 3. Make sure our code can talk to the container Before Testcontainers, we might have hardcoded an address like localhost:6379 into our tests. Testcontainers uses randomized ports for each container it starts, but makes it easy to obtain the actual port at runtime. We can do this in our test setUp method, to set up our component under test: Obtaining a mapped port String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); Tip Notice that we also ask Testcontainers for the container's actual address with redis.getHost(); , rather than hard-coding localhost . localhost may work in some environments but not others - for example it may not work on your current or future CI environment. As such, avoid hard-coding the address, and use getHost() instead. 4. Run the tests! That's it! Let's look at our complete test class to see how little we had to add to get up and running with Testcontainers: RedisBackedCacheIntTest public class RedisBackedCacheIntTest { private RedisBackedCache underTest ; // rule { @Rule public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); // } @Before public void setUp () { String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } }","title":"JUnit 4 Quickstart"},{"location":"quickstart/junit_4_quickstart/#junit-4-quickstart","text":"It's easy to add Testcontainers to your project - let's walk through a quick example to see how. Let's imagine we have a simple program that has a dependency on Redis, and we want to add some tests for it. In our imaginary program, there is a RedisBackedCache class which stores data in Redis. You can see an example test that could have been written for it (without using Testcontainers): Pre-Testcontainers test code public class RedisBackedCacheIntTestStep0 { private RedisBackedCache underTest ; @Before public void setUp () { // Assume that we have Redis running locally? underTest = new RedisBackedCache ( \"localhost\" , 6379 ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } } Notice that the existing test has a problem - it's relying on a local installation of Redis, which is a red flag for test reliability. This may work if we were sure that every developer and CI machine had Redis installed, but would fail otherwise. We might also have problems if we attempted to run tests in parallel, such as state bleeding between tests, or port clashes. Let's start from here, and see how to improve the test with Testcontainers:","title":"JUnit 4 Quickstart"},{"location":"quickstart/junit_4_quickstart/#1-add-testcontainers-as-a-test-scoped-dependency","text":"First, add Testcontainers as a dependency as follows: Gradle Maven testImplementation \"org.testcontainers:testcontainers:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"1. Add Testcontainers as a test-scoped dependency"},{"location":"quickstart/junit_4_quickstart/#2-get-testcontainers-to-run-a-redis-container-during-our-tests","text":"Simply add the following to the body of our test class: JUnit 4 Rule @Rule public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); The @Rule annotation tells JUnit to notify this field about various events in the test lifecycle. In this case, our rule object is a Testcontainers GenericContainer , configured to use a specific Redis image from Docker Hub, and configured to expose a port. If we run our test as-is, then regardless of the actual test outcome, we'll see logs showing us that Testcontainers: was activated before our test method ran discovered and quickly tested our local Docker setup pulled the image if necessary started a new container and waited for it to be ready shut down and deleted the container after the test","title":"2. Get Testcontainers to run a Redis container during our tests"},{"location":"quickstart/junit_4_quickstart/#3-make-sure-our-code-can-talk-to-the-container","text":"Before Testcontainers, we might have hardcoded an address like localhost:6379 into our tests. Testcontainers uses randomized ports for each container it starts, but makes it easy to obtain the actual port at runtime. We can do this in our test setUp method, to set up our component under test: Obtaining a mapped port String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); Tip Notice that we also ask Testcontainers for the container's actual address with redis.getHost(); , rather than hard-coding localhost . localhost may work in some environments but not others - for example it may not work on your current or future CI environment. As such, avoid hard-coding the address, and use getHost() instead.","title":"3. Make sure our code can talk to the container"},{"location":"quickstart/junit_4_quickstart/#4-run-the-tests","text":"That's it! Let's look at our complete test class to see how little we had to add to get up and running with Testcontainers: RedisBackedCacheIntTest public class RedisBackedCacheIntTest { private RedisBackedCache underTest ; // rule { @Rule public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); // } @Before public void setUp () { String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } }","title":"4. Run the tests!"},{"location":"quickstart/junit_5_quickstart/","text":"JUnit 5 Quickstart It's easy to add Testcontainers to your project - let's walk through a quick example to see how. Let's imagine we have a simple program that has a dependency on Redis, and we want to add some tests for it. In our imaginary program, there is a RedisBackedCache class which stores data in Redis. You can see an example test that could have been written for it (without using Testcontainers): Pre-Testcontainers test code public class RedisBackedCacheIntTestStep0 { private RedisBackedCache underTest ; @BeforeEach public void setUp () { // Assume that we have Redis running locally? underTest = new RedisBackedCache ( \"localhost\" , 6379 ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } } Notice that the existing test has a problem - it's relying on a local installation of Redis, which is a red flag for test reliability. This may work if we were sure that every developer and CI machine had Redis installed, but would fail otherwise. We might also have problems if we attempted to run tests in parallel, such as state bleeding between tests, or port clashes. Let's start from here, and see how to improve the test with Testcontainers: 1. Add Testcontainers as a test-scoped dependency First, add Testcontainers as a dependency as follows: Gradle Maven testImplementation \"org.junit.jupiter:junit-jupiter:5.8.1\" testImplementation \"org.testcontainers:testcontainers:1.20.6\" testImplementation \"org.testcontainers:junit-jupiter:1.20.6\" <dependency> <groupId> org.junit.jupiter </groupId> <artifactId> junit-jupiter </artifactId> <version> 5.8.1 </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> junit-jupiter </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> 2. Get Testcontainers to run a Redis container during our tests First, you'll need to annotate the test class with @Testcontainers . Furthermore, add the following to the body of our test class: JUnit 5 Rule @Container public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); The @Container annotation tells JUnit to notify this field about various events in the test lifecycle. In this case, our rule object is a Testcontainers GenericContainer , configured to use a specific Redis image from Docker Hub, and configured to expose a port. If we run our test as-is, then regardless of the actual test outcome, we'll see logs showing us that Testcontainers: was activated before our test method ran discovered and quickly tested our local Docker setup pulled the image if necessary started a new container and waited for it to be ready shut down and deleted the container after the test 3. Make sure our code can talk to the container Before Testcontainers, we might have hardcoded an address like localhost:6379 into our tests. Testcontainers uses randomized ports for each container it starts, but makes it easy to obtain the actual port at runtime. We can do this in our test setUp method, to set up our component under test: Obtaining a mapped port String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); Tip Notice that we also ask Testcontainers for the container's actual address with redis.getHost(); , rather than hard-coding localhost . localhost may work in some environments but not others - for example it may not work on your current or future CI environment. As such, avoid hard-coding the address, and use getHost() instead. 4. Additional attributes Additional attributes are available for the @Testcontainers annotation. Those attributes can be helpful when: Tests should be skipped instead of failing because Docker is unavailable in the current environment. Set disabledWithoutDocker to true . Enable parallel container initialization instead of sequential (by default). Set parallel to true . 5. Run the tests! That's it! Let's look at our complete test class to see how little we had to add to get up and running with Testcontainers: RedisBackedCacheIntTest @Testcontainers public class RedisBackedCacheIntTest { private RedisBackedCache underTest ; // container { @Container public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); // } @BeforeEach public void setUp () { String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } }","title":"JUnit 5 Quickstart"},{"location":"quickstart/junit_5_quickstart/#junit-5-quickstart","text":"It's easy to add Testcontainers to your project - let's walk through a quick example to see how. Let's imagine we have a simple program that has a dependency on Redis, and we want to add some tests for it. In our imaginary program, there is a RedisBackedCache class which stores data in Redis. You can see an example test that could have been written for it (without using Testcontainers): Pre-Testcontainers test code public class RedisBackedCacheIntTestStep0 { private RedisBackedCache underTest ; @BeforeEach public void setUp () { // Assume that we have Redis running locally? underTest = new RedisBackedCache ( \"localhost\" , 6379 ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } } Notice that the existing test has a problem - it's relying on a local installation of Redis, which is a red flag for test reliability. This may work if we were sure that every developer and CI machine had Redis installed, but would fail otherwise. We might also have problems if we attempted to run tests in parallel, such as state bleeding between tests, or port clashes. Let's start from here, and see how to improve the test with Testcontainers:","title":"JUnit 5 Quickstart"},{"location":"quickstart/junit_5_quickstart/#1-add-testcontainers-as-a-test-scoped-dependency","text":"First, add Testcontainers as a dependency as follows: Gradle Maven testImplementation \"org.junit.jupiter:junit-jupiter:5.8.1\" testImplementation \"org.testcontainers:testcontainers:1.20.6\" testImplementation \"org.testcontainers:junit-jupiter:1.20.6\" <dependency> <groupId> org.junit.jupiter </groupId> <artifactId> junit-jupiter </artifactId> <version> 5.8.1 </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> testcontainers </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> <dependency> <groupId> org.testcontainers </groupId> <artifactId> junit-jupiter </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"1. Add Testcontainers as a test-scoped dependency"},{"location":"quickstart/junit_5_quickstart/#2-get-testcontainers-to-run-a-redis-container-during-our-tests","text":"First, you'll need to annotate the test class with @Testcontainers . Furthermore, add the following to the body of our test class: JUnit 5 Rule @Container public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); The @Container annotation tells JUnit to notify this field about various events in the test lifecycle. In this case, our rule object is a Testcontainers GenericContainer , configured to use a specific Redis image from Docker Hub, and configured to expose a port. If we run our test as-is, then regardless of the actual test outcome, we'll see logs showing us that Testcontainers: was activated before our test method ran discovered and quickly tested our local Docker setup pulled the image if necessary started a new container and waited for it to be ready shut down and deleted the container after the test","title":"2. Get Testcontainers to run a Redis container during our tests"},{"location":"quickstart/junit_5_quickstart/#3-make-sure-our-code-can-talk-to-the-container","text":"Before Testcontainers, we might have hardcoded an address like localhost:6379 into our tests. Testcontainers uses randomized ports for each container it starts, but makes it easy to obtain the actual port at runtime. We can do this in our test setUp method, to set up our component under test: Obtaining a mapped port String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); Tip Notice that we also ask Testcontainers for the container's actual address with redis.getHost(); , rather than hard-coding localhost . localhost may work in some environments but not others - for example it may not work on your current or future CI environment. As such, avoid hard-coding the address, and use getHost() instead.","title":"3. Make sure our code can talk to the container"},{"location":"quickstart/junit_5_quickstart/#4-additional-attributes","text":"Additional attributes are available for the @Testcontainers annotation. Those attributes can be helpful when: Tests should be skipped instead of failing because Docker is unavailable in the current environment. Set disabledWithoutDocker to true . Enable parallel container initialization instead of sequential (by default). Set parallel to true .","title":"4. Additional attributes"},{"location":"quickstart/junit_5_quickstart/#5-run-the-tests","text":"That's it! Let's look at our complete test class to see how little we had to add to get up and running with Testcontainers: RedisBackedCacheIntTest @Testcontainers public class RedisBackedCacheIntTest { private RedisBackedCache underTest ; // container { @Container public GenericContainer redis = new GenericContainer ( DockerImageName . parse ( \"redis:6-alpine\" )) . withExposedPorts ( 6379 ); // } @BeforeEach public void setUp () { String address = redis . getHost (); Integer port = redis . getFirstMappedPort (); // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ); } @Test public void testSimplePutAndGet () { underTest . put ( \"test\" , \"example\" ); String retrieved = underTest . get ( \"test\" ); assertThat ( retrieved ). isEqualTo ( \"example\" ); } }","title":"5. Run the tests!"},{"location":"quickstart/spock_quickstart/","text":"Spock Quickstart It's easy to add Testcontainers to your project - let's walk through a quick example to see how. Let's imagine we have a simple program that has a dependency on Redis, and we want to add some tests for it. In our imaginary program, there is a RedisBackedCache class which stores data in Redis. You can see an example test that could have been written for it (without using Testcontainers): Pre-Testcontainers test code class RedisBackedCacheIntTestStep0 extends Specification { private RedisBackedCache underTest void setup () { // Assume that we have Redis running locally? underTest = new RedisBackedCache ( \"localhost\" , 6379 ) } void testSimplePutAndGet () { setup: underTest . put ( \"test\" , \"example\" ) when: String retrieved = underTest . get ( \"test\" ) then: retrieved == \"example\" } } Notice that the existing test has a problem - it's relying on a local installation of Redis, which is a red flag for test reliability. This may work if we were sure that every developer and CI machine had Redis installed, but would fail otherwise. We might also have problems if we attempted to run tests in parallel, such as state bleeding between tests, or port clashes. Let's start from here, and see how to improve the test with Testcontainers: 1. Add Testcontainers as a test-scoped dependency First, add Testcontainers as a dependency as follows: Gradle Maven testImplementation \"org.testcontainers:spock:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> spock </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> 2. Get Testcontainers to run a Redis container during our tests Annotate the Spock specification class with the Testcontainers extension: Spock Testcontainers annotation @org.testcontainers.spock.Testcontainers class RedisBackedCacheIntTest extends Specification { And add the following field to the body of our test class: Spock Testcontainers init GenericContainer redis = new GenericContainer <>( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) This tells Spock to start a Testcontainers GenericContainer , configured to use a specific Redis image from Docker Hub, and configured to expose a port. If we run our test as-is, then regardless of the actual test outcome, we'll see logs showing us that Testcontainers: was activated before our test method ran discovered and quickly tested our local Docker setup pulled the image if necessary started a new container and waited for it to be ready shut down and deleted the container after the test 3. Make sure our code can talk to the container Before Testcontainers, we might have hardcoded an address like localhost:6379 into our tests. Testcontainers uses randomized ports for each container it starts, but makes it easy to obtain the actual port at runtime. We can do this in our test setup method, to set up our component under test: Obtaining a mapped port String address = redis . host Integer port = redis . firstMappedPort // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ) Tip Notice that we also ask Testcontainers for the container's actual address with redis.containerIpAddress , rather than hard-coding localhost . localhost may work in some environments but not others - for example it may not work on your current or future CI environment. As such, avoid hard-coding the address, and use containerIpAddress instead. 4. Run the tests! That's it! Let's look at our complete test class to see how little we had to add to get up and running with Testcontainers: RedisBackedCacheIntTest // complete { @org.testcontainers.spock.Testcontainers class RedisBackedCacheIntTest extends Specification { private RedisBackedCache underTest // init { GenericContainer redis = new GenericContainer <>( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) // } void setup () { String address = redis . host Integer port = redis . firstMappedPort // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ) } void testSimplePutAndGet () { setup: underTest . put ( \"test\" , \"example\" ) when: String retrieved = underTest . get ( \"test\" ) then: retrieved == \"example\" } } // }","title":"Spock Quickstart"},{"location":"quickstart/spock_quickstart/#spock-quickstart","text":"It's easy to add Testcontainers to your project - let's walk through a quick example to see how. Let's imagine we have a simple program that has a dependency on Redis, and we want to add some tests for it. In our imaginary program, there is a RedisBackedCache class which stores data in Redis. You can see an example test that could have been written for it (without using Testcontainers): Pre-Testcontainers test code class RedisBackedCacheIntTestStep0 extends Specification { private RedisBackedCache underTest void setup () { // Assume that we have Redis running locally? underTest = new RedisBackedCache ( \"localhost\" , 6379 ) } void testSimplePutAndGet () { setup: underTest . put ( \"test\" , \"example\" ) when: String retrieved = underTest . get ( \"test\" ) then: retrieved == \"example\" } } Notice that the existing test has a problem - it's relying on a local installation of Redis, which is a red flag for test reliability. This may work if we were sure that every developer and CI machine had Redis installed, but would fail otherwise. We might also have problems if we attempted to run tests in parallel, such as state bleeding between tests, or port clashes. Let's start from here, and see how to improve the test with Testcontainers:","title":"Spock Quickstart"},{"location":"quickstart/spock_quickstart/#1-add-testcontainers-as-a-test-scoped-dependency","text":"First, add Testcontainers as a dependency as follows: Gradle Maven testImplementation \"org.testcontainers:spock:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> spock </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"1. Add Testcontainers as a test-scoped dependency"},{"location":"quickstart/spock_quickstart/#2-get-testcontainers-to-run-a-redis-container-during-our-tests","text":"Annotate the Spock specification class with the Testcontainers extension: Spock Testcontainers annotation @org.testcontainers.spock.Testcontainers class RedisBackedCacheIntTest extends Specification { And add the following field to the body of our test class: Spock Testcontainers init GenericContainer redis = new GenericContainer <>( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) This tells Spock to start a Testcontainers GenericContainer , configured to use a specific Redis image from Docker Hub, and configured to expose a port. If we run our test as-is, then regardless of the actual test outcome, we'll see logs showing us that Testcontainers: was activated before our test method ran discovered and quickly tested our local Docker setup pulled the image if necessary started a new container and waited for it to be ready shut down and deleted the container after the test","title":"2. Get Testcontainers to run a Redis container during our tests"},{"location":"quickstart/spock_quickstart/#3-make-sure-our-code-can-talk-to-the-container","text":"Before Testcontainers, we might have hardcoded an address like localhost:6379 into our tests. Testcontainers uses randomized ports for each container it starts, but makes it easy to obtain the actual port at runtime. We can do this in our test setup method, to set up our component under test: Obtaining a mapped port String address = redis . host Integer port = redis . firstMappedPort // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ) Tip Notice that we also ask Testcontainers for the container's actual address with redis.containerIpAddress , rather than hard-coding localhost . localhost may work in some environments but not others - for example it may not work on your current or future CI environment. As such, avoid hard-coding the address, and use containerIpAddress instead.","title":"3. Make sure our code can talk to the container"},{"location":"quickstart/spock_quickstart/#4-run-the-tests","text":"That's it! Let's look at our complete test class to see how little we had to add to get up and running with Testcontainers: RedisBackedCacheIntTest // complete { @org.testcontainers.spock.Testcontainers class RedisBackedCacheIntTest extends Specification { private RedisBackedCache underTest // init { GenericContainer redis = new GenericContainer <>( \"redis:6-alpine\" ) . withExposedPorts ( 6379 ) // } void setup () { String address = redis . host Integer port = redis . firstMappedPort // Now we have an address and port for Redis, no matter where it is running underTest = new RedisBackedCache ( address , port ) } void testSimplePutAndGet () { setup: underTest . put ( \"test\" , \"example\" ) when: String retrieved = underTest . get ( \"test\" ) then: retrieved == \"example\" } } // }","title":"4. Run the tests!"},{"location":"supported_docker_environment/","text":"General Container runtime requirements Overview To run Testcontainers-based tests, you need a Docker-API compatible container runtime, such as using Testcontainers Cloud or installing Docker locally. During development, Testcontainers is actively tested against recent versions of Docker on Linux, as well as against Docker Desktop on Mac and Windows. These Docker environments are automatically detected and used by Testcontainers without any additional configuration being necessary. It is possible to configure Testcontainers to work with alternative container runtimes. Making use of the free Testcontainers Desktop app will take care of most of the manual configuration. When using those alternatives without Testcontainers Desktop, sometimes some manual configuration might be necessary (see further down for specific runtimes, or Customizing Docker host detection for general configuration mechanisms). Alternative container runtimes are not actively tested in the main development workflow, so not all Testcontainers features might be available. If you have further questions about configuration details for your setup or whether it supports running Testcontainers-based tests, please contact the Testcontainers team and other users from the Testcontainers community on Slack . Colima In order to run testcontainers against colima the env vars below should be set colima start --network-address export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE = /var/run/docker.sock export TESTCONTAINERS_HOST_OVERRIDE = $( colima ls -j | jq -r '.address' ) export DOCKER_HOST = \"unix:// ${ HOME } /.colima/default/docker.sock\" Podman In order to run testcontainers against podman the env vars bellow should be set MacOS: export DOCKER_HOST = unix:// $( podman machine inspect --format '{{.ConnectionInfo.PodmanSocket.Path}}' ) export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE = /var/run/docker.sock Linux: export DOCKER_HOST = unix:// ${ XDG_RUNTIME_DIR } /podman/podman.sock If you're running Podman in rootless mode, ensure to include the following line to disable Ryuk: export TESTCONTAINERS_RYUK_DISABLED = true Note Previous to version 1.19.0, export TESTCONTAINERS_RYUK_PRIVILEGED=true was required for rootful mode. Starting with 1.19.0, this is no longer required. Rancher Desktop In order to run testcontainers against Rancher Desktop the env vars below should be set. If you're running Rancher Desktop as an administrator in a MacOS (M1) machine: Using QEMU emulation export TESTCONTAINERS_HOST_OVERRIDE = $( rdctl shell ip a show rd0 | awk '/inet / {sub(\"/.*\",\"\"); print $2}' ) Using VZ emulation export TESTCONTAINERS_HOST_OVERRIDE = $( rdctl shell ip a show vznat | awk '/inet / {sub(\"/.*\",\"\"); print $2}' ) If you're not running Rancher Desktop as an administrator in a MacOS (M1) machine: Using VZ emulation export DOCKER_HOST = unix:// $HOME /.rd/docker.sock export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE = /var/run/docker.sock export TESTCONTAINERS_HOST_OVERRIDE = $( rdctl shell ip a show vznat | awk '/inet / {sub(\"/.*\",\"\"); print $2}' ) Docker environment discovery Testcontainers will try to connect to a Docker daemon using the following strategies in order: Environment variables: DOCKER_HOST DOCKER_TLS_VERIFY DOCKER_CERT_PATH Defaults: DOCKER_HOST=https://localhost:2376 DOCKER_TLS_VERIFY=1 DOCKER_CERT_PATH=~/.docker If Docker Machine is installed, the docker machine environment for the first machine found. Docker Machine needs to be on the PATH for this to succeed. If you're going to run your tests inside a container, please read Patterns for running tests inside a docker container first. Docker registry authentication Testcontainers will try to authenticate to registries with supplied config using the following strategies in order: Environment variables: DOCKER_AUTH_CONFIG Docker config At location specified in DOCKER_CONFIG or at {HOME}/.docker/config.json","title":"General Container runtime requirements"},{"location":"supported_docker_environment/#general-container-runtime-requirements","text":"","title":"General Container runtime requirements"},{"location":"supported_docker_environment/#overview","text":"To run Testcontainers-based tests, you need a Docker-API compatible container runtime, such as using Testcontainers Cloud or installing Docker locally. During development, Testcontainers is actively tested against recent versions of Docker on Linux, as well as against Docker Desktop on Mac and Windows. These Docker environments are automatically detected and used by Testcontainers without any additional configuration being necessary. It is possible to configure Testcontainers to work with alternative container runtimes. Making use of the free Testcontainers Desktop app will take care of most of the manual configuration. When using those alternatives without Testcontainers Desktop, sometimes some manual configuration might be necessary (see further down for specific runtimes, or Customizing Docker host detection for general configuration mechanisms). Alternative container runtimes are not actively tested in the main development workflow, so not all Testcontainers features might be available. If you have further questions about configuration details for your setup or whether it supports running Testcontainers-based tests, please contact the Testcontainers team and other users from the Testcontainers community on Slack .","title":"Overview"},{"location":"supported_docker_environment/#colima","text":"In order to run testcontainers against colima the env vars below should be set colima start --network-address export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE = /var/run/docker.sock export TESTCONTAINERS_HOST_OVERRIDE = $( colima ls -j | jq -r '.address' ) export DOCKER_HOST = \"unix:// ${ HOME } /.colima/default/docker.sock\"","title":"Colima"},{"location":"supported_docker_environment/#podman","text":"In order to run testcontainers against podman the env vars bellow should be set MacOS: export DOCKER_HOST = unix:// $( podman machine inspect --format '{{.ConnectionInfo.PodmanSocket.Path}}' ) export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE = /var/run/docker.sock Linux: export DOCKER_HOST = unix:// ${ XDG_RUNTIME_DIR } /podman/podman.sock If you're running Podman in rootless mode, ensure to include the following line to disable Ryuk: export TESTCONTAINERS_RYUK_DISABLED = true Note Previous to version 1.19.0, export TESTCONTAINERS_RYUK_PRIVILEGED=true was required for rootful mode. Starting with 1.19.0, this is no longer required.","title":"Podman"},{"location":"supported_docker_environment/#rancher-desktop","text":"In order to run testcontainers against Rancher Desktop the env vars below should be set. If you're running Rancher Desktop as an administrator in a MacOS (M1) machine: Using QEMU emulation export TESTCONTAINERS_HOST_OVERRIDE = $( rdctl shell ip a show rd0 | awk '/inet / {sub(\"/.*\",\"\"); print $2}' ) Using VZ emulation export TESTCONTAINERS_HOST_OVERRIDE = $( rdctl shell ip a show vznat | awk '/inet / {sub(\"/.*\",\"\"); print $2}' ) If you're not running Rancher Desktop as an administrator in a MacOS (M1) machine: Using VZ emulation export DOCKER_HOST = unix:// $HOME /.rd/docker.sock export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE = /var/run/docker.sock export TESTCONTAINERS_HOST_OVERRIDE = $( rdctl shell ip a show vznat | awk '/inet / {sub(\"/.*\",\"\"); print $2}' )","title":"Rancher Desktop"},{"location":"supported_docker_environment/#docker-environment-discovery","text":"Testcontainers will try to connect to a Docker daemon using the following strategies in order: Environment variables: DOCKER_HOST DOCKER_TLS_VERIFY DOCKER_CERT_PATH Defaults: DOCKER_HOST=https://localhost:2376 DOCKER_TLS_VERIFY=1 DOCKER_CERT_PATH=~/.docker If Docker Machine is installed, the docker machine environment for the first machine found. Docker Machine needs to be on the PATH for this to succeed. If you're going to run your tests inside a container, please read Patterns for running tests inside a docker container first.","title":"Docker environment discovery"},{"location":"supported_docker_environment/#docker-registry-authentication","text":"Testcontainers will try to authenticate to registries with supplied config using the following strategies in order: Environment variables: DOCKER_AUTH_CONFIG Docker config At location specified in DOCKER_CONFIG or at {HOME}/.docker/config.json","title":"Docker registry authentication"},{"location":"supported_docker_environment/image_registry_rate_limiting/","text":"Image Registry rate limiting As of November 2020 Docker Hub pulls are rate limited. As Testcontainers uses Docker Hub for standard images, some users may hit these rate limits and should mitigate accordingly. Suggested mitigations are noted in this issue at present. Which images are used by Testcontainers? As of the current version of Testcontainers (1.20.6): every image directly used by your tests images pulled by Testcontainers itself to support functionality: testcontainers/ryuk - performs fail-safe cleanup of containers, and always required (unless Ryuk is disabled ) alpine - used to check whether images can be pulled at startup, and always required (unless startup checks are disabled ) testcontainers/sshd - required if exposing host ports to containers testcontainers/vnc-recorder - required if using Webdriver containers and using the screen recording feature docker/compose - required if using Docker Compose alpine/socat - required if using Docker Compose","title":"Image Registry rate limiting"},{"location":"supported_docker_environment/image_registry_rate_limiting/#image-registry-rate-limiting","text":"As of November 2020 Docker Hub pulls are rate limited. As Testcontainers uses Docker Hub for standard images, some users may hit these rate limits and should mitigate accordingly. Suggested mitigations are noted in this issue at present.","title":"Image Registry rate limiting"},{"location":"supported_docker_environment/image_registry_rate_limiting/#which-images-are-used-by-testcontainers","text":"As of the current version of Testcontainers (1.20.6): every image directly used by your tests images pulled by Testcontainers itself to support functionality: testcontainers/ryuk - performs fail-safe cleanup of containers, and always required (unless Ryuk is disabled ) alpine - used to check whether images can be pulled at startup, and always required (unless startup checks are disabled ) testcontainers/sshd - required if exposing host ports to containers testcontainers/vnc-recorder - required if using Webdriver containers and using the screen recording feature docker/compose - required if using Docker Compose alpine/socat - required if using Docker Compose","title":"Which images are used by Testcontainers?"},{"location":"supported_docker_environment/logging_config/","text":"Recommended logback configuration Testcontainers, and many of the libraries it uses, utilize SLF4J for logging. In order to see logs from Testcontainers, your project should include an SLF4J implementation (Logback is recommended). The following example logback-test.xml should be included in your classpath to show a reasonable level of log output: <configuration> <appender name= \"STDOUT\" class= \"ch.qos.logback.core.ConsoleAppender\" > <encoder> <pattern> %d{HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n </pattern> </encoder> </appender> <root level= \"info\" > <appender-ref ref= \"STDOUT\" /> </root> <logger name= \"org.testcontainers\" level= \"INFO\" /> <!-- The following logger can be used for containers logs since 1.18.0 --> <logger name= \"tc\" level= \"INFO\" /> <logger name= \"com.github.dockerjava\" level= \"WARN\" /> <logger name= \"com.github.dockerjava.zerodep.shaded.org.apache.hc.client5.http.wire\" level= \"OFF\" /> </configuration> In order to troubleshoot issues with Testcontainers, increase the logging level of org.testcontainers to DEBUG : <logger name= \"org.testcontainers\" level= \"DEBUG\" /> Avoid changing the root logger's level to DEBUG , because this turns on debug logging for every package whose level isn't explicitly configured here, resulting in a large amount of log data.","title":"Recommended logback configuration"},{"location":"supported_docker_environment/logging_config/#recommended-logback-configuration","text":"Testcontainers, and many of the libraries it uses, utilize SLF4J for logging. In order to see logs from Testcontainers, your project should include an SLF4J implementation (Logback is recommended). The following example logback-test.xml should be included in your classpath to show a reasonable level of log output: <configuration> <appender name= \"STDOUT\" class= \"ch.qos.logback.core.ConsoleAppender\" > <encoder> <pattern> %d{HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n </pattern> </encoder> </appender> <root level= \"info\" > <appender-ref ref= \"STDOUT\" /> </root> <logger name= \"org.testcontainers\" level= \"INFO\" /> <!-- The following logger can be used for containers logs since 1.18.0 --> <logger name= \"tc\" level= \"INFO\" /> <logger name= \"com.github.dockerjava\" level= \"WARN\" /> <logger name= \"com.github.dockerjava.zerodep.shaded.org.apache.hc.client5.http.wire\" level= \"OFF\" /> </configuration> In order to troubleshoot issues with Testcontainers, increase the logging level of org.testcontainers to DEBUG : <logger name= \"org.testcontainers\" level= \"DEBUG\" /> Avoid changing the root logger's level to DEBUG , because this turns on debug logging for every package whose level isn't explicitly configured here, resulting in a large amount of log data.","title":"Recommended logback configuration"},{"location":"supported_docker_environment/windows/","text":"Windows Support Prerequisites Docker for Windows needs to be installed Docker version 17.06 is confirmed to work on Windows 10 with Hyper-V. Testcontainers supports communication with Docker on Docker for Windows using named pipes. WSL2 backend is supported starting with Windows 10 2004. ( Beta ) Docker on Windows Server 2019 is currently not supported (also note this issue ). Limitations The following features are not available or do not work correctly so make sure you do not use them or use them with caution. The list may not be complete. MySQL containers MySQL server prevents custom configuration file (ini-script) from being loaded due to security measures ( link to feature description ) Windows Container on Windows (WCOW) WCOW is currently not supported, since Testcontainers uses auxiliary Linux containers for certain tasks and Docker for Windows does not support hybrid engine mode at the time of writing. WSL2 backend Using Docker for Windows with WSL2 backend should work out of the box. However, there is an existing issue in WSL/WSL2 that effects certain older Docker images. The currently proposed workaround is to enable vsyscall emulation in the WSL2 kernel: [wsl2] kernelCommandLine = vsyscall=emulate Windows Subsystem for Linux (WSL) Testcontainers supports communicating with Docker for Windows within the Windows Subsystem for Linux ( WSL ) . The following additional configurations steps are required: Expose the Docker for Windows daemon on tcp port 2375 without TLS . (Right-click the Docker for Windows icon on the task bar, click setting and go to General ) . Set the DOCKER_HOST environment variable inside the WSL shell to tcp://localhost:2375 . It is recommended to add this to your ~/.bashrc file, so it\u2019s available every time you open your terminal. Optional - Only if volumes are required: Inside the WSL shell, modify the /ect/wsl.conf file to mount the Windows drives on / instead of on /mnt/ . (Reboot required after this step) . Remember to share the drives, on which you will store your volumes, with Docker for Windows. (Right-click the Docker for Windows icon on the task bar, click setting and go to Shared Drives ) . More information about running Docker within the WSL can be found here . Reporting issues Please report any issues with the Windows build of Testcontainers here and be sure to note that you are using this on Windows.","title":"Windows Support"},{"location":"supported_docker_environment/windows/#windows-support","text":"","title":"Windows Support"},{"location":"supported_docker_environment/windows/#prerequisites","text":"Docker for Windows needs to be installed Docker version 17.06 is confirmed to work on Windows 10 with Hyper-V. Testcontainers supports communication with Docker on Docker for Windows using named pipes. WSL2 backend is supported starting with Windows 10 2004. ( Beta ) Docker on Windows Server 2019 is currently not supported (also note this issue ).","title":"Prerequisites"},{"location":"supported_docker_environment/windows/#limitations","text":"The following features are not available or do not work correctly so make sure you do not use them or use them with caution. The list may not be complete.","title":"Limitations"},{"location":"supported_docker_environment/windows/#mysql-containers","text":"MySQL server prevents custom configuration file (ini-script) from being loaded due to security measures ( link to feature description )","title":"MySQL containers"},{"location":"supported_docker_environment/windows/#windows-container-on-windows-wcow","text":"WCOW is currently not supported, since Testcontainers uses auxiliary Linux containers for certain tasks and Docker for Windows does not support hybrid engine mode at the time of writing.","title":"Windows Container on Windows (WCOW)"},{"location":"supported_docker_environment/windows/#wsl2-backend","text":"Using Docker for Windows with WSL2 backend should work out of the box. However, there is an existing issue in WSL/WSL2 that effects certain older Docker images. The currently proposed workaround is to enable vsyscall emulation in the WSL2 kernel: [wsl2] kernelCommandLine = vsyscall=emulate","title":"WSL2 backend"},{"location":"supported_docker_environment/windows/#windows-subsystem-for-linux-wsl","text":"Testcontainers supports communicating with Docker for Windows within the Windows Subsystem for Linux ( WSL ) . The following additional configurations steps are required: Expose the Docker for Windows daemon on tcp port 2375 without TLS . (Right-click the Docker for Windows icon on the task bar, click setting and go to General ) . Set the DOCKER_HOST environment variable inside the WSL shell to tcp://localhost:2375 . It is recommended to add this to your ~/.bashrc file, so it\u2019s available every time you open your terminal. Optional - Only if volumes are required: Inside the WSL shell, modify the /ect/wsl.conf file to mount the Windows drives on / instead of on /mnt/ . (Reboot required after this step) . Remember to share the drives, on which you will store your volumes, with Docker for Windows. (Right-click the Docker for Windows icon on the task bar, click setting and go to Shared Drives ) . More information about running Docker within the WSL can be found here .","title":"Windows Subsystem for Linux (WSL)"},{"location":"supported_docker_environment/windows/#reporting-issues","text":"Please report any issues with the Windows build of Testcontainers here and be sure to note that you are using this on Windows.","title":"Reporting issues"},{"location":"supported_docker_environment/continuous_integration/aws_codebuild/","text":"AWS CodeBuild To enable access to Docker in AWS CodeBuild, go to Privileged section and check Enable this flag if you want to build Docker images or want your builds to get elevated privileges . This is a sample buildspec.yml config: version : 0.2 phases : install : runtime-versions : java : corretto17 build : commands : - ./mvnw test","title":"AWS CodeBuild"},{"location":"supported_docker_environment/continuous_integration/aws_codebuild/#aws-codebuild","text":"To enable access to Docker in AWS CodeBuild, go to Privileged section and check Enable this flag if you want to build Docker images or want your builds to get elevated privileges . This is a sample buildspec.yml config: version : 0.2 phases : install : runtime-versions : java : corretto17 build : commands : - ./mvnw test","title":"AWS CodeBuild"},{"location":"supported_docker_environment/continuous_integration/bitbucket_pipelines/","text":"Bitbucket Pipelines To enable access to Docker in Bitbucket Pipelines, you need to add docker as a service on the step. Furthermore, Ryuk needs to be turned off since Bitbucket Pipelines does not allow starting privileged containers (see Disabling Ryuk ). This can either be done by setting a repository variable in Bitbucket's project settings or by explicitly exporting the variable on a step. In some cases the memory available to Docker needs to be increased. Here is a sample Bitbucket Pipeline configuration that does a checkout of a project and runs maven: image: maven:3.6.1 pipelines: default: - step: script: - export TESTCONTAINERS_RYUK_DISABLED=true - mvn clean install services: - docker definitions: services: docker: memory: 2048","title":"Bitbucket Pipelines"},{"location":"supported_docker_environment/continuous_integration/bitbucket_pipelines/#bitbucket-pipelines","text":"To enable access to Docker in Bitbucket Pipelines, you need to add docker as a service on the step. Furthermore, Ryuk needs to be turned off since Bitbucket Pipelines does not allow starting privileged containers (see Disabling Ryuk ). This can either be done by setting a repository variable in Bitbucket's project settings or by explicitly exporting the variable on a step. In some cases the memory available to Docker needs to be increased. Here is a sample Bitbucket Pipeline configuration that does a checkout of a project and runs maven: image: maven:3.6.1 pipelines: default: - step: script: - export TESTCONTAINERS_RYUK_DISABLED=true - mvn clean install services: - docker definitions: services: docker: memory: 2048","title":"Bitbucket Pipelines"},{"location":"supported_docker_environment/continuous_integration/circle_ci/","text":"CircleCI (Cloud, Server v2.x, and Server v3.x) Your CircleCI configuration should use a dedicated VM for Testcontainers to work. You can achieve this by specifying the executor type in your .circleci/config.yml to be machine instead of the default docker executor (see Choosing an Executor Type for more info). Here is a sample CircleCI configuration that does a checkout of a project and runs Maven: jobs: build: # Check https://circleci.com/docs/executor-intro#linux-vm for more details machine: true steps: - checkout - run: mvn -B clean install You can learn more about the best practices of using Testcontainers together with CircleCI in this article .","title":"CircleCI (Cloud, Server v2.x, and Server v3.x)"},{"location":"supported_docker_environment/continuous_integration/circle_ci/#circleci-cloud-server-v2x-and-server-v3x","text":"Your CircleCI configuration should use a dedicated VM for Testcontainers to work. You can achieve this by specifying the executor type in your .circleci/config.yml to be machine instead of the default docker executor (see Choosing an Executor Type for more info). Here is a sample CircleCI configuration that does a checkout of a project and runs Maven: jobs: build: # Check https://circleci.com/docs/executor-intro#linux-vm for more details machine: true steps: - checkout - run: mvn -B clean install You can learn more about the best practices of using Testcontainers together with CircleCI in this article .","title":"CircleCI (Cloud, Server v2.x, and Server v3.x)"},{"location":"supported_docker_environment/continuous_integration/concourse_ci/","text":"Concourse CI This is an example to run Testcontainers tests on Concourse CI . A possible pipeline.yml config looks like this: resources : - name : repo type : git source : uri : https://github.com/testcontainers/testcontainers-java-repro.git jobs : - name : testcontainers-job plan : # Add a get step referencing the resource - get : repo - task : testcontainers-task privileged : true config : platform : linux image_resource : type : docker-image source : repository : amidos/dcind tag : 2.1.0 inputs : - name : repo run : path : /bin/sh args : - -c - | source /docker-lib.sh start_docker cd repo docker run -it --rm -v \"$PWD:$PWD\" -w \"$PWD\" -v /var/run/docker.sock:/var/run/docker.sock eclipse-temurin:17.0.5_8-jdk-alpine ./mvnw clean package fly -t tutorial set-pipeline -p testcontainers-pipeline -c pipeline.yml fly -t tutorial unpause-pipeline -p testcontainers-pipeline fly -t tutorial trigger-job --job testcontainers-pipeline/testcontainers-job --watch","title":"Concourse CI"},{"location":"supported_docker_environment/continuous_integration/concourse_ci/#concourse-ci","text":"This is an example to run Testcontainers tests on Concourse CI . A possible pipeline.yml config looks like this: resources : - name : repo type : git source : uri : https://github.com/testcontainers/testcontainers-java-repro.git jobs : - name : testcontainers-job plan : # Add a get step referencing the resource - get : repo - task : testcontainers-task privileged : true config : platform : linux image_resource : type : docker-image source : repository : amidos/dcind tag : 2.1.0 inputs : - name : repo run : path : /bin/sh args : - -c - | source /docker-lib.sh start_docker cd repo docker run -it --rm -v \"$PWD:$PWD\" -w \"$PWD\" -v /var/run/docker.sock:/var/run/docker.sock eclipse-temurin:17.0.5_8-jdk-alpine ./mvnw clean package fly -t tutorial set-pipeline -p testcontainers-pipeline -c pipeline.yml fly -t tutorial unpause-pipeline -p testcontainers-pipeline fly -t tutorial trigger-job --job testcontainers-pipeline/testcontainers-job --watch","title":"Concourse CI"},{"location":"supported_docker_environment/continuous_integration/dind_patterns/","text":"Patterns for running tests inside a Docker container 'Docker wormhole' pattern - Sibling docker containers Testcontainers itself can be used from inside a container. This is very useful for different CI scenarios like running everything in containers on Jenkins, or Docker-based CI tools such as Drone. Testcontainers will automatically detect if it's inside a container and instead of \"localhost\" will use the default gateway's IP. However, additional configuration is required if you use volume mapping . The following points need to be considered: The docker socket must be available via a volume mount The 'local' source code directory must be volume mounted at the same path inside the container that Testcontainers runs in, so that Testcontainers is able to set up the correct volume mounts for the containers it spawns. Docker-only example If you run the tests with just docker run ... then make sure you add -v $PWD:$PWD -w $PWD -v /var/run/docker.sock:/var/run/docker.sock to the command, so it will look like this: $ tree . . \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 src \u2514\u2500\u2500 test \u2514\u2500\u2500 java \u2514\u2500\u2500 MyTestWithTestcontainers.java $ docker run -it --rm -v $PWD : $PWD -w $PWD -v /var/run/docker.sock:/var/run/docker.sock maven:3 mvn test Where: -v $PWD:$PWD will add your current directory as a volume inside the container -w $PWD will set the current directory to this volume -v /var/run/docker.sock:/var/run/docker.sock will map the Docker socket Note If you are using Docker Desktop, you need to configure the TESTCONTAINERS_HOST_OVERRIDE environment variable to use the special DNS name host.docker.internal for accessing the host from within a container, which is provided by Docker Desktop: -e TESTCONTAINERS_HOST_OVERRIDE=host.docker.internal Docker Compose example The same can be achieved with Docker Compose: tests : image : maven:3 stop_signal : SIGKILL stdin_open : true tty : true working_dir : $PWD volumes : - $PWD:$PWD - /var/run/docker.sock:/var/run/docker.sock # Maven cache (optional) - ~/.m2:/root/.m2 command : mvn test Docker-in-Docker While Docker-in-Docker (DinD) is generally considered an instrument of last resort, it is necessary for some CI environments. Drone CI is one such example. Testcontainers has a Docker-in-Docker plugin (build image) for use with Drone, which could be used as inspiration for setting up other similar testing using DinD.","title":"Patterns for running tests inside a Docker container"},{"location":"supported_docker_environment/continuous_integration/dind_patterns/#patterns-for-running-tests-inside-a-docker-container","text":"","title":"Patterns for running tests inside a Docker container"},{"location":"supported_docker_environment/continuous_integration/dind_patterns/#docker-wormhole-pattern-sibling-docker-containers","text":"Testcontainers itself can be used from inside a container. This is very useful for different CI scenarios like running everything in containers on Jenkins, or Docker-based CI tools such as Drone. Testcontainers will automatically detect if it's inside a container and instead of \"localhost\" will use the default gateway's IP. However, additional configuration is required if you use volume mapping . The following points need to be considered: The docker socket must be available via a volume mount The 'local' source code directory must be volume mounted at the same path inside the container that Testcontainers runs in, so that Testcontainers is able to set up the correct volume mounts for the containers it spawns.","title":"'Docker wormhole' pattern - Sibling docker containers"},{"location":"supported_docker_environment/continuous_integration/dind_patterns/#docker-only-example","text":"If you run the tests with just docker run ... then make sure you add -v $PWD:$PWD -w $PWD -v /var/run/docker.sock:/var/run/docker.sock to the command, so it will look like this: $ tree . . \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 src \u2514\u2500\u2500 test \u2514\u2500\u2500 java \u2514\u2500\u2500 MyTestWithTestcontainers.java $ docker run -it --rm -v $PWD : $PWD -w $PWD -v /var/run/docker.sock:/var/run/docker.sock maven:3 mvn test Where: -v $PWD:$PWD will add your current directory as a volume inside the container -w $PWD will set the current directory to this volume -v /var/run/docker.sock:/var/run/docker.sock will map the Docker socket Note If you are using Docker Desktop, you need to configure the TESTCONTAINERS_HOST_OVERRIDE environment variable to use the special DNS name host.docker.internal for accessing the host from within a container, which is provided by Docker Desktop: -e TESTCONTAINERS_HOST_OVERRIDE=host.docker.internal","title":"Docker-only example"},{"location":"supported_docker_environment/continuous_integration/dind_patterns/#docker-compose-example","text":"The same can be achieved with Docker Compose: tests : image : maven:3 stop_signal : SIGKILL stdin_open : true tty : true working_dir : $PWD volumes : - $PWD:$PWD - /var/run/docker.sock:/var/run/docker.sock # Maven cache (optional) - ~/.m2:/root/.m2 command : mvn test","title":"Docker Compose example"},{"location":"supported_docker_environment/continuous_integration/dind_patterns/#docker-in-docker","text":"While Docker-in-Docker (DinD) is generally considered an instrument of last resort, it is necessary for some CI environments. Drone CI is one such example. Testcontainers has a Docker-in-Docker plugin (build image) for use with Drone, which could be used as inspiration for setting up other similar testing using DinD.","title":"Docker-in-Docker"},{"location":"supported_docker_environment/continuous_integration/drone/","text":"Drone CI Drone CI 0.8 is supported via the use of a general purpose Docker-in-Docker plugin. Please see testcontainers/dind-drone-plugin for further details and usage instructions.","title":"Drone CI"},{"location":"supported_docker_environment/continuous_integration/drone/#drone-ci","text":"Drone CI 0.8 is supported via the use of a general purpose Docker-in-Docker plugin. Please see testcontainers/dind-drone-plugin for further details and usage instructions.","title":"Drone CI"},{"location":"supported_docker_environment/continuous_integration/gitlab_ci/","text":"GitLab CI Example using Docker socket This applies if you have your own GitlabCI runner installed, use the Docker executor and you have /var/run/docker.sock mounted in the runner configuration. See below for an example runner configuration: [[runners]] name = \"MACHINE_NAME\" url = \"https://gitlab.com/\" token = \"GENERATED_GITLAB_RUNNER_TOKEN\" executor = \"docker\" [runners.docker] tls_verify = false image = \"docker:latest\" privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [ \"/var/run/docker.sock:/var/run/docker.sock\" , \"/cache\" ] shm_size = 0 Please also include the following in your GitlabCI pipeline definitions ( .gitlab-ci.yml ) that use Testcontainers: variables: TESTCONTAINERS_HOST_OVERRIDE: \"<ip-docker-host>\" The environment variable TESTCONTAINERS_HOST_OVERRIDE needs to be configured, otherwise, a wrong IP address would be used to resolve the Docker host, which will likely lead to failing tests. For Windows and MacOS, use host.docker.internal . Example using DinD (Docker-in-Docker) In order to use Testcontainers in a Gitlab CI pipeline, you need to run the job as a Docker container (see Patterns for running inside Docker ). So edit your .gitlab-ci.yml to include the Docker-In-Docker service ( docker:dind ) and set the DOCKER_HOST variable to tcp://docker:2375 and DOCKER_TLS_CERTDIR to empty string. Caveat: Current docker releases (verified for 20.10.9) intentionally delay the startup, if the docker api is bound to a network address but not TLS protected. To avoid this delay, the docker process needs to be started with the argument --tls=false . Otherwise jobs which access the docker api at the very beginning might fail. Here is a sample .gitlab-ci.yml that executes test with gradle: # DinD service is required for Testcontainers services: - name: docker:dind # explicitly disable tls to avoid docker startup interruption command: [\"--tls=false\"] variables: # Instruct Testcontainers to use the daemon of DinD, use port 2375 for non-tls connections. DOCKER_HOST: \"tcp://docker:2375\" # Instruct Docker not to start over TLS. DOCKER_TLS_CERTDIR: \"\" # Improve performance with overlayfs. DOCKER_DRIVER: overlay2 test: image: gradle:5.0 stage: test script: ./gradlew test","title":"GitLab CI"},{"location":"supported_docker_environment/continuous_integration/gitlab_ci/#gitlab-ci","text":"","title":"GitLab CI"},{"location":"supported_docker_environment/continuous_integration/gitlab_ci/#example-using-docker-socket","text":"This applies if you have your own GitlabCI runner installed, use the Docker executor and you have /var/run/docker.sock mounted in the runner configuration. See below for an example runner configuration: [[runners]] name = \"MACHINE_NAME\" url = \"https://gitlab.com/\" token = \"GENERATED_GITLAB_RUNNER_TOKEN\" executor = \"docker\" [runners.docker] tls_verify = false image = \"docker:latest\" privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [ \"/var/run/docker.sock:/var/run/docker.sock\" , \"/cache\" ] shm_size = 0 Please also include the following in your GitlabCI pipeline definitions ( .gitlab-ci.yml ) that use Testcontainers: variables: TESTCONTAINERS_HOST_OVERRIDE: \"<ip-docker-host>\" The environment variable TESTCONTAINERS_HOST_OVERRIDE needs to be configured, otherwise, a wrong IP address would be used to resolve the Docker host, which will likely lead to failing tests. For Windows and MacOS, use host.docker.internal .","title":"Example using Docker socket"},{"location":"supported_docker_environment/continuous_integration/gitlab_ci/#example-using-dind-docker-in-docker","text":"In order to use Testcontainers in a Gitlab CI pipeline, you need to run the job as a Docker container (see Patterns for running inside Docker ). So edit your .gitlab-ci.yml to include the Docker-In-Docker service ( docker:dind ) and set the DOCKER_HOST variable to tcp://docker:2375 and DOCKER_TLS_CERTDIR to empty string. Caveat: Current docker releases (verified for 20.10.9) intentionally delay the startup, if the docker api is bound to a network address but not TLS protected. To avoid this delay, the docker process needs to be started with the argument --tls=false . Otherwise jobs which access the docker api at the very beginning might fail. Here is a sample .gitlab-ci.yml that executes test with gradle: # DinD service is required for Testcontainers services: - name: docker:dind # explicitly disable tls to avoid docker startup interruption command: [\"--tls=false\"] variables: # Instruct Testcontainers to use the daemon of DinD, use port 2375 for non-tls connections. DOCKER_HOST: \"tcp://docker:2375\" # Instruct Docker not to start over TLS. DOCKER_TLS_CERTDIR: \"\" # Improve performance with overlayfs. DOCKER_DRIVER: overlay2 test: image: gradle:5.0 stage: test script: ./gradlew test","title":"Example using DinD (Docker-in-Docker)"},{"location":"supported_docker_environment/continuous_integration/tekton/","text":"Tekton To enable access to Docker in Tekton, a dind sidecar needs to be added. An example of it can be found here This is an example apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : run-tests description : Run Tests spec : workspaces : - name : source steps : - name : read image : eclipse-temurin:17.0.3_7-jdk-alpine workingDir : $(workspaces.source.path) script : ./mvnw test volumeMounts : - mountPath : /var/run/ name : dind-socket sidecars : - image : docker:20.10-dind name : docker securityContext : privileged : true volumeMounts : - mountPath : /var/lib/docker name : dind-storage - mountPath : /var/run/ name : dind-socket volumes : - name : dind-storage emptyDir : { } - name : dind-socket emptyDir : { } --- apiVersion : tekton.dev/v1beta1 kind : Pipeline metadata : name : testcontainers-demo spec : description : | This pipeline clones a git repo, run testcontainers. params : - name : repo-url type : string description : The git repo URL to clone from. workspaces : - name : shared-data description : | This workspace contains the cloned repo files, so they can be read by the next task. tasks : - name : fetch-source taskRef : name : git-clone workspaces : - name : output workspace : shared-data params : - name : url value : $(params.repo-url) - name : run-tests runAfter : [ \"fetch-source\" ] taskRef : name : run-tests workspaces : - name : source workspace : shared-data --- apiVersion : tekton.dev/v1beta1 kind : PipelineRun metadata : name : testcontainers-demo-run spec : pipelineRef : name : testcontainers-demo workspaces : - name : shared-data volumeClaimTemplate : spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi params : - name : repo-url value : https://github.com/testcontainers/testcontainers-java-repro.git","title":"Tekton"},{"location":"supported_docker_environment/continuous_integration/tekton/#tekton","text":"To enable access to Docker in Tekton, a dind sidecar needs to be added. An example of it can be found here This is an example apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : run-tests description : Run Tests spec : workspaces : - name : source steps : - name : read image : eclipse-temurin:17.0.3_7-jdk-alpine workingDir : $(workspaces.source.path) script : ./mvnw test volumeMounts : - mountPath : /var/run/ name : dind-socket sidecars : - image : docker:20.10-dind name : docker securityContext : privileged : true volumeMounts : - mountPath : /var/lib/docker name : dind-storage - mountPath : /var/run/ name : dind-socket volumes : - name : dind-storage emptyDir : { } - name : dind-socket emptyDir : { } --- apiVersion : tekton.dev/v1beta1 kind : Pipeline metadata : name : testcontainers-demo spec : description : | This pipeline clones a git repo, run testcontainers. params : - name : repo-url type : string description : The git repo URL to clone from. workspaces : - name : shared-data description : | This workspace contains the cloned repo files, so they can be read by the next task. tasks : - name : fetch-source taskRef : name : git-clone workspaces : - name : output workspace : shared-data params : - name : url value : $(params.repo-url) - name : run-tests runAfter : [ \"fetch-source\" ] taskRef : name : run-tests workspaces : - name : source workspace : shared-data --- apiVersion : tekton.dev/v1beta1 kind : PipelineRun metadata : name : testcontainers-demo-run spec : pipelineRef : name : testcontainers-demo workspaces : - name : shared-data volumeClaimTemplate : spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi params : - name : repo-url value : https://github.com/testcontainers/testcontainers-java-repro.git","title":"Tekton"},{"location":"supported_docker_environment/continuous_integration/travis/","text":"Travis To run Testcontainers on TravisCI, docker needs to be installed. The configuration below is the minimal required config. language : java jdk : - openjdk8 services : - docker script : ./mvnw verify","title":"Travis"},{"location":"supported_docker_environment/continuous_integration/travis/#travis","text":"To run Testcontainers on TravisCI, docker needs to be installed. The configuration below is the minimal required config. language : java jdk : - openjdk8 services : - docker script : ./mvnw verify","title":"Travis"},{"location":"test_framework_integration/external/","text":"External Integrations The following Open Source frameworks add direct integration to Testcontainers Framework Source Code Documentation jqwik jqwik-testcontainers README Kotest Kotest Extensions Testcontainers kotest.io Synthesized Synthesized TDK-Testcontainers integration synthesized.io TCI Testcontainers Infrastructure (TCI) Framework README","title":"External Integrations"},{"location":"test_framework_integration/external/#external-integrations","text":"The following Open Source frameworks add direct integration to Testcontainers Framework Source Code Documentation jqwik jqwik-testcontainers README Kotest Kotest Extensions Testcontainers kotest.io Synthesized Synthesized TDK-Testcontainers integration synthesized.io TCI Testcontainers Infrastructure (TCI) Framework README","title":"External Integrations"},{"location":"test_framework_integration/junit_4/","text":"JUnit 4 @Rule / @ClassRule integration JUnit4 @Rule / @ClassRule : This mode starts the container before your tests and tears it down afterwards. Add a @Rule or @ClassRule annotated field to your test class, e.g.: public class SimpleMySQLTest { @Rule public MySQLContainer mysql = new MySQLContainer (); // [...] } Manually controlling container lifecycle As an alternative, you can manually start the container in a @BeforeClass / @Before annotated method in your tests. Tear down will be done automatically on JVM exit, but you can of course also use an @AfterClass / @After annotated method to manually call the stop() method on your container. Example of starting a container in a @Before annotated method: class SimpleMySQLTest { private MySQLContainer mysql = new MySQLContainer (); @Before void before () { mysql . start (); } @After void after () { mysql . stop (); } // [...] } Singleton containers Note that the singleton container pattern is also an option when using JUnit 4.","title":"JUnit 4"},{"location":"test_framework_integration/junit_4/#junit-4","text":"","title":"JUnit 4"},{"location":"test_framework_integration/junit_4/#ruleclassrule-integration","text":"JUnit4 @Rule / @ClassRule : This mode starts the container before your tests and tears it down afterwards. Add a @Rule or @ClassRule annotated field to your test class, e.g.: public class SimpleMySQLTest { @Rule public MySQLContainer mysql = new MySQLContainer (); // [...] }","title":"@Rule/@ClassRule integration"},{"location":"test_framework_integration/junit_4/#manually-controlling-container-lifecycle","text":"As an alternative, you can manually start the container in a @BeforeClass / @Before annotated method in your tests. Tear down will be done automatically on JVM exit, but you can of course also use an @AfterClass / @After annotated method to manually call the stop() method on your container. Example of starting a container in a @Before annotated method: class SimpleMySQLTest { private MySQLContainer mysql = new MySQLContainer (); @Before void before () { mysql . start (); } @After void after () { mysql . stop (); } // [...] }","title":"Manually controlling container lifecycle"},{"location":"test_framework_integration/junit_4/#singleton-containers","text":"Note that the singleton container pattern is also an option when using JUnit 4.","title":"Singleton containers"},{"location":"test_framework_integration/junit_5/","text":"Jupiter / JUnit 5 While Testcontainers is tightly coupled with the JUnit 4.x rule API, this module provides an API that is based on the JUnit Jupiter extension model. The extension supports two modes: containers that are restarted for every test method containers that are shared between all methods of a test class Note that Jupiter/JUnit 5 integration is packaged as a separate library JAR; see below for details. Extension Jupiter integration is provided by means of the @Testcontainers annotation. The extension finds all fields that are annotated with @Container and calls their container lifecycle methods (methods on the Startable interface). Containers declared as static fields will be shared between test methods. They will be started only once before any test method is executed and stopped after the last test method has executed. Containers declared as instance fields will be started and stopped for every test method. Note: This extension has only been tested with sequential test execution. Using it with parallel test execution is unsupported and may have unintended side effects. Example: Mixed Lifecycle @Testcontainers class MixedLifecycleTests { // will be shared between test methods @Container private static final MySQLContainer MY_SQL_CONTAINER = new MySQLContainer (); // will be started before and stopped after each test method @Container private PostgreSQLContainer postgresqlContainer = new PostgreSQLContainer () . withDatabaseName ( \"foo\" ) . withUsername ( \"foo\" ) . withPassword ( \"secret\" ); @Test void test () { assertThat ( MY_SQL_CONTAINER . isRunning ()). isTrue (); assertThat ( postgresqlContainer . isRunning ()). isTrue (); } } Examples To use the Testcontainers extension annotate your test class with @Testcontainers . Restarted containers To define a restarted container, define an instance field inside your test class and annotate it with the @Container annotation. Restarted Containers @Testcontainers class TestcontainersNestedRestartedContainerTests { @Container private final GenericContainer <?> topLevelContainer = new GenericContainer <> ( JUnitJupiterTestImages . HTTPD_IMAGE ) . withExposedPorts ( 80 ); \u22ef @Test void top_level_container_should_be_running () { assertThat ( topLevelContainer . isRunning ()). isTrue (); \u22ef } @Nested class NestedTestCase { @Container private final GenericContainer <?> nestedContainer = new GenericContainer <> ( JUnitJupiterTestImages . HTTPD_IMAGE ) . withExposedPorts ( 80 ); @Test void both_containers_should_be_running () { // top level container is restarted for nested methods assertThat ( topLevelContainer . isRunning ()). isTrue (); // nested containers are only available inside their nested class assertThat ( nestedContainer . isRunning ()). isTrue (); \u22ef } \u22ef } } Shared containers Shared containers are defined as static fields in a top level test class and have to be annotated with @Container . Note that shared containers can't be declared inside nested test classes. This is because nested test classes have to be defined non-static and can't therefore have static fields. Singleton containers Note that the singleton container pattern is also an option when using JUnit 5. Limitations Since this module has a dependency onto JUnit Jupiter and on Testcontainers core, which has a dependency onto JUnit 4.x, projects using this module will end up with both, JUnit Jupiter and JUnit 4.x in the test classpath. This extension has only been tested with sequential test execution. Using it with parallel test execution is unsupported and may have unintended side effects. Adding Testcontainers JUnit 5 support to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:junit-jupiter:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> junit-jupiter </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Jupiter / JUnit 5"},{"location":"test_framework_integration/junit_5/#jupiter-junit-5","text":"While Testcontainers is tightly coupled with the JUnit 4.x rule API, this module provides an API that is based on the JUnit Jupiter extension model. The extension supports two modes: containers that are restarted for every test method containers that are shared between all methods of a test class Note that Jupiter/JUnit 5 integration is packaged as a separate library JAR; see below for details.","title":"Jupiter / JUnit 5"},{"location":"test_framework_integration/junit_5/#extension","text":"Jupiter integration is provided by means of the @Testcontainers annotation. The extension finds all fields that are annotated with @Container and calls their container lifecycle methods (methods on the Startable interface). Containers declared as static fields will be shared between test methods. They will be started only once before any test method is executed and stopped after the last test method has executed. Containers declared as instance fields will be started and stopped for every test method. Note: This extension has only been tested with sequential test execution. Using it with parallel test execution is unsupported and may have unintended side effects. Example: Mixed Lifecycle @Testcontainers class MixedLifecycleTests { // will be shared between test methods @Container private static final MySQLContainer MY_SQL_CONTAINER = new MySQLContainer (); // will be started before and stopped after each test method @Container private PostgreSQLContainer postgresqlContainer = new PostgreSQLContainer () . withDatabaseName ( \"foo\" ) . withUsername ( \"foo\" ) . withPassword ( \"secret\" ); @Test void test () { assertThat ( MY_SQL_CONTAINER . isRunning ()). isTrue (); assertThat ( postgresqlContainer . isRunning ()). isTrue (); } }","title":"Extension"},{"location":"test_framework_integration/junit_5/#examples","text":"To use the Testcontainers extension annotate your test class with @Testcontainers .","title":"Examples"},{"location":"test_framework_integration/junit_5/#restarted-containers","text":"To define a restarted container, define an instance field inside your test class and annotate it with the @Container annotation. Restarted Containers @Testcontainers class TestcontainersNestedRestartedContainerTests { @Container private final GenericContainer <?> topLevelContainer = new GenericContainer <> ( JUnitJupiterTestImages . HTTPD_IMAGE ) . withExposedPorts ( 80 ); \u22ef @Test void top_level_container_should_be_running () { assertThat ( topLevelContainer . isRunning ()). isTrue (); \u22ef } @Nested class NestedTestCase { @Container private final GenericContainer <?> nestedContainer = new GenericContainer <> ( JUnitJupiterTestImages . HTTPD_IMAGE ) . withExposedPorts ( 80 ); @Test void both_containers_should_be_running () { // top level container is restarted for nested methods assertThat ( topLevelContainer . isRunning ()). isTrue (); // nested containers are only available inside their nested class assertThat ( nestedContainer . isRunning ()). isTrue (); \u22ef } \u22ef } }","title":"Restarted containers"},{"location":"test_framework_integration/junit_5/#shared-containers","text":"Shared containers are defined as static fields in a top level test class and have to be annotated with @Container . Note that shared containers can't be declared inside nested test classes. This is because nested test classes have to be defined non-static and can't therefore have static fields.","title":"Shared containers"},{"location":"test_framework_integration/junit_5/#singleton-containers","text":"Note that the singleton container pattern is also an option when using JUnit 5.","title":"Singleton containers"},{"location":"test_framework_integration/junit_5/#limitations","text":"Since this module has a dependency onto JUnit Jupiter and on Testcontainers core, which has a dependency onto JUnit 4.x, projects using this module will end up with both, JUnit Jupiter and JUnit 4.x in the test classpath. This extension has only been tested with sequential test execution. Using it with parallel test execution is unsupported and may have unintended side effects.","title":"Limitations"},{"location":"test_framework_integration/junit_5/#adding-testcontainers-junit-5-support-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:junit-jupiter:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> junit-jupiter </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding Testcontainers JUnit 5 support to your project dependencies"},{"location":"test_framework_integration/manual_lifecycle_control/","text":"Manual container lifecycle control While Testcontainers was originally built with JUnit 4 integration in mind, it is fully usable with other test frameworks, or with no framework at all. Manually starting/stopping containers Containers can be started and stopped in code using start() and stop() methods. Additionally, container classes implement AutoCloseable . This enables better assurance that the container will be stopped at the appropriate time. try ( GenericContainer container = new GenericContainer ( \"imagename\" )) { container . start (); // ... use the container // no need to call stop() afterwards } Singleton containers Sometimes it might be useful to define a container that is only started once for several test classes. There is no special support for this use case provided by the Testcontainers extension. Instead this can be implemented using the following pattern: abstract class AbstractContainerBaseTest { static final MySQLContainer MY_SQL_CONTAINER ; static { MY_SQL_CONTAINER = new MySQLContainer (); MY_SQL_CONTAINER . start (); } } class FirstTest extends AbstractContainerBaseTest { @Test void someTestMethod () { String url = MY_SQL_CONTAINER . getJdbcUrl (); // create a connection and run test as normal } } The singleton container is started only once when the base class is loaded. The container can then be used by all inheriting test classes. At the end of the test suite the Ryuk container that is started by Testcontainers core will take care of stopping the singleton container.","title":"Manual container lifecycle control"},{"location":"test_framework_integration/manual_lifecycle_control/#manual-container-lifecycle-control","text":"While Testcontainers was originally built with JUnit 4 integration in mind, it is fully usable with other test frameworks, or with no framework at all.","title":"Manual container lifecycle control"},{"location":"test_framework_integration/manual_lifecycle_control/#manually-startingstopping-containers","text":"Containers can be started and stopped in code using start() and stop() methods. Additionally, container classes implement AutoCloseable . This enables better assurance that the container will be stopped at the appropriate time. try ( GenericContainer container = new GenericContainer ( \"imagename\" )) { container . start (); // ... use the container // no need to call stop() afterwards }","title":"Manually starting/stopping containers"},{"location":"test_framework_integration/manual_lifecycle_control/#singleton-containers","text":"Sometimes it might be useful to define a container that is only started once for several test classes. There is no special support for this use case provided by the Testcontainers extension. Instead this can be implemented using the following pattern: abstract class AbstractContainerBaseTest { static final MySQLContainer MY_SQL_CONTAINER ; static { MY_SQL_CONTAINER = new MySQLContainer (); MY_SQL_CONTAINER . start (); } } class FirstTest extends AbstractContainerBaseTest { @Test void someTestMethod () { String url = MY_SQL_CONTAINER . getJdbcUrl (); // create a connection and run test as normal } } The singleton container is started only once when the base class is loaded. The container can then be used by all inheriting test classes. At the end of the test suite the Ryuk container that is started by Testcontainers core will take care of stopping the singleton container.","title":"Singleton containers"},{"location":"test_framework_integration/spock/","text":"Spock Spock extension for Testcontainers library, which allows to use Docker containers inside of Spock tests. Usage @Testcontainers class-annotation Specifying the @Testcontainers annotation will instruct Spock to start and stop all testcontainers accordingly. This annotation can be mixed with Spock's @Shared annotation to indicate, that containers shouldn't be restarted between tests. PostgresContainerIT @Testcontainers class PostgresContainerIT extends Specification { @Shared PostgreSQLContainer postgreSQLContainer = new PostgreSQLContainer ( SpockTestImages . POSTGRES_TEST_IMAGE ) . withDatabaseName ( \"foo\" ) . withUsername ( \"foo\" ) . withPassword ( \"secret\" ) def \"waits until postgres accepts jdbc connections\" () { given: \"a jdbc connection\" HikariConfig hikariConfig = new HikariConfig () hikariConfig . setJdbcUrl ( postgreSQLContainer . jdbcUrl ) hikariConfig . setUsername ( \"foo\" ) hikariConfig . setPassword ( \"secret\" ) HikariDataSource ds = new HikariDataSource ( hikariConfig ) when: \"querying the database\" Statement statement = ds . getConnection (). createStatement () statement . execute ( \"SELECT 1\" ) ResultSet resultSet = statement . getResultSet () resultSet . next () then: \"result is returned\" int resultSetInt = resultSet . getInt ( 1 ) resultSetInt == 1 cleanup: ds . close () } } Adding Testcontainers Spock support to your project dependencies Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:spock:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> spock </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency> Attributions The initial version of this project was heavily inspired by the excellent JUnit5 docker extension by FaustXVI .","title":"Spock"},{"location":"test_framework_integration/spock/#spock","text":"Spock extension for Testcontainers library, which allows to use Docker containers inside of Spock tests.","title":"Spock"},{"location":"test_framework_integration/spock/#usage","text":"","title":"Usage"},{"location":"test_framework_integration/spock/#testcontainers-class-annotation","text":"Specifying the @Testcontainers annotation will instruct Spock to start and stop all testcontainers accordingly. This annotation can be mixed with Spock's @Shared annotation to indicate, that containers shouldn't be restarted between tests. PostgresContainerIT @Testcontainers class PostgresContainerIT extends Specification { @Shared PostgreSQLContainer postgreSQLContainer = new PostgreSQLContainer ( SpockTestImages . POSTGRES_TEST_IMAGE ) . withDatabaseName ( \"foo\" ) . withUsername ( \"foo\" ) . withPassword ( \"secret\" ) def \"waits until postgres accepts jdbc connections\" () { given: \"a jdbc connection\" HikariConfig hikariConfig = new HikariConfig () hikariConfig . setJdbcUrl ( postgreSQLContainer . jdbcUrl ) hikariConfig . setUsername ( \"foo\" ) hikariConfig . setPassword ( \"secret\" ) HikariDataSource ds = new HikariDataSource ( hikariConfig ) when: \"querying the database\" Statement statement = ds . getConnection (). createStatement () statement . execute ( \"SELECT 1\" ) ResultSet resultSet = statement . getResultSet () resultSet . next () then: \"result is returned\" int resultSetInt = resultSet . getInt ( 1 ) resultSetInt == 1 cleanup: ds . close () } }","title":"@Testcontainers class-annotation"},{"location":"test_framework_integration/spock/#adding-testcontainers-spock-support-to-your-project-dependencies","text":"Add the following dependency to your pom.xml / build.gradle file: Gradle Maven testImplementation \"org.testcontainers:spock:1.20.6\" <dependency> <groupId> org.testcontainers </groupId> <artifactId> spock </artifactId> <version> 1.20.6 </version> <scope> test </scope> </dependency>","title":"Adding Testcontainers Spock support to your project dependencies"},{"location":"test_framework_integration/spock/#attributions","text":"The initial version of this project was heavily inspired by the excellent JUnit5 docker extension by FaustXVI .","title":"Attributions"}]}